---
layout: default
title: "[8.5]Physical ID-Transfer Attacks against Multi-Object Tracking via Adversarial Trajectory"
---

# [8.5] Physical ID-Transfer Attacks against Multi-Object Tracking via Adversarial Trajectory

- Authors: Chenyi Wang, Yanmao Man, Raymond Muller, Ming Li, Z. Berkay Celik, Ryan Gerdes, Jonathan ...
- [arXiv Link](https://arxiv.org/abs/2512.01934)
- [PDF Link](https://arxiv.org/pdf/2512.01934.pdf)

## Subfields
 安全与鲁棒性 / 多目标跟踪 (Security & Robustness / MOT)
## Reason for Interest

1. 创新性强：不同于以往针对物体检测（OD）模块的对抗性补丁攻击，本文创新性地攻击了MOT中的关联阶段（特别是卡尔曼滤波运动预测），通过物理轨迹欺骗（Adversarial Trajectory）实现ID互换，揭示了基于运动模型的跟踪算法的底层逻辑缺陷。
2. 实验完整且深入：不仅在CARLA仿真中验证了多种SOTA跟踪器，还进行了真人实地行走实验，验证了攻击的物理可行性。更重要的是，论文还在Baidu Apollo自动驾驶全栈系统中进行了端到端测试，证明该攻击可导致车辆做出错误的急刹车决策，直接关联到自动驾驶安全。
3. 行业价值高：提出的“急停-起步”等通用对抗动作（Universal Adversarial Maneuvers）简单易行，对自动驾驶路测和感知算法的鲁棒性测试具有极高的参考价值。
4. 局限性：实车攻击仅在仿真中进行，真实世界实验仅限于行人场景，但考虑到安全伦理，这是合理的。
## Abstract: 
Multi-Object Tracking (MOT) is a critical task in computer vision, with applications ranging from surveillance systems to autonomous driving. However, threats to MOT algorithms have yet been widely studied. In particular, incorrect association between the tracked objects and their assigned IDs can lead to severe consequences, such as wrong trajectory predictions. Previous attacks against MOT either focused on hijacking the trackers of individual objects, or manipulating the tracker IDs in MOT by attacking the integrated object detection (OD) module in the digital domain, which are model-specific, non-robust, and only able to affect specific samples in offline datasets. In this paper, we present AdvTraj, the first online and physical ID-manipulation attack against tracking-by-detection MOT, in which an attacker uses adversarial trajectories to transfer its ID to a targeted object to confuse the tracking system, without attacking OD. Our simulation results in CARLA show that AdvTraj can fool ID assignments with 100% success rate in various scenarios for white-box attacks against SORT, which also have high attack transferability (up to 93% attack success rate) against state-of-the-art (SOTA) MOT algorithms due to their common design principles. We characterize the patterns of trajectories generated by AdvTraj and propose two universal adversarial maneuvers that can be performed by a human walker/driver in daily scenarios. Our work reveals under-explored weaknesses in the object association phase of SOTA MOT systems, and provides insights into enhancing the robustness of such systems.
