---
layout: default
title: "[7.8]Range-Edit: Semantic Mask Guided Outdoor LiDAR Scene Editing"
---

# [7.8] Range-Edit: Semantic Mask Guided Outdoor LiDAR Scene Editing

- Authors: Suchetan G. Uppur, Hemant Kumar, Vaibhav Kumar
- [arXiv Link](https://arxiv.org/abs/2511.17269)
- [PDF Link](https://arxiv.org/pdf/2511.17269.pdf)

## Subfields
 自动驾驶仿真 / LiDAR场景生成 (AD Simulation / LiDAR Scene Generation)
## Reason for Interest

论文提出了一种基于潜扩散模型（LDM）和语义掩码引导的LiDAR场景编辑方法Range-EDIT。创新点在于将3D点云编辑转化为2D距离图像（Range Image）的修复问题，并利用凸包（Convex Hull）掩码增强了几何一致性，无需预定义的3D CAD模型即可生成碰撞、遮挡等长尾（Corner Case）场景。这对于自动驾驶感知模型的鲁棒性训练具有较高价值。扣分点在于目前实验仅限于'Car'类别，且主要进行了消融实验，缺乏与现有其他LiDAR增强方法（如基于CAD模型的插入或LiDARSim等）的广泛横向对比，下游感知任务的提升验证也相对初步。
## Abstract: 
Training autonomous driving and navigation systems requires large and diverse point cloud datasets that capture complex edge case scenarios from various dynamic urban settings. Acquiring such diverse scenarios from real-world point cloud data, especially for critical edge cases, is challenging, which restricts system generalization and robustness. Current methods rely on simulating point cloud data within handcrafted 3D virtual environments, which is time-consuming, computationally expensive, and often fails to fully capture the complexity of real-world scenes. To address some of these issues, this research proposes a novel approach that addresses the problem discussed by editing real-world LiDAR scans using semantic mask-based guidance to generate novel synthetic LiDAR point clouds. We incorporate range image projection and semantic mask conditioning to achieve diffusion-based generation. Point clouds are transformed to 2D range view images, which are used as an intermediate representation to enable semantic editing using convex hull-based semantic masks. These masks guide the generation process by providing information on the dimensions, orientations, and locations of objects in the real environment, ensuring geometric consistency and realism. This approach demonstrates high-quality LiDAR point cloud generation, capable of producing complex edge cases and dynamic scenes, as validated on the KITTI-360 dataset. This offers a cost-effective and scalable solution for generating diverse LiDAR data, a step toward improving the robustness of autonomous driving systems.
