---
layout: default
title: "[9.2]LidarDM: Generative LiDAR Simulation in a Generated World"
---

# [9.2] LidarDM: Generative LiDAR Simulation in a Generated World

- Authors: Vlas Zyrianov, Henry Che, Zhijian Liu, Shenlong Wang
- [arXiv Link](https://arxiv.org/abs/2404.02903)
- [PDF Link](https://arxiv.org/pdf/2404.02903.pdf)

## Subfields
 仿真模拟 / 数据增强 / 生成式模型
## Reason for Interest

该论文提出了一种结合潜在扩散模型（Latent Diffusion Model）与基于物理的光线投射（Raycasting）的4D LiDAR场景生成框架。创新性极高：它是首个支持基于地图布局（Layout-aware）生成且具备时序一致性的LiDAR视频生成模型。方法论上，通过先生成3D静态场景和动态物体（4D World），再进行传感器模拟，保证了物理合理性和几何一致性，解决了纯数据驱动方法中“闪烁”或几何结构不稳定的问题。实验非常完整：不仅在生成质量指标（JSD, MMD）上达到SOTA水平，更重要的是通过Sim2Real实验证明了生成数据能显著提升下游感知和规划任务的性能，具有极高的行业落地价值。代码已开源，可信度高。
## Abstract: 
We present LidarDM, a novel LiDAR generative model capable of producing realistic, layout-aware, physically plausible, and temporally coherent LiDAR videos. LidarDM stands out with two unprecedented capabilities in LiDAR generative modeling: (i) LiDAR generation guided by driving scenarios, offering significant potential for autonomous driving simulations, and (ii) 4D LiDAR point cloud generation, enabling the creation of realistic and temporally coherent sequences. At the heart of our model is a novel integrated 4D world generation framework. Specifically, we employ latent diffusion models to generate the 3D scene, combine it with dynamic actors to form the underlying 4D world, and subsequently produce realistic sensory observations within this virtual environment. Our experiments indicate that our approach outperforms competing algorithms in realism, temporal coherency, and layout consistency. We additionally show that LidarDM can be used as a generative world model simulator for training and testing perception models.
