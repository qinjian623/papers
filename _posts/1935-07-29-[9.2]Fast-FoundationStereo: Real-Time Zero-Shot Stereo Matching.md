---
layout: default
title: "[9.2]Fast-FoundationStereo: Real-Time Zero-Shot Stereo Matching"
---

# [9.2] Fast-FoundationStereo: Real-Time Zero-Shot Stereo Matching

- Authors: Bowen Wen, Shaurya Dewan, Stan Birchfield
- [arXiv Link](https://arxiv.org/abs/2512.11130)
- [PDF Link](https://arxiv.org/pdf/2512.11130.pdf)

## Subfields
 3D感知 / 立体匹配 (Stereo Matching)
## Reason for Interest

该论文直击自动驾驶视觉感知中‘大模型泛化性强但推理慢’与‘小模型速度快但泛化差’的痛点，具有极高的工业价值。1. 创新性：提出了一套完整的‘分治加速’策略，结合了知识蒸馏（保留大模型先验）、分块NAS搜索（优化代价过滤）和结构化剪枝（加速精细化模块），技术路线清晰且高效。2. 实验完整性：在Middlebury、ETH3D和KITTI等多个权威数据集上进行了广泛的零样本测试，证明了其在不同域下的鲁棒性；同时提供了详尽的消融实验和运行时间分析。3. 实用性：作为NVIDIA的研究成果，该方法将Foundation Model的强悍能力成功压缩至实时运行级别（~20FPS+），对于不依赖LiDAR的纯视觉自动驾驶方案或低算力机器人平台具有重大意义。
## Abstract: 
Stereo foundation models achieve strong zero-shot generalization but remain computationally prohibitive for real-time applications. Efficient stereo architectures, on the other hand, sacrifice robustness for speed and require costly per-domain fine-tuning. To bridge this gap, we present Fast-FoundationStereo, a family of architectures that achieve, for the first time, strong zero-shot generalization at real-time frame rate. We employ a divide-and-conquer acceleration strategy with three components: (1) knowledge distillation to compress the hybrid backbone into a single efficient student; (2) blockwise neural architecture search for automatically discovering optimal cost filtering designs under latency budgets, reducing search complexity exponentially; and (3) structured pruning for eliminating redundancy in the iterative refinement module. Furthermore, we introduce an automatic pseudo-labeling pipeline used to curate 1.4M in-the-wild stereo pairs to supplement synthetic training data and facilitate knowledge distillation. The resulting model can run over 10x faster than FoundationStereo while closely matching its zero-shot accuracy, thus establishing a new state-of-the-art among real-time methods. Project page: https://nvlabs.github.io/Fast-FoundationStereo/
