---
layout: default
title: "[8.5]CATS-V2V: A Real-World Vehicle-to-Vehicle Cooperative Perception Dataset with Complex Adverse Traffic Scenarios"
---

# [8.5] CATS-V2V: A Real-World Vehicle-to-Vehicle Cooperative Perception Dataset with Complex Adverse Traffic Scenarios

- Authors: Hangyu Li, Bofeng Cao, Zhaohui Liang, Wuzhen Li, Juyoung Oh, Yuxuan Chen, Shixiao Liang, ...
- [arXiv Link](https://arxiv.org/abs/2511.11168)
- [PDF Link](https://arxiv.org/pdf/2511.11168.pdf)

## Subfields
 V2X Cooperative Perception / Dataset (V2X协同感知/数据集)
## Reason for Interest

论文填补了自动驾驶领域中极度稀缺的‘真实世界+恶劣天气+V2V协同’数据集空白。创新性在于构建了一套基于FPGA和PTP的高精度硬件同步采集系统（误差<1ms），解决了多车多传感器（LiDAR/Camera）在高速运动下的时空对齐难题。此外，提出的基于目标的时序对齐算法有效修正了卷帘快门和扫描机制带来的畸变，显著提高了标注与数据的吻合度。虽然论文未提供下游感知任务（如3D检测）的Baseline性能跑分，但作为高质量的基础设施建设工作，对提升协同感知算法在长尾场景下的鲁棒性具有极高的行业价值和研究潜力。
## Abstract: 
Vehicle-to-Vehicle (V2V) cooperative perception has great potential to enhance autonomous driving performance by overcoming perception limitations in complex adverse traffic scenarios (CATS). Meanwhile, data serves as the fundamental infrastructure for modern autonomous driving AI. However, due to stringent data collection requirements, existing datasets focus primarily on ordinary traffic scenarios, constraining the benefits of cooperative perception. To address this challenge, we introduce CATS-V2V, the first-of-its-kind real-world dataset for V2V cooperative perception under complex adverse traffic scenarios. The dataset was collected by two hardware time-synchronized vehicles, covering 10 weather and lighting conditions across 10 diverse locations. The 100-clip dataset includes 60K frames of 10 Hz LiDAR point clouds and 1.26M multi-view 30 Hz camera images, along with 750K anonymized yet high-precision RTK-fixed GNSS and IMU records. Correspondingly, we provide time-consistent 3D bounding box annotations for objects, as well as static scenes to construct a 4D BEV representation. On this basis, we propose a target-based temporal alignment method, ensuring that all objects are precisely aligned across all sensor modalities. We hope that CATS-V2V, the largest-scale, most supportive, and highest-quality dataset of its kind to date, will benefit the autonomous driving community in related tasks.
