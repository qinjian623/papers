---
layout: default
title: "[9.2]WPT: World-to-Policy Transfer via Online World Model Distillation"
---

# [9.2] WPT: World-to-Policy Transfer via Online World Model Distillation

- Authors: Guangfeng Jiang, Yueru Luo, Jun Liu, Yi Huang, Yiyao Zhu, Zhan Qu, Dave Zhenyu Chen, Bing...
- [arXiv Link](https://arxiv.org/abs/2511.20095v1)
- [PDF Link](https://arxiv.org/pdf/2511.20095v1.pdf)

## Subfields
 端到端自动驾驶 / 世界模型 (End-to-End AD / World Models)
## Reason for Interest

论文切中自动驾驶世界模型（World Model）应用中的核心痛点——推理延迟高。提出了一种‘世界模型到策略转移’（WPT）的训练范式，利用世界模型作为训练时的‘教师’，通过构造包含模仿与模拟信号的奖励模型，将对未来的预测推理能力蒸馏至轻量级的‘学生’策略网络中。该方法既保留了世界模型在长时序规划和安全性上的优势（nuScenes碰撞率极低），又通过蒸馏避免了推理时的计算开销（推理速度提升4.9倍，仅需64ms），兼具极高的学术创新性和工业落地价值。实验验证详实，涵盖开环与闭环测试，SOTA优势明显。
## Abstract: 

