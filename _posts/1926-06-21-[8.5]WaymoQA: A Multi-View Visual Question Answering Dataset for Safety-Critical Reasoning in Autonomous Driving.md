---
layout: default
title: "[8.5]WaymoQA: A Multi-View Visual Question Answering Dataset for Safety-Critical Reasoning in Autonomous Driving"
---

# [8.5] WaymoQA: A Multi-View Visual Question Answering Dataset for Safety-Critical Reasoning in Autonomous Driving

- Authors: Seungjun Yu, Seonho Lee, Namho Kim, Jaeyo Shin, Junsung Park, Wonjeong Ryu, Raehyuk Jung,...
- [arXiv Link](https://arxiv.org/abs/2511.20022v1)
- [PDF Link](https://arxiv.org/pdf/2511.20022v1.pdf)

## Subfields
 自动驾驶多模态大模型 (AD-MLLM) / 驾驶问答 (Driving QA) / 安全关键场景理解
## Reason for Interest

论文针对自动驾驶大模型（MLLM）在长尾安全关键场景（Safety-Critical Scenarios）推理能力不足的问题，提出了高质量的 WaymoQA 数据集和评测基准。

1. **创新性与方向价值 (9/10)**：不同于以往关注正常驾驶或仅用于评测的数据集（如 NuScenes-QA, DVBench），该工作专注于“多视角（Multi-view）”与“安全关键”的结合，并填补了此类场景缺乏训练集（Training Split）的空白。提出的“两阶段安全推理（先解决即时风险，再规避衍生风险）”符合驾驶决策逻辑。

2. **实验完整性 (8/10)**：基于 Waymo Open Dataset 构建，利用 NHTSA 事故类型分类筛选场景，并经过人工校验（非纯合成），保证了数据质量。实验覆盖了主流开源 MLLM（Qwen, LLaVA, InternVL），消融实验验证了多视角输入和视频时序信息的必要性。

3. **结果可信度 (8/10)**：结果显示现有通用 MLLM 在安全场景表现显著弱于正常场景，而使用该数据集微调后能力大幅提升，证明了针对性数据的必要性。

4. **行业潜力**：该工作对于提升端到端自动驾驶模型在 Corner Case 下的解释性、感知与规划对齐能力具有重要的参考价值。
## Abstract: 

