---
layout: default
title: "[9.0]Poutine: Vision-Language-Trajectory Pre-Training and Reinforcement Learning Post-Training Enable Robust End-to-End Autonomous Driving"
---

# [9.0] Poutine: Vision-Language-Trajectory Pre-Training and Reinforcement Learning Post-Training Enable Robust End-to-End Autonomous Driving

- Authors: Luke Rowe, Rodrigue de Schaetzen, Roger Girgis, Christopher Pal, Liam Paull
- [arXiv Link](https://arxiv.org/abs/2506.11234)
- [PDF Link](https://arxiv.org/pdf/2506.11234.pdf)

## Subfields
 端到端自动驾驶 / 视觉-语言-轨迹模型 / 强化学习在自动驾驶中的应用
## Reason for Interest

该论文提出了Poutine，一个利用现成的3B参数视觉-语言模型（VLM）实现鲁棒端到端自动驾驶的方法。其创新性体现在：1) 采用VLT（视觉-语言-轨迹）预训练范式，将轨迹直接编码为文本进行预测，避免了自定义感知骨干或动作头，简化了架构；2) 通过一个更大（72B参数）的VLM自动生成语言标注，大大减少了对人工标注的需求，实现了可扩展的自监督预训练；3) 引入了轻量级的基于人类偏好的强化学习（GRPO）后训练阶段，仅使用少量标注（不足500帧）便显著提升了在长尾场景下的性能；4) 展示了模型在不同地理区域（日本到美国，左舵到右舵）的零样本泛化能力，这一点对于自动驾驶的全球部署具有重要意义。实验在Waymo WOD-E2E数据集上进行了充分验证，该数据集专注于挑战性的长尾场景，而非传统的名义场景，确保了结果的相关性。Poutine模型在挑战赛中名列第一，其结果可信度极高。尽管在少数特定长尾场景（如Spotlight, Construction）上RL微调可能导致性能略有下降，但整体RFS和ADE的提升及其强调的鲁棒性和泛化能力，使其在自动驾驶领域具有巨大的行业潜力和研究价值。
## Abstract: 
Maintaining good driving behavior in out-of-distribution scenarios remains a critical challenge in autonomous driving. A promising direction is to leverage the generalist knowledge and reasoning capabilities of large-language models by treating unusual driving scenarios as a logical reasoning task. In this work, we present Poutine, a method that uses an off-the-shelf 3B-parameter vision-language model (VLM) - without any additional components - to achieve robust end-to-end autonomous driving via a simple and scalable training recipe. To learn strong base driving capabilities, we first train Poutine-Base using self-supervised next-token prediction over vision, language, and trajectory (VLT) tokens, leveraging both nominal and long-tail driving data. In the second stage, we fine-tune Poutine-Base using Group Relative Policy Optimization (GRPO) with a small set of human preference-labeled examples. We evaluated our approach on the Waymo end-to-end driving benchmark curated for long-tail scenarios. The final Poutine model achieves an RFS of 7.99 on the test set, placing 1st in the 2025 Waymo Vision-Based End-to-End Driving Challenge by a significant margin. Our results suggest that handcrafted tokenizers or custom architectural components added to base VLMs in prior work are not necessary to achieve strong driving performance. Instead, this work highlights the potential of scalable VLT pretraining combined with lightweight RL fine-tuning to enable robust and generalizable autonomous driving.
