---
layout: default
title: "[6.8]RangeSAM: On the Potential of Visual Foundation Models for Range-View represented LiDAR segmentation"
---

# [6.8] RangeSAM: On the Potential of Visual Foundation Models for Range-View represented LiDAR segmentation

- Authors: Paul Julius K\"uhn, Duc Anh Nguyen, Arjan Kuijper, Holger Graf, Saptarshi Neil Sinha
- [arXiv Link](https://arxiv.org/abs/2509.15886)
- [PDF Link](https://arxiv.org/pdf/2509.15886.pdf)

## Subfields
 LiDAR语义分割 / 距离视图感知 / 视觉基础模型在3D感知中的应用
## Reason for Interest

1. **创新性：** 论文的创新点在于首次将2D视觉基础模型（如SAM2）适配到3D LiDAR点云的距离视图（Range-View）语义分割任务中，并针对距离视图数据的几何特性对SAM2的编码器（Stem模块、Hiera Blocks、窗口注意力机制）进行了定制化修改。这一探索方向在自动驾驶感知领域，尤其是利用大规模预训练模型方面具有前瞻性。
2. **实验完整性：** 论文在主流的SemanticKITTI数据集上进行了详细的实验验证，并利用nuScenes数据集进行了预训练。评估指标采用标准的mIoU和各类别IoU。此外，论文还进行了全面的消融研究，分析了不同Hiera骨干网、数据增强策略以及迁移学习对模型性能的影响，实验设计较为完善。
3. **可信度：** 论文在结果分析中表现出高度的诚实性和批判性思维。它明确承认当前模型性能未达SOTA，并量化了与现有SOTA方法的差距。同时，论文还指出了模型的局限性，例如在处理稀有或小物体时的不足，以及计算复杂度（RFB模块成为瓶颈）对实时部署的挑战，这些坦诚的讨论大大增加了研究的可信度。
4. **行业潜力：** 论文所提出的将视觉基础模型与距离视图方法结合，以实现LiDAR语义分割的理念，在自动驾驶领域具有重要的理论和长期潜力。这种方法有望继承2D管道的速度、可扩展性和部署简易性，并利用基础模型的泛化能力和零样本学习潜力来减少标注成本，提高模型在复杂多样环境下的鲁棒性。然而，当前模型的性能与SOTA仍有较大差距，且文中明确指出的计算瓶颈（RFB）也限制了其在自动驾驶场景下的实时部署能力，因此在当前阶段直接应用于产业的潜力有限，更多是为未来研究指明了方向。
## Abstract: 
Point cloud segmentation is central to autonomous driving and 3D scene understanding. While voxel- and point-based methods dominate recent research due to their compatibility with deep architectures and ability to capture fine-grained geometry, they often incur high computational cost, irregular memory access, and limited real-time efficiency. In contrast, range-view methods, though relatively underexplored - can leverage mature 2D semantic segmentation techniques for fast and accurate predictions. Motivated by the rapid progress in Visual Foundation Models (VFMs) for captioning, zero-shot recognition, and multimodal tasks, we investigate whether SAM2, the current state-of-the-art VFM for segmentation tasks, can serve as a strong backbone for LiDAR point cloud segmentation in the range view. We present , to our knowledge, the first range-view framework that adapts SAM2 to 3D segmentation, coupling efficient 2D feature extraction with standard projection/back-projection to operate on point clouds. To optimize SAM2 for range-view representations, we implement several architectural modifications to the encoder: (1) a novel module that emphasizes horizontal spatial dependencies inherent in LiDAR range images, (2) a customized configuration of tailored to the geometric properties of spherical projections, and (3) an adapted mechanism in the encoder backbone specifically designed to capture the unique spatial patterns and discontinuities present in range-view pseudo-images. Our approach achieves competitive performance on SemanticKITTI while benefiting from the speed, scalability, and deployment simplicity of 2D-centric pipelines. This work highlights the viability of VFMs as general-purpose backbones for 3D perception and opens a path toward unified, foundation-model-driven LiDAR segmentation. Results lets us conclude that range-view segmentation methods using VFMs leads to promising results.
