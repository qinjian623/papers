---
layout: default
title: "[8.2]End-to-End Visual Autonomous Parking via Control-Aided Attention"
---

# [8.2] End-to-End Visual Autonomous Parking via Control-Aided Attention

- Authors: Chao Chen, Shunyu Yao, Yuanwu He, Feng Tao, Ruojing Song, Yuliang Guo, Xinyu Huang, Chenx...
- [arXiv Link](https://arxiv.org/abs/2509.11090v2)
- [PDF Link](https://arxiv.org/pdf/2509.11090v2.pdf)

## Subfields
 端到端自动泊车 / 模仿学习
## Reason for Interest

1. 创新性：提出了Control-Aided Attention (CAA) 机制，利用控制信号的梯度回传监督注意力模块，使感知网络更关注对决策关键的区域（如车位边界），思路新颖且符合端到端直觉。同时引入了显式的目标Token化（TTM）和可学习的运动预测模块，解决了传统E2E方法中目标模糊和时序不一致的问题。
2. 实验完整性：在CARLA仿真器中进行了详尽的对比实验（对比了IV 2024的E2EParking和经典的Hybrid A*），消融实验清晰地证明了各个模块（CAA, TTM, Waypoints）的有效性。提供了详细的失败案例分析（Failure Case Study），增加了结果的可信度。
3. 可信度：承诺开源代码和数据集，复现了基线方法并进行了公平对比。
4. 局限性：实验仅限于仿真环境（CARLA），缺乏实车验证，考虑到泊车场景对实车感知的噪声和动态障碍物处理要求较高，仿真结果到现实的迁移能力有待验证。但作为针对泊车这一特定低速场景的方法论研究，质量较高。
## Abstract: 

