---
layout: default
title: "[9.2]ColaVLA: Leveraging Cognitive Latent Reasoning for Hierarchical Parallel Trajectory Planning in Autonomous Driving"
---

# [9.2] ColaVLA: Leveraging Cognitive Latent Reasoning for Hierarchical Parallel Trajectory Planning in Autonomous Driving

- Authors: Qihang Peng, Xuesong Chen, Chenye Yang, Shaoshuai Shi, Hongsheng Li
- [arXiv Link](https://arxiv.org/abs/2512.22939)
- [PDF Link](https://arxiv.org/pdf/2512.22939.pdf)

## Subfields
 端到端自动驾驶 / VLM 轨迹规划
## Reason for Interest

1. 创新性强：提出了 Cognitive Latent Reasoning（认知潜伏推理），将 VLM 的推理过程从文本空间转移到潜伏空间，解决了文本思维链（CoT）推理速度慢和与控制信号模态不匹配的问题；同时设计了分层并行规划器（Hierarchical Parallel Planner），实现了高效的因果一致性轨迹生成。
2. 实验充分且结果优异：在权威的 nuScenes 开环和 NeuroNCAP 闭环测试中均取得了 SOTA 或极具竞争力的结果，特别是在闭环测试中，安全性和得分大幅领先现有方法。
3. 行业价值高：在保持 VLM 强泛化能力的同时，将推理延迟降低了 5 倍以上，不仅具备学术价值，更大大提升了 VLM 上车的工程可行性。
4. 数据详实：提供了详细的消融实验、可视化分析及延迟对比，可信度高。
## Abstract: 
Autonomous driving requires generating safe and reliable trajectories from complex multimodal inputs. Traditional modular pipelines separate perception, prediction, and planning, while recent end-to-end (E2E) systems learn them jointly. Vision-language models (VLMs) further enrich this paradigm by introducing cross-modal priors and commonsense reasoning, yet current VLM-based planners face three key challenges: (i) a mismatch between discrete text reasoning and continuous control, (ii) high latency from autoregressive chain-of-thought decoding, and (iii) inefficient or non-causal planners that limit real-time deployment. We propose ColaVLA, a unified vision-language-action framework that transfers reasoning from text to a unified latent space and couples it with a hierarchical, parallel trajectory decoder. The Cognitive Latent Reasoner compresses scene understanding into compact, decision-oriented meta-action embeddings through ego-adaptive selection and only two VLM forward passes. The Hierarchical Parallel Planner then generates multi-scale, causality-consistent trajectories in a single forward pass. Together, these components preserve the generalization and interpretability of VLMs while enabling efficient, accurate and safe trajectory generation. Experiments on the nuScenes benchmark show that ColaVLA achieves state-of-the-art performance in both open-loop and closed-loop settings with favorable efficiency and robustness.
