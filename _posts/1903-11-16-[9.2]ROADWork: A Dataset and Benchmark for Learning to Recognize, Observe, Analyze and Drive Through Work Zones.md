---
layout: default
title: "[9.2]ROADWork: A Dataset and Benchmark for Learning to Recognize, Observe, Analyze and Drive Through Work Zones"
---

# [9.2] ROADWork: A Dataset and Benchmark for Learning to Recognize, Observe, Analyze and Drive Through Work Zones

- Authors: Anurag Ghosh, Shen Zheng, Robert Tamburo, Khiem Vuong, Juan Alvarez-Padilla, Hailiang Zhu...
- [arXiv Link](https://arxiv.org/abs/2406.07661)
- [PDF Link](https://arxiv.org/pdf/2406.07661.pdf)

## Subfields
 自动驾驶数据集 / 特殊场景感知与规划 (施工区)
## Reason for Interest

该论文提出了一个在自动驾驶领域极具价值且长期被忽视的长尾场景——施工区（Work Zones）的综合性数据集 ROADWork。数据集规模大，包含4375个视频、9650个精心标注的关键帧和129017个自动计算的路径图像，覆盖18个美国城市及全球范围内的复杂情况。其标注深度和广度极为出色，涵盖了像素级分割、物体级检测、细粒度属性（如路牌文字）、场景描述及2D/3D可行驶路径，为施工区感知、理解和规划提供了全面的研究基础。

论文通过详尽的实验，首次系统性地评估了现有最先进的通用基础模型（如开放词汇检测器、VLM）在施工区场景下的性能瓶颈，有力证明了特定领域数据和微调的重要性。同时，论文还探索并验证了一些“简单而有效”的技术，如视频标签传播、裁剪缩放辅助文本识别、将检测结果作为上下文辅助VLM生成场景描述、以及融入施工区语义进行路径预测等，在各自任务上均取得了显著的性能提升，为后续研究提供了宝贵的经验。

尽管论文本身未提出开创性的新型模型架构，但其通过构建一个高质量、多模态、面向复杂场景的数据集，并在此之上进行全面而深入的基准测试和分析，揭示了当前AI模型在处理自动驾驶关键长尾问题时的局限性，并指明了未来研究方向。数据集的高行业潜力，直接解决了L4/L5级自动驾驶技术部署的一个核心挑战。考虑到其对自动驾驶领域研究的推动作用，尤其是对关键安全问题的关注，该论文具有极高的价值和影响力。
## Abstract: 
Perceiving and autonomously navigating through work zones is a challenging and underexplored problem. Open datasets for this long-tailed scenario are scarce. We propose the ROADWork dataset to learn to recognize, observe, analyze, and drive through work zones. State-of-the-art foundation models fail when applied to work zones. Fine-tuning models on our dataset significantly improves perception and navigation in work zones. With ROADWork dataset, we discover new work zone images with higher precision (+32.5%) at a much higher rate (12.8$\times$) around the world. Open-vocabulary methods fail too, whereas fine-tuned detectors improve performance (+32.2 AP). Vision-Language Models (VLMs) struggle to describe work zones, but fine-tuning substantially improves performance (+36.7 SPICE).
  Beyond fine-tuning, we show the value of simple techniques. Video label propagation provides additional gains (+2.6 AP) for instance segmentation. While reading work zone signs, composing a detector and text spotter via crop-scaling improves performance +14.2% 1-NED). Composing work zone detections to provide context further reduces hallucinations (+3.9 SPICE) in VLMs. We predict navigational goals and compute drivable paths from work zone videos. Incorporating road work semantics ensures 53.6% goals have angular error (AE) < 0.5 (+9.9 %) and 75.3% pathways have AE < 0.5 (+8.1 %).
