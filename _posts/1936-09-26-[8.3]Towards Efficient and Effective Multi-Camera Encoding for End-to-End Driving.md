---
layout: default
title: "[8.3]Towards Efficient and Effective Multi-Camera Encoding for End-to-End Driving"
---

# [8.3] Towards Efficient and Effective Multi-Camera Encoding for End-to-End Driving

- Authors: Jiawei Yang, Ziyu Chen, Yurong You, Yan Wang, Yiming Li, Yuxiao Chen, Boyi Li, Boris Ivan...
- [arXiv Link](https://arxiv.org/abs/2512.10947v2)
- [PDF Link](https://arxiv.org/pdf/2512.10947v2.pdf)

## Subfields
 端到端自动驾驶 / 视觉语言动作模型 (VLA) / 视觉表征学习
## Reason for Interest

1. **创新性与方向价值 (8.5/10)**: 论文针对大模型(VLA)上车面临的视觉Token计算瓶颈，提出了一种打破常规的思路——摒弃BEV、Tri-plane等显式3D几何先验，转而采用纯数据驱动的全局Attention机制来压缩Token。这种'Geometry-Agnostic'的方法符合'The Bitter Lesson'的趋势，且实验发现模型能自发涌现出对终点、车道线的语义理解，对行业技术路线选择（从人工先验转向端到端学习）有重要启发。

2. **实验完整性与可信度 (8.0/10)**: 依托NVIDIA背景，使用了20,000小时的真实路测数据进行训练和评估，实验规模属于行业顶尖水平，消融实验设计详尽（Patchifier大小、Token数量、层数等）。

3. **缺陷与扣分项 (-0.5)**: 尽管实验规模宏大，但评估完全基于私有数据集（Internal Dataset），未在 nuScenes 或 Waymo 等公开学术基准上提供对比结果。这意味着其'SOTA'声明难以被外部研究者直接验证或复现，限制了其在学术界的通用参考价值。

4. **综合评价**: 这是一篇具有极高工业落地潜力的论文，解决了实际工程痛点（推理效率），虽然缺乏公开榜单成绩，但其大规模数据下的结论极具说服力。
## Abstract: 

