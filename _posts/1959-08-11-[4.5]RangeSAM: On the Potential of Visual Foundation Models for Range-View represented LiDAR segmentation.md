---
layout: default
title: "[4.5]RangeSAM: On the Potential of Visual Foundation Models for Range-View represented LiDAR segmentation"
---

# [4.5] RangeSAM: On the Potential of Visual Foundation Models for Range-View represented LiDAR segmentation

- Authors: Paul Julius Kühn, Duc Anh Nguyen, Arjan Kuijper, Holger Graf, Saptarshi Neil Sinha
- [arXiv Link](https://arxiv.org/abs/2509.15886v3)
- [PDF Link](https://arxiv.org/pdf/2509.15886v3.pdf)

## Subfields
 3D感知 / LiDAR语义分割 (LiDAR Semantic Segmentation)
## Reason for Interest

该论文探索了将视觉基础模型（SAM2）应用于LiDAR距离图像（Range View）分割的可行性，具有一定的学术探索意义（验证了跨模态应用）。然而，作为自动驾驶领域的论文，其评分较低的主要原因如下：
1. **性能差距显著**：在SemanticKITTI数据集上，其mIoU仅为60.9%，落后于2022年的主流方法超过12个百分点，甚至不如2020-2021年的部分方法。
2. **工程实用性低**：Range View方法通常追求极致的推理速度，但该模型参数量巨大（63M，即便使用SAM2-tiny），作者在“Future Work”中明确承认参数开销导致其无法满足实时性要求（precludes deployment in real-time applications）。
3. **负面实验结果**：论文提到在Cityscapes上的预训练反而降低了性能，且对于长尾类别（小物体）的检测效果较差。

综上，虽然创新点在于引入SAM2，但对于自动驾驶车端部署而言，该方法目前呈现出“速度慢且精度低”的特点，实际应用价值有限。
## Abstract: 

