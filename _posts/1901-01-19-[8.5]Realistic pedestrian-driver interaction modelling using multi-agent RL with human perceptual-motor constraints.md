---
layout: default
title: "[8.5]Realistic pedestrian-driver interaction modelling using multi-agent RL with human perceptual-motor constraints"
---

# [8.5] Realistic pedestrian-driver interaction modelling using multi-agent RL with human perceptual-motor constraints

- Authors: Yueyang Wang, Mehmet Dogar, Gustav Markkula
- [arXiv Link](https://arxiv.org/abs/2510.27383)
- [PDF Link](https://arxiv.org/pdf/2510.27383.pdf)

## Subfields
 行为建模 / 多智能体交互模拟 / 轨迹预测
## Reason for Interest

这篇论文在自动驾驶领域中，专注于一个至关重要但常被忽视的方向：**逼真的行人-驾驶员交互行为建模**。其核心创新在于提出了一种多智能体强化学习（MARL）框架，首次将人类的感知-运动约束（如视觉噪声、凝视依赖的敏锐度、步态弹道控制、行走努力、驾驶员加速度控制）融入到**行人与驾驶员两个智能体**的策略中，并使用真实世界数据进行训练和验证。这使得模型能够生成更具人性化和可解释性的行为。

**创新性强：**
1.  **多智能体强化学习集成人类约束：** 将人类感知（视觉噪声、贝叶斯感知、凝视依赖的敏锐度）和运动约束（步态弹道控制、行走努力、驾驶员加速平滑）同时应用于行人与车辆智能体，这在现有MARL行为建模工作中是新颖的。过去的工作多集中于优化交互结果或再现经验模式，而没有考虑人类固有的生理限制。
2.  **人口层面参数拟合：** 引入了一种新颖的种群层面参数拟合方法，通过建模人类约束参数的分布来捕捉个体间的行为差异，而非为每个个体优化固定参数。这对于数据有限的真实世界场景建模非常有价值。
3.  **凝视行为建模：** 模型的凝视方向作为决策策略的一部分，实现了与情境适应性凝视行为的模拟，为行人意图识别等领域提供了新的视角。

**实验完整性高：**
1.  **全面对比：** 论文通过四种约束组合（无约束NC、仅运动约束MC、仅视觉约束VC、视觉和运动约束VMC）以及行为克隆（BC）基线，在真实世界数据集上进行了严格的对比实验。
2.  **多维度评估：** 采用NLL、ADE、FDE等轨迹精度指标，以及KS统计量等行为分布相似性指标，从行为、运动学和轨迹层面全面评估了模型的真实性。
3.  **现实世界数据：** 使用了一个精心筛选和预处理的真实世界斑马线交叉口数据集，增强了模型的实际应用价值。

**可信度高：**
1.  **结果一致：** VMC模型在所有评估指标上均表现出最佳性能，证明了同时考虑视觉和运动约束的重要性。
2.  **消融分析：** 通过比较不同约束模型，清晰地展示了运动约束对动作平滑度和时序的影响，视觉约束对感知不确定性和谨慎行为的影响。
3.  **充分讨论限制：** 论文坦诚讨论了模型的局限性，如当前模型仅限于一对一交互、消融分析粒度较粗、奖励函数设计仍有改进空间等，并提出了未来工作方向，体现了严谨的学术态度。

**行业潜力：**
对于自动驾驶系统而言，开发安全、高效且符合人类预期的交互策略至关重要。该研究通过提供更真实的仿真环境，使AV规划系统能够学习与人类期望相符的交互方式，从而提高AV的社会兼容性和安全性。尤其是在数据稀缺的场景下，该基于奖励驱动学习的方法展现出优于行为克隆的潜力，对自动驾驶的仿真评估和规划控制具有重要意义。虽然不是直接的感知或控制模块，但它是自动驾驶系统进行行为预测、决策规划和仿真测试的基石，因此与车端自动驾驶研究直接相关，具有非常高的价值。
## Abstract: 
Modelling pedestrian-driver interactions is critical for understanding human road user behaviour and developing safe autonomous vehicle systems. Existing approaches often rely on rule-based logic, game-theoretic models, or 'black-box' machine learning methods. However, these models typically lack flexibility or overlook the underlying mechanisms, such as sensory and motor constraints, which shape how pedestrians and drivers perceive and act in interactive scenarios. In this study, we propose a multi-agent reinforcement learning (RL) framework that integrates both visual and motor constraints of pedestrian and driver agents. Using a real-world dataset from an unsignalised pedestrian crossing, we evaluate four model variants, one without constraints, two with either motor or visual constraints, and one with both, across behavioural metrics of interaction realism. Results show that the combined model with both visual and motor constraints performs best. Motor constraints lead to smoother movements that resemble human speed adjustments during crossing interactions. The addition of visual constraints introduces perceptual uncertainty and field-of-view limitations, leading the agents to exhibit more cautious and variable behaviour, such as less abrupt deceleration. In this data-limited setting, our model outperforms a supervised behavioural cloning model, demonstrating that our approach can be effective without large training datasets. Finally, our framework accounts for individual differences by modelling parameters controlling the human constraints as population-level distributions, a perspective that has not been explored in previous work on pedestrian-vehicle interaction modelling. Overall, our work demonstrates that multi-agent RL with human constraints is a promising modelling approach for simulating realistic road user interactions.
