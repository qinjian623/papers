---
layout: default
title: "[8.8]TransBridge: Boost 3D Object Detection by Scene-Level Completion with Transformer Decoder"
---

# [8.8] TransBridge: Boost 3D Object Detection by Scene-Level Completion with Transformer Decoder

- Authors: Qinghao Meng, Chenming Wu, Liangjun Zhang, Jianbing Shen
- [arXiv Link](https://arxiv.org/abs/2512.11926)
- [PDF Link](https://arxiv.org/pdf/2512.11926.pdf)

## Subfields
 LiDAR 3D目标检测 / 点云补全 (LiDAR 3D Object Detection / Point Cloud Completion)
## Reason for Interest

1. 创新性：提出了TransBridge模块，通过Transformer解码器联合学习检测与点云补全，有效解决了LiDAR远距离稀疏性问题；设计的DSRecon模块利用时序聚合与表面重建生成高质量稠密真值，为补全任务提供了可靠监督。
2. 实用性：该方法作为即插即用的模块，在单阶段模式下仅增加极少的推理延迟（约0.5ms），却能带来稳定的性能提升（mAP提升0.7-1.5%），具备极高的落地潜力。
3. 实验完整性：在nuScenes和Waymo两大主流数据集上验证了其有效性，且在5种不同的主流检测器（如CenterPoint, VoxelNext, HEDNet）上均表现出一致的提升，证明了泛化能力。
4. 局限性：双阶段模式虽然性能更优但推理耗时显著增加，限制了其在实时系统中的直接应用，但单阶段模式已足够优秀。
## Abstract: 
3D object detection is essential in autonomous driving, providing vital information about moving objects and obstacles. Detecting objects in distant regions with only a few LiDAR points is still a challenge, and numerous strategies have been developed to address point cloud sparsity through densification.This paper presents a joint completion and detection framework that improves the detection feature in sparse areas while maintaining costs unchanged. Specifically, we propose TransBridge, a novel transformer-based up-sampling block that fuses the features from the detection and completion networks.The detection network can benefit from acquiring implicit completion features derived from the completion network. Additionally, we design the Dynamic-Static Reconstruction (DSRecon) module to produce dense LiDAR data for the completion network, meeting the requirement for dense point cloud ground truth.Furthermore, we employ the transformer mechanism to establish connections between channels and spatial relations, resulting in a high-resolution feature map used for completion purposes.Extensive experiments on the nuScenes and Waymo datasets demonstrate the effectiveness of the proposed framework.The results show that our framework consistently improves end-to-end 3D object detection, with the mean average precision (mAP) ranging from 0.7 to 1.5 across multiple methods, indicating its generalization ability. For the two-stage detection framework, it also boosts the mAP up to 5.78 points.
