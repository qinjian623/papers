---
layout: default
title: "[8.5]AsynEIO: Asynchronous Monocular Event-Inertial Odometry Using Gaussian Process Regression"
---

# [8.5] AsynEIO: Asynchronous Monocular Event-Inertial Odometry Using Gaussian Process Regression

- Authors: Zhixiang Wang, Xudong Li, Yizhai Zhang, Fan Zhang, Panfeng Huang
- [arXiv Link](https://arxiv.org/abs/2411.12175)
- [PDF Link](https://arxiv.org/pdf/2411.12175.pdf)

## Subfields
 定位与建图 / 事件相机VIO (Localization & Mapping / Event-based VIO)
## Reason for Interest

1. 创新性：论文提出了一种基于高斯过程（GP）回归的连续时间事件-惯性里程计（AsynEIO），设计了纯事件驱动的异步前端，并深入分析了不同惯性融合因子（GPIF, GPP, ExtPreint）在连续时间框架下的表现，理论深度较强。
2. 实验完整性：在多个权威公开数据集（涵盖高速运动、HDR、低光照）及自采集数据集上进行了广泛测试，对比了传统方法和基于学习的方法，消融实验详尽，验证了不同融合策略的适用场景。
3. 行业价值：针对传统VIO在高速和高动态范围场景下的失效问题提供了有效解决方案。虽然实验主要基于无人机和手持设备，但其连续时间融合框架对自动驾驶中的多传感器非同步融合（如激光雷达/相机/IMU）具有重要的借鉴意义。论文发表于机器人领域顶刊IEEE T-RO，结果可信度高。
## Abstract: 
Event cameras, when combined with inertial sensors, show significant potential for motion estimation in challenging scenarios, such as high-speed maneuvers and low-light environments. There are many methods for producing such estimations, but most boil down to a synchronous discrete-time fusion problem. However, the asynchronous nature of event cameras and their unique fusion mechanism with inertial sensors remain underexplored. In this paper, we introduce a monocular event-inertial odometry method called AsynEIO, designed to fuse asynchronous event and inertial data within a unified Gaussian Process (GP) regression framework. Our approach incorporates an event-driven frontend that tracks feature trajectories directly from raw event streams at a high temporal resolution. These tracked feature trajectories, along with various inertial factors, are integrated into the same GP regression framework to enable asynchronous fusion. With deriving analytical residual Jacobians and noise models, our method constructs a factor graph that is iteratively optimized and pruned using a sliding-window optimizer. Comparative assessments highlight the performance of different inertial fusion strategies, suggesting optimal choices for varying conditions. Experimental results on both public datasets and our own event-inertial sequences indicate that AsynEIO outperforms existing methods, especially in high-speed and low-illumination scenarios.
