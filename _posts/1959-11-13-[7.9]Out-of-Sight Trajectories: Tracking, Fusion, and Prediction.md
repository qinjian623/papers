---
layout: default
title: "[7.9]Out-of-Sight Trajectories: Tracking, Fusion, and Prediction"
---

# [7.9] Out-of-Sight Trajectories: Tracking, Fusion, and Prediction

- Authors: Haichao Zhang, Yi Xu, Yun Fu
- [arXiv Link](https://arxiv.org/abs/2509.15219v1)
- [PDF Link](https://arxiv.org/pdf/2509.15219v1.pdf)

## Subfields
 轨迹预测 / V2X 协同感知 / 多传感器融合
## Reason for Interest

该论文针对自动驾驶中极具挑战性的‘视线外（Out-of-Sight）’与‘遮挡’问题，提出了一种利用V2X/V2P（如手机GPS/无线信号）噪声数据进行轨迹恢复与预测的创新框架。1. **创新性**：提出了视觉-定位去噪模块（Vision-Positioning Denoising），在无真值监督的情况下，巧妙利用视线内目标的视觉数据训练模型，将噪声较大的无线/传感器信号映射到精准的视觉坐标系中，思路新颖且具有较高的理论价值。2. **实验完整性**：在Vi-Fi和JRDB两个多模态数据集上进行了详尽的实验，对比了包括HiVT、AutoBots等SOTA模型的修改版，并进行了充分的消融实验（Ablation Study）。3. **应用价值**：直接解决了纯视觉方案无法处理的严重遮挡盲区安全隐患，对提升自动驾驶安全性有重要意义。4. **局限性**：该方案依赖于被遮挡对象（行人/车辆）携带通信设备（如手机、标签），属于协同感知（Cooperative Perception）范畴，相较于单车智能的通用性略受限，且实验数据集（Vi-Fi, JRDB）相比nuScenes/Waymo稍显小众。但作为前瞻性研究，质量较高，故给予较高评分。
## Abstract: 

