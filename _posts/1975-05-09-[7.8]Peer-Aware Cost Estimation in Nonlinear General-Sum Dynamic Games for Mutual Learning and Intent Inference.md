---
layout: default
title: "[7.8]Peer-Aware Cost Estimation in Nonlinear General-Sum Dynamic Games for Mutual Learning and Intent Inference"
---

# [7.8] Peer-Aware Cost Estimation in Nonlinear General-Sum Dynamic Games for Mutual Learning and Intent Inference

- Authors: Seyed Yousef Soltanian, Wenlong Zhang
- [arXiv Link](https://arxiv.org/abs/2504.17129)
- [PDF Link](https://arxiv.org/pdf/2504.17129.pdf)

## Subfields
 规划控制 / 多智能体博弈 (Game-Theoretic Planning)
## Reason for Interest

论文针对自动驾驶交互中的核心痛点——“博弈对手意图推断”提出了创新解法。核心亮点在于打破了传统方法中假设对方为‘全知专家’的局限，转而将对方建模为‘正在学习的智能体’（Learning from a Learner），并引入意图通信机制主动影响对方策略。理论推导严谨（基于ILQGames扩展），在解决交互死锁和提高博弈安全性方面展示了强大的潜力。主要扣分点在于验证仅限于简化的运动学仿真场景，缺乏在真实大规模驾驶数据集（如Waymo/nuScenes）上的验证或实车部署数据，且计算复杂度在多车场景下的实时性仍需进一步工程验证。
## Abstract: 
Dynamic game theory is a powerful tool in modeling multi-agent interactions and human-robot systems. In practice, since the objective functions of both agents may not be explicitly known to each other, these interactions can be modeled as incomplete-information general-sum dynamic games. Solving for equilibrium policies for such games presents a major challenge, especially if the games involve nonlinear underlying dynamics. To simplify the problem, existing work often assumes that one agent is an expert with complete information about its peer, which can lead to biased estimates and failures in coordination. To address this challenge, we propose a nonlinear peer-aware cost estimation (N-PACE) algorithm for general-sum dynamic games. In N-PACE, using iterative linear quadratic (ILQ) approximation of dynamic games, each agent explicitly models the learning dynamics of its peer agent while inferring their objective functions and updating its own control policy accordingly in real time, which leads to unbiased and fast learning of the unknown objective function of the peer agent. Additionally, we demonstrate how N-PACE enables intent communication by explicitly modeling the peer's learning dynamics. Finally, we show how N-PACE outperforms baseline methods that disregard the learning behavior of the other agent, both analytically and using our case studies
