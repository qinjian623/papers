---
layout: default
title: "[8.5]MonoSR: Open-Vocabulary Spatial Reasoning from Monocular Images"
---

# [8.5] MonoSR: Open-Vocabulary Spatial Reasoning from Monocular Images

- Authors: Qirui Wang, Jingyi He, Yining Pan, Si Yong Yeo, Xulei Yang, Shijie Li
- [arXiv Link](https://arxiv.org/abs/2511.19119)
- [PDF Link](https://arxiv.org/pdf/2511.19119.pdf)

## Subfields
 3D感知 / 视觉语言模型 (VLM) / 空间推理数据集
## Reason for Interest

1. 创新性与价值：该论文针对自动驾驶和具身智能中的核心痛点——单目3D空间推理（Monocular Spatial Reasoning）提出了大规模数据集MonoSR。不同于以往局限于室内场景（ScanQA等）的数据集，MonoSR涵盖了大量户外/道路场景（源自Omni3D，包含KITTI/nuScenes等数据），直接对应自动驾驶中的感知需求。
2. 任务设计高度相关：论文设计的任务包括距离测量、尺寸估计、遮挡判断、视角想象（Perspective-Aware Imagination）以及情境推理（如安全间隙判断）。这些能力是端到端自动驾驶大模型（如DriveVLM）所需的核心空间理解能力。
3. 实验与洞察：通过评测发现当前SOTA VLM（如GPT-4V, Gemini）在纯单目空间推理上仍有显著局限，并证明了引入3D BBox或2D Prompt作为辅助信息能有效提升性能，为未来自动驾驶VLM的输入模态设计提供了指导。
4. 行业潜力：该数据集填补了开放世界单目3D推理评估的空白，对于训练和评估具有更强空间物理常识的自动驾驶大模型具有很高的实用价值。
## Abstract: 
Spatial reasoning (SR), the ability to infer 3D spatial information from 2D inputs, is essential for real-world applications such as embodied AI and autonomous driving. However, existing research primarily focuses on indoor environments and typically relies on multi-view observations, which limits their generalizability to outdoor scenarios and constrains their applicability to monocular images, the most common real-world setting. In this work, we propose MonoSR, a large-scale monocular spatial reasoning dataset that spans diverse scenarios including indoor, outdoor, and object-centric settings, and supports multiple question types. MonoSR provides a path toward open-world monocular spatial reasoning. Beyond introducing the dataset, we evaluate advanced vision-language models to reveal their limitations on this challenging task. We further analyze whether auxiliary information is crucial for monocular spatial reasoning and offer practical guidance for designing future models. These contributions collectively establish a foundation for advancing monocular spatial reasoning in real-world, open-world environments.
