---
layout: default
title: "[4.5]Cross-Level Sensor Fusion with Object Lists via Transformer for 3D Object Detection"
---

# [4.5] Cross-Level Sensor Fusion with Object Lists via Transformer for 3D Object Detection

- Authors: Xiangzhong Liu, Jiajie Zhang, Hao Shen
- [arXiv Link](https://arxiv.org/abs/2512.12884)
- [PDF Link](https://arxiv.org/pdf/2512.12884.pdf)

## Subfields
 多传感器融合 (Sensor Fusion) / 3D 目标检测
## Reason for Interest

该论文提出了一种将稀疏Object List（如V2X或智能传感器输出）与相机图像特征进行'跨层融合'的方法，通过将物体列表编码为Query输入Transformer。虽然选题具有针对性（面向V2X/黑盒传感器），但实验结果暴露了严重缺陷：
1. 性能倒退：Table IV显示，当使用高性能检测器（CenterPoint, NDS 0.652）作为输入源时，融合后的性能反而大幅下降至NDS 0.531。这意味着融合机制未能保留强模态的信息，反而被较弱的视觉特征（基线NDS 0.40）拖累。
2. 对比误导：论文主要强调相比'纯视觉基线'的提升，而回避了相比'输入物体列表'的性能变化。如果融合后的结果不如直接使用输入列表，该融合在工程上缺乏价值。
3. 数据集局限：虽然宣称面向V2X，但仅在nuScenes上通过人工加噪模拟Object List，且未充分利用现有的真实V2X数据集进行验证。
综上，尽管概念尚可，但核心实验结果表明方法存在明显缺陷，难以实际应用。
## Abstract: 
In automotive sensor fusion systems, smart sensors and Vehicle-to-Everything (V2X) modules are commonly utilized. Sensor data from these systems are typically available only as processed object lists rather than raw sensor data from traditional sensors. Instead of processing other raw data separately and then fusing them at the object level, we propose an end-to-end cross-level fusion concept with Transformer, which integrates highly abstract object list information with raw camera images for 3D object detection. Object lists are fed into a Transformer as denoising queries and propagated together with learnable queries through the latter feature aggregation process. Additionally, a deformable Gaussian mask, derived from the positional and size dimensional priors from the object lists, is explicitly integrated into the Transformer decoder. This directs attention toward the target area of interest and accelerates model training convergence. Furthermore, as there is no public dataset containing object lists as a standalone modality, we propose an approach to generate pseudo object lists from ground-truth bounding boxes by simulating state noise and false positives and negatives. As the first work to conduct cross-level fusion, our approach shows substantial performance improvements over the vision-based baseline on the nuScenes dataset. It demonstrates its generalization capability over diverse noise levels of simulated object lists and real detectors.
