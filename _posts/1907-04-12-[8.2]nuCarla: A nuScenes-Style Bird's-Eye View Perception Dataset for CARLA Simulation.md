---
layout: default
title: "[8.2]nuCarla: A nuScenes-Style Bird's-Eye View Perception Dataset for CARLA Simulation"
---

# [8.2] nuCarla: A nuScenes-Style Bird's-Eye View Perception Dataset for CARLA Simulation

- Authors: Zhijie Qiao, Zhong Cao, Henry X. Liu
- [arXiv Link](https://arxiv.org/abs/2511.13744)
- [PDF Link](https://arxiv.org/pdf/2511.13744.pdf)

## Subfields
 自动驾驶仿真 / 数据集 (BEV感知)
## Reason for Interest

该论文主要贡献在于填补了真实世界感知数据集（如nuScenes）与闭环仿真环境（CARLA）之间的鸿沟。1. 实用性强：通过完全对齐nuScenes的数据格式（传感器配置、标注结构、API），使得主流BEV感知模型可以无缝迁移到仿真环境中训练和评估，极大降低了端到端闭环研究的门槛。2. 解决了工程痛点：不仅提供了数据集，还解决了旧版mmdetection3d在现代GPU上的兼容性问题。3. 实验详实：在多个SOTA BEV模型上进行了验证，并针对nuScenes的长尾类别分布不均问题，在仿真数据集中进行了平衡优化（如增加了自行车类别样本）。虽然是数据集类工作，但对于推动端到端自动驾驶的闭环评估具有重要的基础设施价值。
## Abstract: 
End-to-end (E2E) autonomous driving heavily relies on closed-loop simulation, where perception, planning, and control are jointly trained and evaluated in interactive environments. Yet, most existing datasets are collected from the real world under non-interactive conditions, primarily supporting open-loop learning while offering limited value for closed-loop testing. Due to the lack of standardized, large-scale, and thoroughly verified datasets to facilitate learning of meaningful intermediate representations, such as bird's-eye-view (BEV) features, closed-loop E2E models remain far behind even simple rule-based baselines. To address this challenge, we introduce nuCarla, a large-scale, nuScenes-style BEV perception dataset built within the CARLA simulator. nuCarla features (1) full compatibility with the nuScenes format, enabling seamless transfer of real-world perception models; (2) a dataset scale comparable to nuScenes, but with more balanced class distributions; (3) direct usability for closed-loop simulation deployment; and (4) high-performance BEV backbones that achieve state-of-the-art detection results. By providing both data and models as open benchmarks, nuCarla substantially accelerates closed-loop E2E development, paving the way toward reliable and safety-aware research in autonomous driving.
