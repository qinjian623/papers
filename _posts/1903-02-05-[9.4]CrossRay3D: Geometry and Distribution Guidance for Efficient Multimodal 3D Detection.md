---
layout: default
title: "[9.4]CrossRay3D: Geometry and Distribution Guidance for Efficient Multimodal 3D Detection"
---

# [9.4] CrossRay3D: Geometry and Distribution Guidance for Efficient Multimodal 3D Detection

- Authors: Huiming Yang, Wenzhuo Liu, Yicheng Qiao, Lei Yang, Xianzhu Zeng, Li Wang, Zhiwei Li, Ziji...
- [arXiv Link](https://arxiv.org/abs/2510.15991)
- [PDF Link](https://arxiv.org/pdf/2510.15991.pdf)

## Subfields
 多模态3D目标检测 / 稀疏感知 / 融合架构
## Reason for Interest

论文针对稀疏多模态检测器中令牌表示质量次优的问题，提出了CrossRay3D，一个端到端的稀疏多模态检测器。其核心创新点在于：
1. **稀疏选择器 (Sparse Selector, SS)**：结合射线感知监督 (Ray-Aware Supervision, RAS) 和类别平衡监督 (Class-Balanced Supervision, CBS)，从几何结构和类别分布两个维度提升令牌采样质量。RAS通过射线与真值框的交点来保留丰富的几何信息，CBS则根据真值类别分布自适应地调整令牌权重，确保小物体令牌不被忽略。
2. **射线位置编码 (Ray Positional Encoding, Ray PE)**：引入Ray PE来解决LiDAR和图像模态之间的数据分布差异，促进跨模态特征的对齐和融合。

**创新性**：RAS、CBS和Ray PE的提出具有较强的创新性，有效解决了稀疏检测器中关键的令牌质量和多模态对齐问题，为高效的多模态融合提供了新思路。

**实验完整性**：论文在nuScenes和Argoverse 2两个主流自动驾驶数据集上进行了广泛的实验。包含了与大量SOTA方法的性能比较（包括密集和稀疏检测器，以及单模态基线），详细的消融研究验证了每个组件（RAS、CBS、Ray PE）的有效性。此外，还探讨了稀疏度（keeping ratio p）对性能和计算资源的影响，并验证了方法在传感器故障情况下的鲁棒性和通用性，实验结果非常全面和深入。

**可信度**：性能提升显著且有充分数据支持，尤其是在提高效率（更快的推理速度和更低的内存消耗）的同时保持或超越SOTA性能，对自动驾驶落地具有重要意义。速度对比在特定硬件（RTX 3090 GPU）和批处理大小（1）下进行，符合标准实践。虽然“比其他领先方法快1.84倍”的具体数值主要体现在base模型对比CMT上，但large模型也显著更快，整体结论可靠。

**行业潜力**：该方法通过稀疏表示和高效融合，显著降低了计算成本和内存占用，同时保持高精度和鲁棒性。这对于自动驾驶车辆在边缘设备上部署复杂的感知模型至关重要，具有极高的产业应用价值和落地潜力。其在传感器部分缺失时的鲁棒性也进一步提升了实际部署的可靠性。
## Abstract: 
The sparse cross-modality detector offers more advantages than its counterpart, the Bird's-Eye-View (BEV) detector, particularly in terms of adaptability for downstream tasks and computational cost savings. However, existing sparse detectors overlook the quality of token representation, leaving it with a sub-optimal foreground quality and limited performance. In this paper, we identify that the geometric structure preserved and the class distribution are the key to improving the performance of the sparse detector, and propose a Sparse Selector (SS). The core module of SS is Ray-Aware Supervision (RAS), which preserves rich geometric information during the training stage, and Class-Balanced Supervision, which adaptively reweights the salience of class semantics, ensuring that tokens associated with small objects are retained during token sampling. Thereby, outperforming other sparse multi-modal detectors in the representation of tokens. Additionally, we design Ray Positional Encoding (Ray PE) to address the distribution differences between the LiDAR modality and the image. Finally, we integrate the aforementioned module into an end-to-end sparse multi-modality detector, dubbed CrossRay3D. Experiments show that, on the challenging nuScenes benchmark, CrossRay3D achieves state-of-the-art performance with 72.4 mAP and 74.7 NDS, while running 1.84 faster than other leading methods. Moreover, CrossRay3D demonstrates strong robustness even in scenarios where LiDAR or camera data are partially or entirely missing.
