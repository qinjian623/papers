---
layout: default
title: "[2.5]Comparative Analysis of Deep Learning Models for Perception in Autonomous Vehicles"
---

# [2.5] Comparative Analysis of Deep Learning Models for Perception in Autonomous Vehicles

- Authors: Jalal Khan
- [arXiv Link](https://arxiv.org/abs/2512.21673)
- [PDF Link](https://arxiv.org/pdf/2512.21673.pdf)

## Subfields
 2D Perception / Object Detection
## Reason for Interest

该论文属于基础的应用对比报告，缺乏实质性的算法创新。1. 实验完整性严重不足：仅使用了包含1000张图像的私有数据集，未在nuScenes、Waymo或COCO等自动驾驶主流基准上进行验证，结果缺乏通用性和说服力。2. 技术深度浅：仅对比了两个现成的检测模型（YOLOv8与YOLO-NAS），未涉及多模态融合、时序处理或3D感知等前沿问题。3. 分析维度单一：主要关注简单的mAP和训练时间，缺乏对长尾场景、鲁棒性或实际推理延迟的深入探讨。整体来看，该工作更接近于课程作业而非具备行业影响力的研究成果。
## Abstract: 
Recently, a plethora of machine learning (ML) and deep learning (DL) algorithms have been proposed to achieve the efficiency, safety, and reliability of autonomous vehicles (AVs). The AVs use a perception system to detect, localize, and identify other vehicles, pedestrians, and road signs to perform safe navigation and decision-making. In this paper, we compare the performance of DL models, including YOLO-NAS and YOLOv8, for a detection-based perception task. We capture a custom dataset and experiment with both DL models using our custom dataset. Our analysis reveals that the YOLOv8s model saves 75% of training time compared to the YOLO-NAS model. In addition, the YOLOv8s model (83%) outperforms the YOLO-NAS model (81%) when the target is to achieve the highest object detection accuracy. These comparative analyses of these new emerging DL models will allow the relevant research community to understand the models' performance under real-world use case scenarios.
