---
layout: default
title: "[8.9]LiDAR-VGGT: Cross-Modal Coarse-to-Fine Fusion for Globally Consistent and Metric-Scale Dense Mapping"
---

# [8.9] LiDAR-VGGT: Cross-Modal Coarse-to-Fine Fusion for Globally Consistent and Metric-Scale Dense Mapping

- Authors: Lijie Wang, Lianjie Guo, Ziyi Xu, Qianhao Wang, Fei Gao, Xieyuanli Chen
- [arXiv Link](https://arxiv.org/abs/2511.01186)
- [PDF Link](https://arxiv.org/pdf/2511.01186.pdf)

## Subfields
 高精地图构建 / 多传感器融合 / 3D重建
## Reason for Interest

该论文提出了 LiDAR-VGGT，一个创新性的粗到细两阶段融合框架，旨在解决激光雷达（LiDAR）稀疏性与VGGT模型（Visual Geometry Grounded Transformer）缺乏度量尺度和可扩展性的问题，以实现大规模、密集、度量准确且全局一致的彩色点云重建。其创新性体现在：1) 首次将LiDAR与VGGT紧密耦合，实现了两者优势互补；2) 设计了新颖的预融合模块，包含线性度验证和尺度感知RANSAC，用于鲁棒的初始化和尺度粗校准；3) 引入了带边界框正则化的跨模态Sim(3)配准方法，有效解决相机和LiDAR视场（FOV）差异导致的尺度漂移问题，提升配准稳定性；4) 提出了新的彩色点云评估工具包，填补了该领域评估方法不足的空白。在实验完整性方面，论文在MARS-LVIG、FAST-LIVO2、MUN_FRL等多个公开数据集以及自采集数据集上进行了广泛而彻底的验证，评估了几何精度和色彩质量，并与VGGT-Long、VGGT-SLAM、SLAM3R和FAST-LIVO2等多个强劲基线进行了全面比较。消融实验和鲁棒性分析也充分证明了所提方法的有效性和对外部噪声的鲁棒性。结果可信度高，数据和可视化证据支持了其优异性能的主张。从行业潜力来看，生成大规模、高密度、度量准确且全局一致的彩色点云是自动驾驶高精地图构建、定位和环境理解的关键技术，该方法直接解决了现有技术在这些方面的痛点，尤其是在对传感器校准和同步要求降低的情况下仍能保持高性能，这对于自动驾驶的实际部署具有重要价值。鉴于其高度的创新性、扎实的实验验证以及对自动驾驶核心需求的高度相关性，给予高分。
## Abstract: 
Reconstructing large-scale colored point clouds is an important task in robotics, supporting perception, navigation, and scene understanding. Despite advances in LiDAR inertial visual odometry (LIVO), its performance remains highly sensitive to extrinsic calibration. Meanwhile, 3D vision foundation models, such as VGGT, suffer from limited scalability in large environments and inherently lack metric scale. To overcome these limitations, we propose LiDAR-VGGT, a novel framework that tightly couples LiDAR inertial odometry with the state-of-the-art VGGT model through a two-stage coarse- to-fine fusion pipeline: First, a pre-fusion module with robust initialization refinement efficiently estimates VGGT poses and point clouds with coarse metric scale within each session. Then, a post-fusion module enhances cross-modal 3D similarity transformation, using bounding-box-based regularization to reduce scale distortions caused by inconsistent FOVs between LiDAR and camera sensors. Extensive experiments across multiple datasets demonstrate that LiDAR-VGGT achieves dense, globally consistent colored point clouds and outperforms both VGGT-based methods and LIVO baselines. The implementation of our proposed novel color point cloud evaluation toolkit will be released as open source.
