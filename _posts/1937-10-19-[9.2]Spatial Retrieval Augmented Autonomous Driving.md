---
layout: default
title: "[9.2]Spatial Retrieval Augmented Autonomous Driving"
---

# [9.2] Spatial Retrieval Augmented Autonomous Driving

- Authors: Xiaosong Jia, Chenhe Zhang, Yule Jiang, Songbur Wong, Zhiyuan Zhang, Chen Chen, Shaofeng ...
- [arXiv Link](https://arxiv.org/abs/2512.06865v1)
- [PDF Link](https://arxiv.org/pdf/2512.06865v1.pdf)

## Subfields
 多模态感知 / 端到端规划 / 世界模型 (Multi-modal Perception / End-to-End Planning / World Models)
## Reason for Interest

1. 创新性高：提出'空间检索增强'（Spatial Retrieval Augmented）范式，利用离线获取的地理图像（如Google Street View）作为额外模态，突破了车载传感器视距和遮挡的物理限制，思路新颖且符合人类驾驶直觉。
2. 实验极其完整：在五个核心自动驾驶任务（3D检测、在线建图、占用栅格预测、端到端规划、生成式世界模型）上进行了验证，证明了方法的通用性。
3. 技术方案扎实：设计了即插即用的Spatial Retrieval Adapter，并专门提出了Reliability Estimation Gate机制来解决离线地图数据可能存在的过时或未对齐问题，工程落地考量成熟。
4. 结果显著：特别是在依赖静态环境理解的任务（如建图）上取得了巨大的性能提升（mAP提升近10个点），在长尾场景（夜间、恶劣天气）下的规划安全性也有明显改善。
5. 数据贡献：构建并承诺开源nuScenes-Geography数据集，对行业研究有较高价值。
## Abstract: 
  For experiments, we first extend the nuScenes dataset with geographic images retrieved via Google Maps APIs and align the new data with ego-vehicle trajectories. We establish baselines across five core autonomous driving tasks: object detection, online mapping, occupancy prediction, end-to-end planning, and generative world modeling. Extensive experiments show that the extended modality could enhance the performance of certain tasks. We will open-source dataset curation code, data, and benchmarks for further study of this new autonomous driving paradigm.
