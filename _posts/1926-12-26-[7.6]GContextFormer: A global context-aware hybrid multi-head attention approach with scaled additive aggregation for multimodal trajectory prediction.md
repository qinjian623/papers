---
layout: default
title: "[7.6]GContextFormer: A global context-aware hybrid multi-head attention approach with scaled additive aggregation for multimodal trajectory prediction"
---

# [7.6] GContextFormer: A global context-aware hybrid multi-head attention approach with scaled additive aggregation for multimodal trajectory prediction

- Authors: Yuzhi Chen, Yuanchang Xie, Lei Zhao, Pan Liu, Yajie Zou, Chen Wang
- [arXiv Link](https://arxiv.org/abs/2511.18874v1)
- [PDF Link](https://arxiv.org/pdf/2511.18874v1.pdf)

## Subfields
 轨迹预测 / 无地图 (Map-free) 轨迹预测
## Reason for Interest

论文针对无高清地图依赖的轨迹预测任务，提出了一种结合全局意图先验的Encoder和分层交互推理的Decoder架构（GContextFormer）。

1. 创新性：提出了Motion-Aware Encoder (MAE)，利用缩放加性注意力机制聚合全局上下文作为意图先验，解决了无地图方法中常见的意图错位问题；设计了Hierarchical Interaction Decoder (HID)，通过双通路注意力机制平衡了几何覆盖与邻域显著性，不仅考虑了‘谁在周围’，还考虑了‘对哪种运动模式重要’，具有较好的设计逻辑。
2. 实验效果：在TOD-VT高速匝道数据集上，相比于Social-STGCNN、TUTR等现有SOTA模型取得了显著的性能提升（minFDE提升约16%），且消融实验和可视化分析（热力图）详实，验证了模型在非线性路段（如匝道合并/分流）的优势。
3. 局限性：实验主要集中在高速匝道场景（TOD-VT），未在Argoverse 2或nuScenes等更通用的城市复杂场景基准数据集上进行验证，其在高度异构的城市环境中的泛化能力尚待证明。但作为针对特定高风险场景（匝道）的无地图方案，具有较高的应用价值。
## Abstract: 

