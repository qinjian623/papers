---
layout: default
title: "[8.5]Ethics-Aware Safe Reinforcement Learning for Rare-Event Risk Control in Interactive Urban Driving"
---

# [8.5] Ethics-Aware Safe Reinforcement Learning for Rare-Event Risk Control in Interactive Urban Driving

- Authors: Dianzhao Li, Ostap Okhrin
- [arXiv Link](https://arxiv.org/abs/2508.14926)
- [PDF Link](https://arxiv.org/pdf/2508.14926.pdf)

## Subfields
 规划控制 / 安全强化学习 / 伦理决策
## Reason for Interest

这篇论文的创新点在于提出了一个伦理感知的安全强化学习（Safe RL）框架EthicAR，它将伦理考量作为设计核心，而不是事后添加。主要创新包括：1）结合碰撞概率和伤害严重性构建了复合伦理风险成本信号，在Safe RL中平衡自我安全与对其他道路使用者的公平性。2）引入了动态优先级经验回放（Dynamic PER），以提高对稀有但关键的高风险事件的学习效率。3）提出了分层控制架构，将高层决策（Safe RL）与低层执行（经典控制器）分离。这些创新点在自动驾驶领域具有重要的理论和实践意义。

实验部分在基于Waymo Open Dataset构建的闭环仿真环境中进行了充分验证，涵盖了多种车辆、自行车和行人的真实世界交通场景。通过与多个基线方法（如不带PER的EthicAR、标准SACLag、LSTMSAC）进行对比，验证了EthicAR在降低冲突频率、提高安全合规性和优化风险分布方面的优越性。消融研究清晰地证明了LSTM架构和Dynamic PER在处理稀疏成本信号和促进伦理行为学习中的关键作用。结果可信度高，且代码已开源，支持复现。

行业潜力方面，该论文旨在解决自动驾驶系统在复杂城市交通环境中面临的伦理决策难题，特别是在保护弱势道路使用者（VRUs）方面。这对于提高自动驾驶系统的社会接受度和可靠性至关重要。将伦理考量融入规划控制，是未来自动驾驶落地不可或缺的一环。论文强调了结合形式化控制理论和数据驱动学习在伦理自动驾驶方面的潜力，为该领域的研究和发展提供了重要的方向。特别是在AVs与人类驾驶车辆共存的过渡时期，其提出的伦理决策能力对于提升公共安全和信任具有深远意义。该研究成果对自动驾驶规划与控制，尤其是涉及多智能体交互的决策制定，具有直接的指导价值和广阔的应用前景。
## Abstract: 
Autonomous vehicles hold great promise for reducing traffic fatalities and improving transportation efficiency, yet their widespread adoption hinges on embedding credible and transparent ethical reasoning into routine and emergency maneuvers, particularly to protect vulnerable road users (VRUs) such as pedestrians and cyclists. Here, we present a hierarchical Safe Reinforcement Learning (Safe RL) framework that augments standard driving objectives with ethics-aware cost signals. At the decision level, a Safe RL agent is trained using a composite ethical risk cost, combining collision probability and harm severity, to generate high-level motion targets. A dynamic, risk-sensitive Prioritized Experience Replay mechanism amplifies learning from rare but critical, high-risk events. At the execution level, polynomial path planning coupled with Proportional-Integral-Derivative (PID) and Stanley controllers translates these targets into smooth, feasible trajectories, ensuring both accuracy and comfort. We train and validate our approach on closed-loop simulation environments derived from large-scale, real-world traffic datasets encompassing diverse vehicles, cyclists, and pedestrians, and demonstrate that it outperforms baseline methods in reducing risk to others while maintaining ego performance and comfort. This work provides a reproducible benchmark for Safe RL with explicitly ethics-aware objectives in human-mixed traffic scenarios. Our results highlight the potential of combining formal control theory and data-driven learning to advance ethically accountable autonomy that explicitly protects those most at risk in urban traffic environments. Across two interactive benchmarks and five random seeds, our policy decreases conflict frequency by 25-45% compared to matched task successes while maintaining comfort metrics within 5%.
