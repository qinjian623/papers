---
layout: default
title: "[5.0]Generative Semantic Coding for Ultra-Low Bitrate Visual Communication and Analysis"
---

# [5.0] Generative Semantic Coding for Ultra-Low Bitrate Visual Communication and Analysis

- Authors: Weiming Chen, Yijia Wang, Zhihan Zhu, Zhihai He
- [arXiv Link](https://arxiv.org/abs/2510.27324)
- [PDF Link](https://arxiv.org/pdf/2510.27324.pdf)

## Subfields
 语义通信 / 超低比特率视觉编码 (应用于机器人导航与自动驾驶辅助)
## Reason for Interest

该论文提出了一个名为GSC（Generative Semantic Coding）的创新框架，旨在解决在极其有限的带宽（远低于0.01 bpp）下进行视觉通信和分析的问题。其核心思想是结合图像生成和深度图像压缩，利用语义文本描述和少量编码潜变量来引导生成模型，以精确重建视觉场景，并特别优化下游视觉任务（而非仅仅像素级重建）的性能。

创新性强：在超低比特率下，通过联合文本语义信息和动态选择的结构潜变量（仅需极少比特），实现高质量视觉重建和下游任务性能，这一范式在现有工作中具有显著创新性。特别是在如此低的比特率下保持结构一致性，是一大亮点。

实验完整性高：论文在多个主流数据集（KITTI、Cityscapes、COCO2017等自动驾驶相关数据集以及Hypersim、Kodak等通用数据集）上进行了全面且严格的评估。涵盖了深度估计、语义分割、目标检测等关键的自动驾驶感知任务，并与当前最先进的超低比特率压缩方法进行了详细对比。消融研究也充分验证了方法各组件的有效性。

结果可信度高：实验结果一致表明，GSC方法能够在比现有超低比特率方法少一个数量级甚至更多的带宽消耗下，保持或超越这些方法的视觉分析性能。例如，在KITTI数据集上，GSC在0.0069 bpp下达到了比PICS（0.0235 bpp）和MS-ILLM350（0.0539 bpp）更好的深度估计性能。定性结果也支持了其在细节保持上的优势。

行业潜力：该方法虽然不直接是车端自动驾驶的感知、规划或控制模块，但其解决的“超低带宽视觉通信和分析”问题对于自动驾驶系统在特定场景下（如远程遥控、恶劣通信环境下的V2X数据传输、日志回传、或应用于太空探索机器人等更广义的机器人导航）具有显著的实用价值和潜力。论文多次提及“机器人导航”并使用了大量的自动驾驶主流数据集进行评估，表明其对自动驾驶领域具有重要的间接贡献，可作为自动驾驶系统在通信受限环境下的重要使能技术。考虑到评分规则中“不直接和车端自动驾驶相关，最多5分”的严格限制，尽管其技术创新和实验表现非常出色，但因其主要贡献在于通用视觉通信与压缩，而非直接的自动驾驶栈核心算法，故给出此上限分数5.0分。
## Abstract: 
We consider the problem of ultra-low bit rate visual communication for remote vision analysis, human interactions and control in challenging scenarios with very low communication bandwidth, such as deep space exploration, battlefield intelligence, and robot navigation in complex environments. In this paper, we ask the following important question: can we accurately reconstruct the visual scene using only a very small portion of the bit rate in existing coding methods while not sacrificing the accuracy of vision analysis and performance of human interactions? Existing text-to-image generation models offer a new approach for ultra-low bitrate image description. However, they can only achieve a semantic-level approximation of the visual scene, which is far insufficient for the purpose of visual communication and remote vision analysis and human interactions. To address this important issue, we propose to seamlessly integrate image generation with deep image compression, using joint text and coding latent to guide the rectified flow models for precise generation of the visual scene. The semantic text description and coding latent are both encoded and transmitted to the decoder at a very small bit rate. Experimental results demonstrate that our method can achieve the same image reconstruction quality and vision analysis accuracy as existing methods while using much less bandwidth. The code will be released upon paper acceptance.
