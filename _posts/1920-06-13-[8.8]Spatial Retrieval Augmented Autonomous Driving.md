---
layout: default
title: "[8.8]Spatial Retrieval Augmented Autonomous Driving"
---

# [8.8] Spatial Retrieval Augmented Autonomous Driving

- Authors: Xiaosong Jia, Chenhe Zhang, Yule Jiang, Songbur Wong, Zhiyuan Zhang, Chen Chen, Shaofeng ...
- [arXiv Link](https://arxiv.org/abs/2512.06865)
- [PDF Link](https://arxiv.org/pdf/2512.06865.pdf)

## Subfields
 Perception / End-to-End Autonomous Driving / World Models
## Reason for Interest

论文提出了一种新颖的“空间检索增强”（Spatial Retrieval Augmented）范式，类似于LLM中的RAG，将离线获取的Google Maps街景和卫星图像作为额外的模态输入，解决车载传感器视距受限和遮挡问题。创新性较强，且通用性好，适配了检测、建图、占据栅格、规划和世界模型五个主流任务。实验设计详实，构建了nuScenes-Geography数据集，并在静态场景理解（建图、Occupancy）和生成式任务上取得了显著的性能提升。提出的可靠性门控机制（Reliability Estimation Gate）有效解决了地图数据过时或未对齐的工程痛点，具有较高的行业落地参考价值。
## Abstract: 
Existing autonomous driving systems rely on onboard sensors (cameras, LiDAR, IMU, etc) for environmental perception. However, this paradigm is limited by the drive-time perception horizon and often fails under limited view scope, occlusion or extreme conditions such as darkness and rain. In contrast, human drivers are able to recall road structure even under poor visibility. To endow models with this ``recall" ability, we propose the spatial retrieval paradigm, introducing offline retrieved geographic images as an additional input. These images are easy to obtain from offline caches (e.g, Google Maps or stored autonomous driving datasets) without requiring additional sensors, making it a plug-and-play extension for existing AD tasks.
  For experiments, we first extend the nuScenes dataset with geographic images retrieved via Google Maps APIs and align the new data with ego-vehicle trajectories. We establish baselines across five core autonomous driving tasks: object detection, online mapping, occupancy prediction, end-to-end planning, and generative world modeling. Extensive experiments show that the extended modality could enhance the performance of certain tasks. We will open-source dataset curation code, data, and benchmarks for further study of this new autonomous driving paradigm.
