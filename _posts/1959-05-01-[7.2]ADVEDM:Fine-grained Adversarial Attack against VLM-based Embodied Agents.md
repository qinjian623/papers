---
layout: default
title: "[7.2]ADVEDM:Fine-grained Adversarial Attack against VLM-based Embodied Agents"
---

# [7.2] ADVEDM:Fine-grained Adversarial Attack against VLM-based Embodied Agents

- Authors: Yichen Wang, Hangtao Zhang, Hewen Pan, Ziqi Zhou, Xianlong Wang, Peijin Guo, Lulu Xue, Sh...
- [arXiv Link](https://arxiv.org/abs/2509.16645v1)
- [PDF Link](https://arxiv.org/pdf/2509.16645v1.pdf)

## Subfields
 自动驾驶安全 / VLM端到端规划 / 对抗攻击
## Reason for Interest

论文探讨了基于视觉语言模型（VLM）的自动驾驶系统的安全性问题，属于当前大模型上车的热点方向。提出了一种基于灰盒设置的细粒度对抗攻击框架（AdvEDM），通过操控特定对象的语义（移除或添加）同时保留全局上下文，诱导系统输出看似合理但错误的驾驶决策。实验在专门的自动驾驶VLM数据集（Dolphins, DriveLM）上验证了其有效性，攻击成功率显著优于传统方法。虽然目前仍主要局限于数字域攻击（需注入图像流），物理世界部署能力（如对抗补丁）尚待探索（文中Limitation已提及），但该研究对揭示端到端大模型驾驶系统的安全隐患具有重要的学术价值和参考意义。
## Abstract: 

