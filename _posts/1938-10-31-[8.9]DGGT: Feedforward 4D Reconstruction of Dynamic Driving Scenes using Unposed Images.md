---
layout: default
title: "[8.9]DGGT: Feedforward 4D Reconstruction of Dynamic Driving Scenes using Unposed Images"
---

# [8.9] DGGT: Feedforward 4D Reconstruction of Dynamic Driving Scenes using Unposed Images

- Authors: Xiaoxue Chen, Ziyi Xiong, Yuantao Chen, Gen Li, Nan Wang, Hongcheng Luo, Long Chen, Haiya...
- [arXiv Link](https://arxiv.org/abs/2512.03004v1)
- [PDF Link](https://arxiv.org/pdf/2512.03004v1.pdf)

## Subfields
 自动驾驶仿真 / 4D动态场景重建 (Autonomous Driving Simulation / 4D Scene Reconstruction)
## Reason for Interest

1. **高行业价值与创新性**：论文切中了自动驾驶数据闭环中的核心痛点——大规模数据的仿真重建。提出了一种无需预先计算相机位姿（Pose-free）的Feedforward 4D重建框架，彻底摆脱了传统方法对COLMAP等耗时位姿优化的依赖，极大提升了从海量行车日志构建世界模型的效率。
2. **架构设计完善**：通过Joint预测相机参数、3D高斯、动态Mask、3D运动场及天空模型，并引入Lifespan参数解决时序一致性，设计精巧且完备。引入单步扩散模型（Diffusion Refinement）进一步提升了稀疏视角下的渲染质量。
3. **实验结果扎实**：在Waymo主数据集上取得了SOTA的重建质量，且在nuScenes和Argoverse2上展现了极强的跨域泛化能力。3D运动估计指标（EPE3D）也优于专门的场景流方法。
4. **速度优势**：实现单场景（3视角x20帧）仅需0.39秒的推理速度，支持快速规模化应用。
综合来看，这是一篇在自动驾驶仿真与数据生成领域具有SOTA水平和极高落地潜力的优质论文。
## Abstract: 

