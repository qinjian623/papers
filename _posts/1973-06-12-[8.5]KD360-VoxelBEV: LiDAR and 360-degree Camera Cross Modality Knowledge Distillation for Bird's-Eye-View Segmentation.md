---
layout: default
title: "[8.5]KD360-VoxelBEV: LiDAR and 360-degree Camera Cross Modality Knowledge Distillation for Bird's-Eye-View Segmentation"
---

# [8.5] KD360-VoxelBEV: LiDAR and 360-degree Camera Cross Modality Knowledge Distillation for Bird's-Eye-View Segmentation

- Authors: Wenke E, Yixin Sun, Jiaxu Liu, Hubert P. H. Shum, Amir Atapour-Abarghouei, Toby P. Brecko...
- [arXiv Link](https://arxiv.org/abs/2512.15311)
- [PDF Link](https://arxiv.org/pdf/2512.15311.pdf)

## Subfields
 BEV Perception / Semantic Segmentation (360Â° Camera)
## Reason for Interest

The paper presents a practical and effective cross-modality distillation framework (KD360-VoxelBEV) specifically designed for single panoramic camera BEV segmentation. Key contributions include a voxel-aligned view transformer that preserves geometric fidelity from LiDAR during training and a Soft-Gated Fusion Module. The method significantly outperforms existing baselines (by ~8.5-10% IoU) on Dur360BEV and KITTI-360 while maintaining real-time inference speeds (31.2 FPS), offering a high-value solution for low-cost autonomous driving sensing.
## Abstract: 
We present the first cross-modality distillation framework specifically tailored for single-panoramic-camera Bird's-Eye-View (BEV) segmentation. Our approach leverages a novel LiDAR image representation fused from range, intensity and ambient channels, together with a voxel-aligned view transformer that preserves spatial fidelity while enabling efficient BEV processing. During training, a high-capacity LiDAR and camera fusion Teacher network extracts both rich spatial and semantic features for cross-modality knowledge distillation into a lightweight Student network that relies solely on a single 360-degree panoramic camera image. Extensive experiments on the Dur360BEV dataset demonstrate that our teacher model significantly outperforms existing camera-based BEV segmentation methods, achieving a 25.6\% IoU improvement. Meanwhile, the distilled Student network attains competitive performance with an 8.5\% IoU gain and state-of-the-art inference speed of 31.2 FPS. Moreover, evaluations on KITTI-360 (two fisheye cameras) confirm that our distillation framework generalises to diverse camera setups, underscoring its feasibility and robustness. This approach reduces sensor complexity and deployment costs while providing a practical solution for efficient, low-cost BEV segmentation in real-world autonomous driving.
