---
layout: default
title: "[8.8]Rethinking the Spatio-Temporal Alignment of End-to-End 3D Perception"
---

# [8.8] Rethinking the Spatio-Temporal Alignment of End-to-End 3D Perception

- Authors: Xiaoyu Li, Peidong Li, Xian Wu, Long Shi, Dedong Liu, Yitao Wu, Jiajia Fu, Dixiao Cui, Li...
- [arXiv Link](https://arxiv.org/abs/2512.23635)
- [PDF Link](https://arxiv.org/pdf/2512.23635.pdf)

## Subfields
 端到端自动驾驶 / 3D时序感知与跟踪
## Reason for Interest

该论文针对端到端感知中的时空对齐（STA）问题，提出了一种结合显式运动模型（CV, CTRV等）与隐式特征学习的混合模块HAT。创新性在于将传统的多模型交互（IMM）思想引入Transformer架构，通过自适应加权解决单一运动假设的局限。实验非常扎实，在3D检测、跟踪（Sparse4D, StreamPETR）及端到端规划（SparseDrive, DiffusionDrive）等多个主流基线上均实现了即插即用的提升，尤其是对规划安全性（大幅降低碰撞率）和鲁棒性（nuScenes-C）的改善具有显著的实战价值。代码已开源，工作完整度高。
## Abstract: 
Spatio-temporal alignment is crucial for temporal modeling of end-to-end (E2E) perception in autonomous driving (AD), providing valuable structural and textural prior information. Existing methods typically rely on the attention mechanism to align objects across frames, simplifying the motion model with a unified explicit physical model (constant velocity, etc.). These approaches prefer semantic features for implicit alignment, challenging the importance of explicit motion modeling in the traditional perception paradigm. However, variations in motion states and object features across categories and frames render this alignment suboptimal. To address this, we propose HAT, a spatio-temporal alignment module that allows each object to adaptively decode the optimal alignment proposal from multiple hypotheses without direct supervision. Specifically, HAT first utilizes multiple explicit motion models to generate spatial anchors and motion-aware feature proposals for historical instances. It then performs multi-hypothesis decoding by incorporating semantic and motion cues embedded in cached object queries, ultimately providing the optimal alignment proposal for the target frame. On nuScenes, HAT consistently improves 3D temporal detectors and trackers across diverse baselines. It achieves state-of-the-art tracking results with 46.0% AMOTA on the test set when paired with the DETR3D detector. In an object-centric E2E AD method, HAT enhances perception accuracy (+1.3% mAP, +3.1% AMOTA) and reduces the collision rate by 32%. When semantics are corrupted (nuScenes-C), the enhancement of motion modeling by HAT enables more robust perception and planning in the E2E AD.
