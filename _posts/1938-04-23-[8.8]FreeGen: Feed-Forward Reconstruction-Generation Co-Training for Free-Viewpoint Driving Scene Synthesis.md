---
layout: default
title: "[8.8]FreeGen: Feed-Forward Reconstruction-Generation Co-Training for Free-Viewpoint Driving Scene Synthesis"
---

# [8.8] FreeGen: Feed-Forward Reconstruction-Generation Co-Training for Free-Viewpoint Driving Scene Synthesis

- Authors: Shijie Chen, Peixi Peng
- [arXiv Link](https://arxiv.org/abs/2512.04830v1)
- [PDF Link](https://arxiv.org/pdf/2512.04830v1.pdf)

## Subfields
 自动驾驶仿真 / 神经渲染与场景生成
## Reason for Interest

该论文提出了一种创新的前馈式重建-生成协同训练框架（FreeGen），巧妙结合了 3D Gaussian Splatting 的几何稳定性和视频扩散模型的生成能力。核心创新在于：1) 摆脱了对 LiDAR 点云和昂贵 3D 标注的依赖，仅使用图像即可训练；2) 实现了前馈推理（Feed-forward），无需耗时的逐场景优化，极大地提升了大规模场景生成的扩展性；3) 设计了闭环协同训练策略，使重建和生成模块互为监督，显著提升了非轨迹视角（Off-trajectory）的渲染质量。实验数据表明，其在视频时序一致性（FVD）上取得了突破性进展，对于构建可扩展的自动驾驶世界模型具有重要价值。
## Abstract: 

