---
layout: default
title: "[4.6]Multi-modal On-Device Learning for Monocular Depth Estimation on Ultra-low-power MCUs"
---

# [4.6] Multi-modal On-Device Learning for Monocular Depth Estimation on Ultra-low-power MCUs

- Authors: Davide Nadalini, Manuele Rusci, Elia Cereda, Luca Benini, Francesco Conti, Daniele Paloss...
- [arXiv Link](https://arxiv.org/abs/2512.00086)
- [PDF Link](https://arxiv.org/pdf/2512.00086.pdf)

## Subfields
 嵌入式感知 / 单目深度估计
## Reason for Interest

论文提出了一种在超低功耗MCU（如GAP9）上进行单目深度估计的端侧学习（On-Device Learning）框架，利用低分辨率ToF传感器（8x8像素）生成伪标签，并采用稀疏反向传播策略在极低内存预算下微调模型，有效缓解了微型模型的域漂移问题。尽管该工作在嵌入式AI和微型机器人（如纳米无人机）领域创新性较强且实验扎实，但其针对的硬件算力级别（毫瓦级、KB级内存）与车载自动驾驶的高性能计算平台（Orin等）存在巨大差异，所提出的内存极致优化技术对车端感知系统的借鉴意义有限，不属于车端自动驾驶的核心研究范畴，因此依据相关性规则给予评分限制。
## Abstract: 
Monocular depth estimation (MDE) plays a crucial role in enabling spatially-aware applications in Ultra-low-power (ULP) Internet-of-Things (IoT) platforms. However, the limited number of parameters of Deep Neural Networks for the MDE task, designed for IoT nodes, results in severe accuracy drops when the sensor data observed in the field shifts significantly from the training dataset. To address this domain shift problem, we present a multi-modal On-Device Learning (ODL) technique, deployed on an IoT device integrating a Greenwaves GAP9 MicroController Unit (MCU), a 80 mW monocular camera and a 8 x 8 pixel depth sensor, consuming $\approx$300mW. In its normal operation, this setup feeds a tiny 107 k-parameter $\mu$PyD-Net model with monocular images for inference. The depth sensor, usually deactivated to minimize energy consumption, is only activated alongside the camera to collect pseudo-labels when the system is placed in a new environment. Then, the fine-tuning task is performed entirely on the MCU, using the new data. To optimize our backpropagation-based on-device training, we introduce a novel memory-driven sparse update scheme, which minimizes the fine-tuning memory to 1.2 MB, 2.2x less than a full update, while preserving accuracy (i.e., only 2% and 1.5% drops on the KITTI and NYUv2 datasets). Our in-field tests demonstrate, for the first time, that ODL for MDE can be performed in 17.8 minutes on the IoT node, reducing the root mean squared error from 4.9 to 0.6m with only 3 k self-labeled samples, collected in a real-life deployment scenario.
