---
layout: default
title: "[7.5]Driving Through Uncertainty: Risk-Averse Control with LLM Commonsense for Autonomous Driving under Perception Deficits"
---

# [7.5] Driving Through Uncertainty: Risk-Averse Control with LLM Commonsense for Autonomous Driving under Perception Deficits

- Authors: Yuting Hu, Chenhui Xu, Ruiyang Qin, Dancheng Liu, Amir Nassereldine, Yiyu Shi, Jinjun Xio...
- [arXiv Link](https://arxiv.org/abs/2503.07020)
- [PDF Link](https://arxiv.org/pdf/2503.07020.pdf)

## Subfields
 自动驾驶安全 / 基于 LLM 的规划与控制 (Safety & Robustness / LLM-based Planning & Control)
## Reason for Interest

该论文针对自动驾驶中的长尾安全问题——部分感知失效（如传感器故障或遮挡），提出了一种利用多模态大模型（LLM）常识推理的风险规避控制框架（LLM-RCO）。

主要优点包括：
1. 创新性：提出了利用 LLM 进行危险推断（Hazard Inference）和短时运动规划的模块化框架，并设计了行动条件验证器（Action Condition Verifier）来平衡大模型的推理延迟与实时控制需求，思路新颖且具有实际意义。
2. 完整性：构建了包含 53,895 个视频片段的 DriveLM-Deficit 数据集用于微调，实验设计包含了不同类型的感知缺失（红绿灯、停车标志、行人等），并在 CARLA 仿真器中进行了闭环验证，包含消融实验。
3. 可信度：除了常规指标，还引入了包含推理时间限制的评估（Table 2），增加了结果的工程可信度。

主要扣分点与局限性：
1. 基线选择稍显陈旧：论文（2025年预印本）选用的基线模型 TransFuser (CVPR 2021) 和 InterFuser (CoRL 2022) 并非当下的最强 SOTA（如 2023-2024 年的 VAD, DriveMLM 等），削弱了其在现代端到端自动驾驶语境下的竞争力说服力。
2. 场景局限：主要依赖人工 Masking（遮罩）来模拟感知缺失，虽然有效但与真实的传感器噪声或攻击特征可能存在差异。

综上，这是一篇在特定细分领域（鲁棒性与安全降级策略）具有较高价值的论文，评分 7.5。
## Abstract: 
Partial perception deficits can compromise autonomous vehicle safety by disrupting environmental understanding. Existing protocols typically default to entirely risk-avoidant actions such as immediate stops, which are detrimental to navigation goals and lack flexibility for rare driving scenarios. Yet, in cases of minor risk, halting the vehicle may be unnecessary, and more adaptive responses are preferable. In this paper, we propose LLM-RCO, a risk-averse framework leveraging large language models (LLMs) to integrate human-like driving commonsense into autonomous systems facing perception deficits. LLM-RCO features four key modules interacting with the dynamic driving environment: hazard inference, short-term motion planner, action condition verifier, and safety constraint generator, enabling proactive and context-aware actions in such challenging conditions. To enhance the driving decision-making of LLMs, we construct DriveLM-Deficit, a dataset of 53,895 video clips featuring deficits of safety-critical objects, annotated for LLM fine-tuning in hazard detection and motion planning. Extensive experiments in adverse driving conditions with the CARLA simulator demonstrate that LLM-RCO promotes proactive maneuvers over purely risk-averse actions in perception deficit scenarios, underscoring its value for boosting autonomous driving resilience against perception loss challenges.
