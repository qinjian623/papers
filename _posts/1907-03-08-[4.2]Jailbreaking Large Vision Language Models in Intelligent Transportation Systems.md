---
layout: default
title: "[4.2]Jailbreaking Large Vision Language Models in Intelligent Transportation Systems"
---

# [4.2] Jailbreaking Large Vision Language Models in Intelligent Transportation Systems

- Authors: Badhan Chandra Das, Md Tasnim Jawad, Md Jueal Mia, M. Hadi Amini, Yanzhao Wu
- [arXiv Link](https://arxiv.org/abs/2511.13892)
- [PDF Link](https://arxiv.org/pdf/2511.13892.pdf)

## Subfields
 AI Security / VLM Robustness (Smart Cockpit)
## Reason for Interest

论文针对应用于智能交通系统（ITS）的大型视觉语言模型（LVLM）提出了一种基于排版操纵和多轮对话的越狱攻击方法。虽然论文声称与ITS安全相关，但其威胁模型和实验主要集中在‘智能座舱/车载聊天机器人’的内容合规性（如诱导模型输出制造炸弹或非法监视的文本），而非核心的自动驾驶控制或感知安全（如导致车辆碰撞）。攻击需要多轮对话交互，难以应用于实时行车控制场景。技术上组合了已知攻击手段，且实验仅在自建小规模数据集上进行。由于其与车端自动驾驶核心任务（感知、规划、控制）的直接关联度较低，依据评分标准限制在5分以下。
## Abstract: 
Large Vision Language Models (LVLMs) demonstrate strong capabilities in multimodal reasoning and many real-world applications, such as visual question answering. However, LVLMs are highly vulnerable to jailbreaking attacks. This paper systematically analyzes the vulnerabilities of LVLMs integrated in Intelligent Transportation Systems (ITS) under carefully crafted jailbreaking attacks. First, we carefully construct a dataset with harmful queries relevant to transportation, following OpenAI's prohibited categories to which the LVLMs should not respond. Second, we introduce a novel jailbreaking attack that exploits the vulnerabilities of LVLMs through image typography manipulation and multi-turn prompting. Third, we propose a multi-layered response filtering defense technique to prevent the model from generating inappropriate responses. We perform extensive experiments with the proposed attack and defense on the state-of-the-art LVLMs (both open-source and closed-source). To evaluate the attack method and defense technique, we use GPT-4's judgment to determine the toxicity score of the generated responses, as well as manual verification. Further, we compare our proposed jailbreaking method with existing jailbreaking techniques and highlight severe security risks involved with jailbreaking attacks with image typography manipulation and multi-turn prompting in the LVLMs integrated in ITS.
