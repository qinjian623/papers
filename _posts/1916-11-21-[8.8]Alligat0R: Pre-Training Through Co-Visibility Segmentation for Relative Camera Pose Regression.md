---
layout: default
title: "[8.8]Alligat0R: Pre-Training Through Co-Visibility Segmentation for Relative Camera Pose Regression"
---

# [8.8] Alligat0R: Pre-Training Through Co-Visibility Segmentation for Relative Camera Pose Regression

- Authors: Thibaut Loiseau, Guillaume Bourmaud, Vincent Lepetit
- [arXiv Link](https://arxiv.org/abs/2503.07561)
- [PDF Link](https://arxiv.org/pdf/2503.07561.pdf)

## Subfields
 3D感知 / 位姿估计 / 视觉预训练
## Reason for Interest

该论文针对自动驾驶中常见的双目/多视角几何感知任务，提出了一种名为Alligat0R的新型预训练范式。核心创新在于用'共视性分割'（预测像素是共视、遮挡还是视野外）替代了传统的掩码图像重构（如CroCo），有效解决了在低重叠率区域重构任务不适定（ill-posed）的问题。此外，论文构建了来源于nuScenes和ScanNet的大规模数据集Cub3（500万对图像），不仅验证了方法的有效性，也为行业提供了宝贵的数据资源。实验表明，该方法在极具挑战性的自动驾驶几何配置下（如相机视角差异大、重叠少）表现出极强的鲁棒性，具有很高的实用价值和学术启发性。
## Abstract: 
Pre-training techniques have greatly advanced computer vision, with CroCo's cross-view completion approach yielding impressive results in tasks like 3D reconstruction and pose regression. However, cross-view completion is ill-posed in non-covisible regions, limiting its effectiveness. We introduce Alligat0R, a novel pre-training approach that replaces cross-view learning with a covisibility segmentation task. Our method predicts whether each pixel in one image is covisible in the second image, occluded, or outside the field of view, making the pre-training effective in both covisible and non-covisible regions, and provides interpretable predictions. To support this, we present Cub3, a large-scale dataset with 5M image pairs and dense covisibility annotations derived from the nuScenes and ScanNet datasets. Cub3 includes diverse scenarios with varying degrees of overlap. The experiments show that our novel pre-training method Alligat0R significantly outperforms CroCo in relative pose regression. Code is available at https://github.com/thibautloiseau/alligat0r.
