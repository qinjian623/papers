---
layout: default
title: "[8.5]Self-localization on a 3D map by fusing global and local features from a monocular camera"
---

# [8.5] Self-localization on a 3D map by fusing global and local features from a monocular camera

- Authors: Satoshi Kikuch, Masaya Kato, Tsuyoshi Tasaki
- [arXiv Link](https://arxiv.org/abs/2510.26170v1)
- [PDF Link](https://arxiv.org/pdf/2510.26170v1.pdf)

## Subfields
 视觉定位 / 高精地图定位 (Visual Localization)
## Reason for Interest

该论文针对单目相机在动态环境（如行人、车辆遮挡）下定位精度下降的问题，提出了一种融合 CNN 局部特征和 ViT 全局特征的端到端定位网络。主要亮点包括：1. **方法论合理**：利用 ViT 的全局注意力机制弥补 CNN 在局部纹理被遮挡时的不足，思路清晰且有效。2. **实验极其完整**：不仅在 CARLA 仿真中验证了动态场景的有效性，还在主流公开数据集（KITTI, nuScenes）上与 2024 年的 SOTA 方法（LHMap-loc）进行了对比，更进一步完成了真实机器人的校园场景实测，实现了 7.51cm 的平均定位精度。3. **落地价值高**：单目视觉定位是低成本自动驾驶的关键技术，该研究在保持低成本的同时实现了厘米级定位，具有很高的工业应用潜力。论文被 IROS 2025 接收，可信度高。
## Abstract: 

