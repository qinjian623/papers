---
layout: default
title: "[8.2]Advancing Autonomous Driving: DepthSense with Radar and Spatial Attention"
---

# [8.2] Advancing Autonomous Driving: DepthSense with Radar and Spatial Attention

- Authors: Muhamamd Ishfaq Hussain, Zubia Naz, Muhammad Aasim Rafique, Moongu Jeon
- [arXiv Link](https://arxiv.org/abs/2109.05265)
- [PDF Link](https://arxiv.org/pdf/2109.05265.pdf)

## Subfields
 3D感知 / 多传感器融合 (Camera-Radar) / 深度估计
## Reason for Interest

论文提出了一种基于ResNet和空间注意力机制（Spatial Attention）的相机-雷达融合深度估计网络（DepthSense）。

1. **创新性与实用性**：针对单目深度估计的不适定问题，利用低成本毫米波雷达进行辅助。虽然核心网络组件（ResNet-18, Ordinal Regression）相对成熟，但结合空间注意力融合模块与多通道增强雷达（MER）数据预处理策略，构建了一套高效的工程化解决方案。
2. **性能表现**：实验结果非常惊人，在nuScenes数据集上声称取得了显著优于当前SOTA（包括基于Transformer的RCDformer和RadarNet）的性能（RMSE从约4.9m降至3.4m左右）。这表明雷达数据的有效预处理（MER）对于融合效果至关重要。
3. **实验完整性**：提供了详细的对比实验（涵盖不同天气场景）、消融实验（损失函数、数据量）以及定性分析（CAM可视化），验证了雷达特征在深度恢复中的核心作用。
4. **行业价值**：该方法推理速度快（0.118s），且证明了基于CNN的架构配合良好的数据增强仍能战胜复杂的Transformer模型，对于车端部署具有较高的参考价值。
## Abstract: 
Depth perception is crucial for spatial understanding and has traditionally been achieved through stereoscopic imaging. However, the precision of depth estimation using stereoscopic methods depends on the accurate calibration of binocular vision sensors. Monocular cameras, while more accessible, often suffer from reduced accuracy, especially under challenging imaging conditions. Optical sensors, too, face limitations in adverse environments, leading researchers to explore radar technology as a reliable alternative. Although radar provides coarse but accurate signals, its integration with fine-grained monocular camera data remains underexplored. In this research, we propose DepthSense, a novel radar-assisted monocular depth enhancement approach. DepthSense employs an encoder-decoder architecture, a Radar Residual Network, feature fusion with a spatial attention mechanism, and an ordinal regression layer to deliver precise depth estimations. We conducted extensive experiments on the nuScenes dataset to validate the effectiveness of DepthSense. Our methodology not only surpasses existing approaches in quantitative performance but also reduces parameter complexity and inference times. Our findings demonstrate that DepthSense represents a significant advancement over traditional stereo methods, offering a robust and efficient solution for depth estimation in autonomous driving. By leveraging the complementary strengths of radar and monocular camera data, DepthSense sets a new benchmark in the field, paving the way for more reliable and accurate spatial perception systems.
