---
layout: default
title: "[8.6]STATIC : Surface Temporal Affine for TIme Consistency in Video Monocular Depth Estimation"
---

# [8.6] STATIC : Surface Temporal Affine for TIme Consistency in Video Monocular Depth Estimation

- Authors: Sunghun Yang, Minhyeok Lee, Suhwan Cho, Jungho Lee, Sangyoun Lee
- [arXiv Link](https://arxiv.org/abs/2412.01090)
- [PDF Link](https://arxiv.org/pdf/2412.01090.pdf)

## Subfields
 3D感知 / 视频单目深度估计
## Reason for Interest

论文提出了一种新颖的视频单目深度估计方法STATIC，其核心创新在于通过表面法线差异掩码将视频帧划分为静态和动态区域，并分别设计Masked Static (MS)模块和Surface Normal Similarity (SNS)模块来独立学习和增强这两个区域的时间一致性。这一方法避免了传统方法对光流、相机参数等额外运动信息的依赖，从而解决了现有方法在内存消耗、动态场景处理和对辅助信息过度依赖等方面的局弊，并显著提升了深度图的时间一致性。

实验设计全面且充分，在自动驾驶领域常用的KITTI Eigen split、室内场景数据集NYUv2以及合成动态场景数据集MPI-Sintel上进行了广泛验证。评估指标涵盖了标准的深度估计精度指标和专门衡量时间一致性的指标。论文与多种单帧及多帧SOTA方法进行了详细对比，结果表明STATIC在深度估计精度和时间一致性上均达到了SOTA水平，尤其在时间一致性方面表现出显著优势。消融实验清晰地展示了各模块的有效性，并通过不同帧率下的鲁棒性分析进一步增强了结果的可信度。

该研究对于自动驾驶领域具有重要意义。单目视频深度估计作为一种低成本感知方案，其时间一致性对于下游的定位、轨迹预测和规划至关重要。STATIC通过减少对额外信息的依赖，简化了系统设计，提高了在复杂动态环境下的鲁棒性，具备较高的行业应用潜力。尽管论文中Sintel数据集的推理时间仍有优化空间，但整体创新性和实验成果证明了其在自动驾驶感知领域的价值。
## Abstract: 
Video monocular depth estimation is essential for applications such as autonomous driving, AR/VR, and robotics. Recent transformer-based single-image monocular depth estimation models perform well on single images but struggle with depth consistency across video frames. Traditional methods aim to improve temporal consistency using multi-frame temporal modules or prior information like optical flow and camera parameters. However, these approaches face issues such as high memory use, reduced performance with dynamic or irregular motion, and limited motion understanding. We propose STATIC, a novel model that independently learns temporal consistency in static and dynamic area without additional information. A difference mask from surface normals identifies static and dynamic area by measuring directional variance. For static area, the Masked Static (MS) module enhances temporal consistency by focusing on stable regions. For dynamic area, the Surface Normal Similarity (SNS) module aligns areas and enhances temporal consistency by measuring feature similarity between frames. A final refinement integrates the independently learned static and dynamic area, enabling STATIC to achieve temporal consistency across the entire sequence. Our method achieves state-of-the-art video depth estimation on the KITTI and NYUv2 datasets without additional information.
