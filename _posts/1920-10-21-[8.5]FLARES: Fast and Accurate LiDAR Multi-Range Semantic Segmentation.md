---
layout: default
title: "[8.5]FLARES: Fast and Accurate LiDAR Multi-Range Semantic Segmentation"
---

# [8.5] FLARES: Fast and Accurate LiDAR Multi-Range Semantic Segmentation

- Authors: Bin Yang, Alexandru Paul Condurache
- [arXiv Link](https://arxiv.org/abs/2502.09274)
- [PDF Link](https://arxiv.org/pdf/2502.09274.pdf)

## Subfields
 LiDAR 语义分割 / 3D 感知
## Reason for Interest

1. 创新性：针对Range-View方法中经典的“多对一（Many-to-One）”投影冲突问题，提出了FLARES策略（点云切分+低分辩率多帧并行处理），在不牺牲视场角的情况下有效保留了空间信息，思路独特且工程实用性强。配合提出的WPD+数据增强和NNRI后处理算法，构成了一套完整的解决方案。
2. 实验完整性：在SemanticKITTI和nuScenes两大权威数据集上，基于四种不同的网络架构（SalsaNext, FIDNet, CENet, RangeViT）进行了全面验证，证明了方法的通用性。提供了详细的消融实验和运行时间分析。
3. 行业价值：作者来自博世（Bosch）自动驾驶团队，论文高度关注车端实时性（Inference Speed），在保持高帧率（如CENet+FLARES仅需24ms）的同时显著提升了分割精度，非常适合量产自动驾驶系统的落地应用。
4. 不足之处：虽然相比Range-View方法提升巨大，但在绝对mIoU指标上仍落后于基于Voxel或Point的SOTA重型网络（如SphereFormer, PTv3），属于典型的高效能工程优化论文。
## Abstract: 
3D scene understanding is a critical yet challenging task in autonomous driving due to the irregularity and sparsity of LiDAR data, as well as the computational demands of processing large-scale point clouds. Recent methods leverage range-view representations to enhance efficiency, but they often adopt higher azimuth resolutions to mitigate information loss during spherical projection, where only the closest point is retained for each 2D grid. However, processing wide panoramic range-view images remains inefficient and may introduce additional distortions. Our empirical analysis shows that training with multiple range images, obtained from splitting the full point cloud, improves both segmentation accuracy and computational efficiency. However, this approach also poses new challenges of exacerbated class imbalance and increase in projection artifacts. To address these, we introduce FLARES, a novel training paradigm that incorporates two tailored data augmentation techniques and a specialized post-processing method designed for multi-range settings. Extensive experiments demonstrate that FLARES is highly generalizable across different architectures, yielding 2.1%~7.9% mIoU improvements on SemanticKITTI and 1.8%~3.9% mIoU on nuScenes, while delivering over 40% speed-up in inference.
