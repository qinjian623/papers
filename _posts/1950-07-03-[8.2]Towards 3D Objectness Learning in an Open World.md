---
layout: default
title: "[8.2]Towards 3D Objectness Learning in an Open World"
---

# [8.2] Towards 3D Objectness Learning in an Open World

- Authors: Taichi Liu, Zhenyu Wang, Ruofeng Liu, Guang Wang, Desheng Zhang
- [arXiv Link](https://arxiv.org/abs/2510.17686v1)
- [PDF Link](https://arxiv.org/pdf/2510.17686v1.pdf)

## Subfields
 Open-World 3D Object Detection / General Obstacle Detection
## Reason for Interest

The paper proposes a novel 'Prompt-free' approach using 2D foundation model (SAM) priors to learn general '3D Objectness' without requiring text prompts or comprehensive 3D labels. 

1. Innovation: The method cleverly addresses the limitations of SAM in 3D (fragmented masks) via a multi-scale point sampling strategy and Cross-Modal Mixture of Experts (MoE). This allows the model to detect 'unknown' objects (like pedestrians when trained only on cars) by learning what constitutes an object geometrically and semantically.
2. Relevance: Highly relevant to autonomous driving safety (General Obstacle Detection). Detecting anomalous objects on the road without predefined training classes is a critical industry problem.
3. Performance: It demonstrates significant margins on indoor datasets. Crucially, on the KITTI autonomous driving dataset, it achieves superior performance in an open-world setting (training on Cars, detecting Pedestrians/Cyclists) compared to existing Open-Vocabulary methods. 
4. Credibility: Extensive ablation studies and cross-dataset generalization (SUN RGB-D <-> ScanNet) support the claims. 

Minor deduction: The majority of the deep-dive analysis and massive gains are shown on indoor datasets (SUN/ScanNet). While the KITTI results are positive, a broader outdoor evaluation (e.g., NuScenes with more diverse 'unknowns' like debris or animals) would have solidified the score further for the AD domain.
## Abstract: 

