---
layout: default
title: "[7.2]Multi-Context Fusion Transformer for Pedestrian Crossing Intention Prediction in Urban Environments"
---

# [7.2] Multi-Context Fusion Transformer for Pedestrian Crossing Intention Prediction in Urban Environments

- Authors: Yuanzhe Li, Hang Zhong, Steffen Müller
- [arXiv Link](https://arxiv.org/abs/2511.20011v1)
- [PDF Link](https://arxiv.org/pdf/2511.20011v1.pdf)

## Subfields
 行为预测 / 行人意图预测
## Reason for Interest

1. 创新性：论文提出了 MFT 框架，利用 Transformer 的渐进式融合策略（Intra/Cross/Refinement）整合行人行为、环境、定位和车辆运动四类上下文信息，结构设计逻辑清晰，消融实验充分证明了各模块有效性。
2. 实验结果：在 JAAD 和 PIE 数据集上取得了 SOTA 或极具竞争力的指标，且模型参数量（0.95M）远小于基于图像的主流方法。
3. 局限性与扣分项：该方法的核心输入依赖显式的语义属性（如“点头”、“手势”、“红绿灯状态”等），文中明确指出这些属性源自数据集标注（dataset annotations）。这意味着模型在测试阶段可能使用了真值（Ground Truth）或假设存在完美的前置感知，而对比的方法（如 PCPA, IntFormer）大多直接处理原始像素。这种比较在一定程度上是不公平的，因为 MFT 规避了从图像中提取细粒度语义特征的难度和噪声。其实际部署价值高度依赖于上游属性感知算法的精度，所谓的“推理速度快”未包含属性提取的耗时。
## Abstract: 

