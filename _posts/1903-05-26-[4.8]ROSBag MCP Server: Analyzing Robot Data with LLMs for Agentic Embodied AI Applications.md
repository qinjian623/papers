---
layout: default
title: "[4.8]ROSBag MCP Server: Analyzing Robot Data with LLMs for Agentic Embodied AI Applications"
---

# [4.8] ROSBag MCP Server: Analyzing Robot Data with LLMs for Agentic Embodied AI Applications

- Authors: Lei Fu, Sahar Salimpour, Leonardo Militano, Harry Edelman, Jorge Pe\~na Queralta, Giovann...
- [arXiv Link](https://arxiv.org/abs/2511.03497)
- [PDF Link](https://arxiv.org/pdf/2511.03497.pdf)

## Subfields
 LLM增强的自动驾驶数据分析与调试工具
## Reason for Interest

该论文提出了一个创新的ROSbag MCP服务器，旨在利用LLM和VLM通过自然语言对机器人数据进行分析、可视化和处理。其核心创新点在于构建了一个领域特定工具集，支持对轨迹、激光雷达、坐标变换和时间序列数据等自动驾驶相关数据进行深入分析，并首次将MCP协议应用于ROS原生数据分析。论文通过详尽的实验，对比了八种主流LLM/VLM模型在机器人数据分析任务中的工具调用能力，并给出了明确的性能排名和影响因素分析，实验设计完整且结果可信。该工作极大地提升了机器人数据分析的便利性和可访问性，对于自动驾驶领域的研发人员进行数据调试、性能评估和问题排查具有显著的辅助价值。然而，根据评审要求，该论文的贡献主要体现在增强自动驾驶的开发工具链和数据分析效率上，而非直接提升车端自动驾驶感知、预测、规划或控制的核心性能指标。其不直接涉及车端自动驾驶系统的核心算法突破，因此根据严格的评分标准，分数限定在5分以内。鉴于其在辅助自动驾驶数据分析方面的创新性和实用性，给出4.8分。
## Abstract: 
Agentic AI systems and Physical or Embodied AI systems have been two key research verticals at the forefront of Artificial Intelligence and Robotics, with Model Context Protocol (MCP) increasingly becoming a key component and enabler of agentic applications. However, the literature at the intersection of these verticals, i.e., Agentic Embodied AI, remains scarce. This paper introduces an MCP server for analyzing ROS and ROS 2 bags, allowing for analyzing, visualizing and processing robot data with natural language through LLMs and VLMs. We describe specific tooling built with robotics domain knowledge, with our initial release focused on mobile robotics and supporting natively the analysis of trajectories, laser scan data, transforms, or time series data. This is in addition to providing an interface to standard ROS 2 CLI tools ("ros2 bag list" or "ros2 bag info"), as well as the ability to filter bags with a subset of topics or trimmed in time. Coupled with the MCP server, we provide a lightweight UI that allows the benchmarking of the tooling with different LLMs, both proprietary (Anthropic, OpenAI) and open-source (through Groq). Our experimental results include the analysis of tool calling capabilities of eight different state-of-the-art LLM/VLM models, both proprietary and open-source, large and small. Our experiments indicate that there is a large divide in tool calling capabilities, with Kimi K2 and Claude Sonnet 4 demonstrating clearly superior performance. We also conclude that there are multiple factors affecting the success rates, from the tool description schema to the number of arguments, as well as the number of tools available to the models. The code is available with a permissive license at https://github.com/binabik-ai/mcp-rosbags.
