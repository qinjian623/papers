---
layout: default
title: "[8.8]U4D: Uncertainty-Aware 4D World Modeling from LiDAR Sequences"
---

# [8.8] U4D: Uncertainty-Aware 4D World Modeling from LiDAR Sequences

- Authors: Xiang Xu, Ao Liang, Youquan Liu, Linfeng Li, Lingdong Kong, Ziwei Liu, Qingshan Liu
- [arXiv Link](https://arxiv.org/abs/2512.02982)
- [PDF Link](https://arxiv.org/pdf/2512.02982.pdf)

## Subfields
 生成式世界模型 / LiDAR场景仿真 (Generative World Models / LiDAR Simulation)
## Reason for Interest

论文提出了一种创新的'由难到易'（hard-to-easy）的4D LiDAR场景生成框架。核心贡献在于利用语义分割模型的不确定性（熵）定位生成困难区域，优先对其进行建模，再进行条件补全，有效解决了现有方法在稀疏或遮挡区域产生伪影的问题。此外，提出的MoST（混合时空）模块通过自适应门控机制有效平衡了空间几何细节与时序连贯性。实验表明该方法在几何保真度、时序稳定性和下游感知任务辅助效果上均达到了SOTA水平，对自动驾驶数据仿真和长尾场景生成具有重要价值。
## Abstract: 
Modeling dynamic 3D environments from LiDAR sequences is central to building reliable 4D worlds for autonomous driving and embodied AI. Existing generative frameworks, however, often treat all spatial regions uniformly, overlooking the varying uncertainty across real-world scenes. This uniform generation leads to artifacts in complex or ambiguous regions, limiting realism and temporal stability. In this work, we present U4D, an uncertainty-aware framework for 4D LiDAR world modeling. Our approach first estimates spatial uncertainty maps from a pretrained segmentation model to localize semantically challenging regions. It then performs generation in a "hard-to-easy" manner through two sequential stages: (1) uncertainty-region modeling, which reconstructs high-entropy regions with fine geometric fidelity, and (2) uncertainty-conditioned completion, which synthesizes the remaining areas under learned structural priors. To further ensure temporal coherence, U4D incorporates a mixture of spatio-temporal (MoST) block that adaptively fuses spatial and temporal representations during diffusion. Extensive experiments show that U4D produces geometrically faithful and temporally consistent LiDAR sequences, advancing the reliability of 4D world modeling for autonomous perception and simulation.
