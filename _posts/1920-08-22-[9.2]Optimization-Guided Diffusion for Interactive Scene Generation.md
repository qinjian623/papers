---
layout: default
title: "[9.2]Optimization-Guided Diffusion for Interactive Scene Generation"
---

# [9.2] Optimization-Guided Diffusion for Interactive Scene Generation

- Authors: Shiaho Li, Naisheng Ye, Tianyu Li, Kashyap Chitta, Tuo An, Peng Su, Boyang Wang, Haiou Li...
- [arXiv Link](https://arxiv.org/abs/2512.07661)
- [PDF Link](https://arxiv.org/pdf/2512.07661.pdf)

## Subfields
 自动驾驶仿真 / 场景生成
## Reason for Interest

该论文提出了一种无需重新训练（Training-free）的优化引导扩散模型框架（OMEGA），针对自动驾驶场景生成的物理可行性和可控性痛点提供了高效解决方案。核心创新点包括：1. 引入KL散度约束的信任区域优化，在逆扩散过程中对生成轨迹进行重锚定（Re-anchoring），在保证分布一致性的同时强制满足物理约束；2. 设计了“预热（Warmup）+滚动零噪（Rolling-Zero）”的两阶段噪声调度策略，有效平衡了长时序连贯性和局部交互反应；3. 提出了基于灵敏度增强的博弈论对抗生成方法，能生成高质量的Safety-critical场景。实验部分非常扎实，不仅在nuPlan上大幅超越SOTA，还在Waymo上展示了极强的零样本泛化能力。该工作对于自动驾驶仿真验证、长尾场景挖掘具有极高的实用价值。
## Abstract: 
Realistic and diverse multi-agent driving scenes are crucial for evaluating autonomous vehicles, but safety-critical events which are essential for this task are rare and underrepresented in driving datasets. Data-driven scene generation offers a low-cost alternative by synthesizing complex traffic behaviors from existing driving logs. However, existing models often lack controllability or yield samples that violate physical or social constraints, limiting their usability. We present OMEGA, an optimization-guided, training-free framework that enforces structural consistency and interaction awareness during diffusion-based sampling from a scene generation model. OMEGA re-anchors each reverse diffusion step via constrained optimization, steering the generation towards physically plausible and behaviorally coherent trajectories. Building on this framework, we formulate ego-attacker interactions as a game-theoretic optimization in the distribution space, approximating Nash equilibria to generate realistic, safety-critical adversarial scenarios. Experiments on nuPlan and Waymo show that OMEGA improves generation realism, consistency, and controllability, increasing the ratio of physically and behaviorally valid scenes from 32.35% to 72.27% for free exploration capabilities, and from 11% to 80% for controllability-focused generation. Our approach can also generate $5\times$ more near-collision frames with a time-to-collision under three seconds while maintaining the overall scene realism.
