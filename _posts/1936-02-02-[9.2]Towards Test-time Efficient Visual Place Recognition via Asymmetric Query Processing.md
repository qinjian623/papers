---
layout: default
title: "[9.2]Towards Test-time Efficient Visual Place Recognition via Asymmetric Query Processing"
---

# [9.2] Towards Test-time Efficient Visual Place Recognition via Asymmetric Query Processing

- Authors: Jaeyoon Kim, Yoonki Cho, Sung-Eui Yoon
- [arXiv Link](https://arxiv.org/abs/2512.13055v1)
- [PDF Link](https://arxiv.org/pdf/2512.13055v1.pdf)

## Subfields
 视觉定位 (Visual Localization) / 视觉位置识别 (VPR)
## Reason for Interest

1. **高行业痛点解决度**：论文直击自动驾驶和机器人领域的核心矛盾——高性能基础模型（如DINOv2）与边缘端设备算力受限之间的冲突。提出的非对称VPR框架允许车端使用轻量级模型达到接近大模型的检索性能。
2. **创新且合理的利用先验**：不同于通过蛮力计算k-NN来蒸馏大模型知识的传统方法，本文巧妙利用VPR数据自带的地理位置信息（Geographical Memory Bank），构建了特定位置的特征统计分布，这在自动驾驶建图场景中是天然存在的优势。
3. **理论与工程兼备**：提出的隐式嵌入增强（Implicit Embedding Augmentation）利用协方差矩阵模拟特征变化，有较好的理论支撑；同时实验展示了极高的训练效率提升（快数千倍），这对实际工程迭代极具价值。
4. **实验充分**：在五个主流数据集上均验证了有效性，且对极端环境（Nordland, AmsterTime）的鲁棒性提升明显。
该工作是端侧落地大模型能力的优秀范例，极具应用前景。
## Abstract: 

