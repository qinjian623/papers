---
layout: default
title: "[8.8]VOIC: Visible-Occluded Decoupling for Monocular 3D Semantic Scene Completion"
---

# [8.8] VOIC: Visible-Occluded Decoupling for Monocular 3D Semantic Scene Completion

- Authors: Zaidao Han, Risa Higashita, Jiang Liu
- [arXiv Link](https://arxiv.org/abs/2512.18954v1)
- [PDF Link](https://arxiv.org/pdf/2512.18954v1.pdf)

## Subfields
 3D感知 / 单目3D语义场景补全 (Semantic Scene Completion, SSC)
## Reason for Interest

1. 创新性强：针对单目 SSC 任务中可视与遮挡区域特征混淆的问题，提出了“可视-遮挡解耦”的策略。通过离线生成的 VRLE（Visible Region Label Extraction）标签对可视区域进行显式监督，利用双解码器（VD 和 OD）分别处理可视感知和遮挡推理，逻辑清晰且切中痛点。
2. 实验扎实：在两个主流室外数据集（SemanticKITTI 和 SSCBench-KITTI-360）上进行了广泛对比，各项指标均有一致性提升，且在长尾类别（如 car, bicycle）上表现优异。
3. 可信度高：提供了详细的消融实验证明各组件有效性，且开源了代码和预训练模型。
4. 行业价值：单目 3D 场景补全对于降低自动驾驶感知成本具有重要意义，该方法不依赖时序信息也能取得高性能，具备较好的落地潜力。
## Abstract: 
  To address these challenges, we introduce an offline Visible Region Label Extraction (VRLE) strategy that explicitly separates and extracts voxel-level supervision for visible regions from dense 3D ground truth. This strategy purifies the supervisory space for two complementary sub-tasks: visible-region perception and occluded-region reasoning. Building on this idea, we propose the Visible-Occluded Interactive Completion Network (VOIC), a novel dual-decoder framework that explicitly decouples SSC into visible-region semantic perception and occluded-region scene completion. VOIC first constructs a base 3D voxel representation by fusing image features with depth-derived occupancy. The visible decoder focuses on generating high-fidelity geometric and semantic priors, while the occlusion decoder leverages these priors together with cross-modal interaction to perform coherent global scene reasoning.
  Extensive experiments on the SemanticKITTI and SSCBench-KITTI360 benchmarks demonstrate that VOIC outperforms existing monocular SSC methods in both geometric completion and semantic segmentation accuracy, achieving state-of-the-art performance.
