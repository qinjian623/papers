---
layout: default
title: "[8.2]E3AD: An Emotion-Aware Vision-Language-Action Model for Human-Centric End-to-End Autonomous Driving"
---

# [8.2] E3AD: An Emotion-Aware Vision-Language-Action Model for Human-Centric End-to-End Autonomous Driving

- Authors: Yihong Tang, Haicheng Liao, Tong Nie, Junlin He, Ao Qu, Kehua Chen, Wei Ma, Zhenning Li, ...
- [arXiv Link](https://arxiv.org/abs/2512.04733v1)
- [PDF Link](https://arxiv.org/pdf/2512.04733v1.pdf)

## Subfields
 端到端自动驾驶 / 视觉-语言-动作模型 (VLA)
## Reason for Interest

论文切入点新颖，将‘情绪感知’引入端到端自动驾驶（VLA）框架，通过连续的VAD情绪空间建模，使车辆能根据乘客指令的语气（如紧迫感、犹豫）调整规划策略。提出的E3AD框架结合了自我中心（Egocentric）和非自我中心（Allocentric）的双流空间推理，增强了VLM的空间理解能力；利用DPO（直接偏好优化）对齐情绪意图与驾驶动作的思路符合当前技术趋势。实验在多个数据集上验证了有效性，并包含用户研究，工作扎实完整。虽然VLA直接输出轨迹的安全性在工业界落地尚存挑战，但该研究为人机共驾和座舱体验提升提供了有价值的前瞻性方向。
## Abstract: 

