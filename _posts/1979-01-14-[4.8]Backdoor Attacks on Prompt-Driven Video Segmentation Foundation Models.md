---
layout: default
title: "[4.8]Backdoor Attacks on Prompt-Driven Video Segmentation Foundation Models"
---

# [4.8] Backdoor Attacks on Prompt-Driven Video Segmentation Foundation Models

- Authors: Zongmin Zhang, Zhen Sun, Yifan Liao, Wenhan Dong, Xinlei He, Xingshuo Han, Shengmin Xu, X...
- [arXiv Link](https://arxiv.org/abs/2512.22046)
- [PDF Link](https://arxiv.org/pdf/2512.22046.pdf)

## Subfields
 AI安全 / 感知基础模型 (Video Segmentation Foundation Models)
## Reason for Interest

1. **相关性不足（评分主要扣分点）**：虽然论文在摘要和引言中提及自动驾驶是VSFM的应用场景之一，但核心实验完全基于通用视频分割数据集（DAVIS, LVOS），未在nuScenes、Waymo等自动驾驶数据集上进行验证，也未测试对车端感知-规划下游任务的实际影响。属于通用CV安全研究，非直接的车端自动驾驶研究。
2. **创新性**：较高。揭示了传统后门攻击在Prompt-driven模型上失效的原因（梯度冲突），并提出了两阶段攻击策略（BadVSFM），成功攻破了SAM2等前沿模型。
3. **实验完整性**：在多个模型（SAM2, MedSAM2, EdgeTAM等）上验证了有效性，并分析了防御策略的失效，逻辑严密。
4. **综合评价**：作为一篇AI安全论文质量很高，但作为自动驾驶领域论文，其针对性和直接应用价值尚未得到实证，依据“非车端直接相关最高5分”的原则，给予4.8分。
## Abstract: 
Prompt-driven Video Segmentation Foundation Models (VSFMs) such as SAM2 are increasingly deployed in applications like autonomous driving and digital pathology, raising concerns about backdoor threats. Surprisingly, we find that directly transferring classic backdoor attacks (e.g., BadNet) to VSFMs is almost ineffective, with ASR below 5\%. To understand this, we study encoder gradients and attention maps and observe that conventional training keeps gradients for clean and triggered samples largely aligned, while attention still focuses on the true object, preventing the encoder from learning a distinct trigger-related representation. To address this challenge, we propose BadVSFM, the first backdoor framework tailored to prompt-driven VSFMs. BadVSFM uses a two-stage strategy: (1) steer the image encoder so triggered frames map to a designated target embedding while clean frames remain aligned with a clean reference encoder; (2) train the mask decoder so that, across prompt types, triggered frame-prompt pairs produce a shared target mask, while clean outputs stay close to a reference decoder. Extensive experiments on two datasets and five VSFMs show that BadVSFM achieves strong, controllable backdoor effects under diverse triggers and prompts while preserving clean segmentation quality. Ablations over losses, stages, targets, trigger settings, and poisoning rates demonstrate robustness to reasonable hyperparameter changes and confirm the necessity of the two-stage design. Finally, gradient-conflict analysis and attention visualizations show that BadVSFM separates triggered and clean representations and shifts attention to trigger regions, while four representative defenses remain largely ineffective, revealing an underexplored vulnerability in current VSFMs.
