---
layout: default
title: "[6.5]Context-aware, Ante-hoc Explanations of Driving Behaviour"
---

# [6.5] Context-aware, Ante-hoc Explanations of Driving Behaviour

- Authors: Dominik Grundt (German Aerospace Center e.V.), Ishan Saxena (German Aerospace Center e.V....
- [arXiv Link](https://arxiv.org/abs/2511.14428)
- [PDF Link](https://arxiv.org/pdf/2511.14428.pdf)

## Subfields
 可解释性AI (XAI) / 形式化方法 / 运行时监控
## Reason for Interest

论文提出了一种利用交通序列图（TSC）进行自动驾驶行为解释的方法，创新性地结合了形式化验证（用于安全性）与可视化规范（用于可解释性），符合欧盟AI法案对透明度的要求。主要贡献在于通过运行时监控实时识别交通场景并触发预定义的解释。然而，评分受限于以下因素：1. 实验仅在简易的CARLA仿真场景（超车）中进行，且依赖理想化的感知数据，未考虑传感器噪声；2. 缺乏用户研究（User Study），无法证明所生成的解释实际上能否提升人类对系统的信任度；3. 属于方法论验证性质的工作，距离实车部署有较大距离。
## Abstract: 
Autonomous vehicles (AVs) must be both safe and trustworthy to gain social acceptance and become a viable option for everyday public transportation. Explanations about the system behaviour can increase safety and trust in AVs. Unfortunately, explaining the system behaviour of AI-based driving functions is particularly challenging, as decision-making processes are often opaque. The field of Explainability Engineering tackles this challenge by developing explanation models at design time. These models are designed from system design artefacts and stakeholder needs to develop correct and good explanations. To support this field, we propose an approach that enables context-aware, ante-hoc explanations of (un)expectable driving manoeuvres at runtime. The visual yet formal language Traffic Sequence Charts is used to formalise explanation contexts, as well as corresponding (un)expectable driving manoeuvres. A dedicated runtime monitoring enables context-recognition and ante-hoc presentation of explanations at runtime. In combination, we aim to support the bridging of correct and good explanations. Our method is demonstrated in a simulated overtaking.
