---
layout: default
title: "[9.2]DiffusionDriveV2: Reinforcement Learning-Constrained Truncated Diffusion Modeling in End-to-End Autonomous Driving"
---

# [9.2] DiffusionDriveV2: Reinforcement Learning-Constrained Truncated Diffusion Modeling in End-to-End Autonomous Driving

- Authors: Jialv Zou, Shaoyu Chen, Bencheng Liao, Zhiyu Zheng, Yuehao Song, Lefei Zhang, Qian Zhang,...
- [arXiv Link](https://arxiv.org/abs/2512.07745v1)
- [PDF Link](https://arxiv.org/pdf/2512.07745v1.pdf)

## Subfields
 端到端自动驾驶 / 轨迹规划 / 生成式模型
## Reason for Interest

论文针对端到端自动驾驶中扩散模型生成轨迹时存在的‘模式坍塌’与‘质量不一致’矛盾，提出了一种结合强化学习（RL）的解决方案。创新性方面，论文巧妙地将大模型领域的 GRPO（Group Relative Policy Optimization）引入轨迹生成，并针对驾驶场景的多模态特性设计了‘锚点内 GRPO’（Intra-Anchor GRPO）和‘锚点间截断 GRPO’（Inter-Anchor Truncated GRPO），有效平衡了探索与利用。实验方面，在权威 benchmark NAVSIM 的两个版本上均取得了显著的 SOTA 成绩，且仅使用 ResNet-34 骨干网络即超越了基于更大骨干网络的方法，证明了其高效性。方法论逻辑严密，消融实验充分，具有较高的学术价值和落地潜力。
## Abstract: 

