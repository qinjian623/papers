---
layout: default
title: "[5.0]SLAM&Render: A Benchmark for the Intersection Between Neural Rendering, Gaussian Splatting and SLAM"
---

# [5.0] SLAM&Render: A Benchmark for the Intersection Between Neural Rendering, Gaussian Splatting and SLAM

- Authors: Samuel Cerezo, Gaetano Meli, Tom\'as Berriel Martins, Kirill Safronov, Javier Civera
- [arXiv Link](https://arxiv.org/abs/2504.13713)
- [PDF Link](https://arxiv.org/pdf/2504.13713.pdf)

## Subfields
 SLAM / 神经场景表示 / 基准数据集
## Reason for Interest

本文提出并发布了一个名为SLAM&Render的基准数据集，旨在推动神经渲染、高斯泼溅和SLAM交叉领域的研究。其创新性在于解决了现有数据集在序列操作、多模态融合、泛化能力（跨视角和光照条件）以及精确传感器运动复现方面的不足。该数据集独特地包含了40个时间同步的RGB-D图像、IMU读数、机器人运动学数据以及高精度真实位姿，这些数据通过机器人机械臂采集，确保了精确的相机运动。此外，数据集还在四种受控光照条件（自然、冷、暖、暗）下，通过五种不同物体布置（包含遮挡和重排）进行记录，并提供了独立的训练和测试轨迹，以评估模型泛化能力。实验部分通过基线方法（如Gaussian Splatting、FeatSplat和MonoGS）验证了数据集的有效性，例如展示了NVS方法在独立测试轨迹上的过拟合现象，以及运动学数据对SLAM跟踪性能的提升。这些设计对于发展鲁棒的SLAM和先进地图表示方法具有重要价值。然而，尽管SLAM是自动驾驶领域的核心技术，且神经场景表示作为新的地图形式具有潜力，但该数据集的采集环境（机械臂在桌面物体周围移动的实验室场景）和所关注的问题（高质量物体级重建、受控光照下的新视角合成）与车端自动驾驶的典型场景（如大规模室外环境、动态交通参与者、复杂道路结构、远距离感知等）存在较大差异。根据评审规则，如果论文不直接和车端自动驾驶相关，则最高评分为5分。鉴于此数据集在通用机器人SLAM和神经渲染领域的高质量和重要性，以及其严谨的实验设计和公开可访问性，我们给予5.0分，以肯定其在相关基础研究领域的卓越贡献，但同时受限于其与车端自动驾驶的直接关联度。
## Abstract: 
Models and methods originally developed for Novel View Synthesis and Scene Rendering, such as Neural Radiance Fields (NeRF) and Gaussian Splatting, are increasingly being adopted as representations in Simultaneous Localization and Mapping (SLAM). However, existing datasets fail to include the specific challenges of both fields, such as sequential operations and, in many settings, multi-modality in SLAM or generalization across viewpoints and illumination conditions in neural rendering. Additionally, the data are often collected using sensors which are handheld or mounted on drones or mobile robots, which complicates the accurate reproduction of sensor motions. To bridge these gaps, we introduce SLAM&amp;Render, a novel dataset designed to benchmark methods in the intersection between SLAM, Novel View Rendering and Gaussian Splatting. Recorded with a robot manipulator, it uniquely includes 40 sequences with time-synchronized RGB-D images, IMU readings, robot kinematic data, and ground-truth pose streams. By releasing robot kinematic data, the dataset also enables the assessment of recent integrations of SLAM paradigms within robotic applications. The dataset features five setups with consumer and industrial objects under four controlled lighting conditions, each with separate training and test trajectories. All sequences are static with different levels of object rearrangements and occlusions. Our experimental results, obtained with several baselines from the literature, validate SLAM&amp;Render as a relevant benchmark for this emerging research area.
