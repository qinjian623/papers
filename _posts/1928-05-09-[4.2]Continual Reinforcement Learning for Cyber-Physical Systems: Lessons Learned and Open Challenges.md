---
layout: default
title: "[4.2]Continual Reinforcement Learning for Cyber-Physical Systems: Lessons Learned and Open Challenges"
---

# [4.2] Continual Reinforcement Learning for Cyber-Physical Systems: Lessons Learned and Open Challenges

- Authors: Kim N. Nolle, Ivana Dusparic, Rhodri Cusack, Vinny Cahill
- [arXiv Link](https://arxiv.org/abs/2511.15652v1)
- [PDF Link](https://arxiv.org/pdf/2511.15652v1.pdf)

## Subfields
 规划控制 / 强化学习 (Planning & Control / Continual RL)
## Reason for Interest

该论文属于‘经验教训（Lessons Learned）’类短文/摘要。虽然研究对象是自动泊车这一AD功能，但存在明显短板：1. 实验环境为极简的2D仿真，无法代表真实世界自动驾驶的复杂性；2. 结论主要重申了强化学习领域已知的‘灾难性遗忘’和‘超参数敏感’问题，未提供创新解决方案；3. 实验显示标准方法（EWC）失效，研究处于问题发现阶段，缺乏工程实用价值或理论突破。因此评分较低。
## Abstract: 
  This paper highlights open challenges in continual RL (CRL) based on experiments in an autonomous driving environment. In this environment, the agent must learn to successfully park in four different scenarios corresponding to parking spaces oriented at varying angles. The agent is successively trained in these four scenarios one after another, representing a CL environment, using Proximal Policy Optimisation (PPO). These experiments exposed a number of open challenges in CRL: finding suitable abstractions of the environment, oversensitivity to hyperparameters, catastrophic forgetting, and efficient use of neural network capacity.
  Based on these identified challenges, we present open research questions that are important to be addressed for creating robust CRL systems. In addition, the identified challenges call into question the suitability of neural networks for CL. We also identify the need for interdisciplinary research, in particular between computer science and neuroscience.
