---
layout: default
title: "[8.2]Reloc-VGGT: Visual Re-localization with Geometry Grounded Transformer"
---

# [8.2] Reloc-VGGT: Visual Re-localization with Geometry Grounded Transformer

- Authors: Tianchen Deng, Wenhua Wu, Kunzhen Wu, Guangming Wang, Siting Zhu, Shenghai Yuan, Xun Chen...
- [arXiv Link](https://arxiv.org/abs/2512.21883v1)
- [PDF Link](https://arxiv.org/pdf/2512.21883v1.pdf)

## Subfields
 Visual Re-localization / Map-based Localization
## Reason for Interest

The paper introduces a novel visual localization framework leveraging a 3D foundation model (VGGT) with two key innovations: a Pose Tokenizer for early fusion of relative pose information and a Sparse Mask Attention mechanism that reduces complexity from quadratic to linear, enabling real-time performance. The method demonstrates strong generalization and accuracy, particularly in outdoor urban scenes (Cambridge Landmarks), which is highly relevant to autonomous driving in GPS-denied environments. While the evaluation primarily uses standard CV benchmarks rather than large-scale AD datasets like nuScenes, the significant accuracy gains and inference speed optimization make it a valuable contribution to the field of visual positioning.
## Abstract: 

