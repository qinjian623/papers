---
layout: default
title: "[7.6]Flexible and Efficient Spatio-Temporal Transformer for Sequential Visual Place Recognition"
---

# [7.6] Flexible and Efficient Spatio-Temporal Transformer for Sequential Visual Place Recognition

- Authors: Yu Kiu, Lau, Chao Chen, Ge Jin, Chen Feng
- [arXiv Link](https://arxiv.org/abs/2510.04282v1)
- [PDF Link](https://arxiv.org/pdf/2510.04282v1.pdf)

## Subfields
 视觉定位 (Visual Place Recognition) / SLAM / 自动驾驶感知
## Reason for Interest

该论文提出了一种针对序列视觉位置识别（Seq-VPR）的轻量化方法 Adapt-STformer。

1. **创新性与合理性**：提出 Recurrent-DTE（递归可变形 Transformer）模块，将空间特征提取与时间序列建模统一，有效解决了传统 Transformer 方法（如 STFormer）计算复杂度高且不支持变长序列的问题。设计思路清晰，符合车载端侧部署需求。

2. **实验完整性**：在 Nordland、Oxford RobotCar 和 NuScenes 三个主流数据集上进行了详尽实验。不仅比较了传统的 Recall 指标，还独创性地引入了“时间约束下的 Recall（Recall under Time Constraints）”分析，模拟了 36FPS 高帧率下的系统表现，实验设计具有较强的工程指导意义。

3. **结果可信度与局限性**：论文诚实地报告了在绝对精度上落后于基于基础模型（Foundation Models，如 DINOv2）的 SOTA 方法（CaseVPR, CricaVPR），特别是在光照变化剧烈的 NuScenes 场景下差距明显（~16%）。虽然其推理速度（18ms/seq）和显存占用（180MB）优势巨大，但在自动驾驶实际应用中，VPR 模块通常不需要运行在 36FPS，因此其“实时性优势”在一定程度上被应用场景的低频特性所稀释。

4. **行业价值**：尽管精度非 SOTA，但其极高的效率和对变长序列的灵活支持，使其非常适合计算资源受限的嵌入式自动驾驶平台或作为辅助定位链路。代码开源增加了其贡献度。
## Abstract: 

