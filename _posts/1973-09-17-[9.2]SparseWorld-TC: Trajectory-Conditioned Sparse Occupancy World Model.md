---
layout: default
title: "[9.2]SparseWorld-TC: Trajectory-Conditioned Sparse Occupancy World Model"
---

# [9.2] SparseWorld-TC: Trajectory-Conditioned Sparse Occupancy World Model

- Authors: Jiayuan Du, Yiming Zhao, Zhenglong Guo, Yong Pan, Wenbo Hou, Zhihui Hao, Kun Zhan, Qijun ...
- [arXiv Link](https://arxiv.org/abs/2511.22039)
- [PDF Link](https://arxiv.org/pdf/2511.22039.pdf)

## Subfields
 自动驾驶世界模型 / 4D 占用预测 (Occupancy Forecasting)
## Reason for Interest

该论文在自动驾驶世界模型领域具有显著的创新性与实用价值。1. **架构创新**：摒弃了主流的 VAE 离散化 Token 和显式 BEV 中间表示，提出基于稀疏锚点（Sparse Anchors）的全 Transformer 架构，直接从图像特征捕捉时空依赖，有效解决了量化损失和计算冗余问题。2. **性能卓越**：在 Occ3D-nuScenes 基准上，不仅大幅刷新了纯视觉方案的 SOTA，还在长时预测（8秒）任务中表现出优异的稳定性。3. **应用价值**：显式引入轨迹条件（Trajectory-Conditioned），使模型能根据自车规划生成未来场景，高度契合端到端自动驾驶的规划与仿真需求。4. **实验完整**：提供了详细的消融实验、长时预测分析及从占用生成传感器的扩展能力验证，可信度高。
## Abstract: 
This paper introduces a novel architecture for trajectory-conditioned forecasting of future 3D scene occupancy. In contrast to methods that rely on variational autoencoders (VAEs) to generate discrete occupancy tokens, which inherently limit representational capacity, our approach predicts multi-frame future occupancy in an end-to-end manner directly from raw image features. Inspired by the success of attention-based transformer architectures in foundational vision and language models such as GPT and VGGT, we employ a sparse occupancy representation that bypasses the intermediate bird's eye view (BEV) projection and its explicit geometric priors. This design allows the transformer to capture spatiotemporal dependencies more effectively. By avoiding both the finite-capacity constraint of discrete tokenization and the structural limitations of BEV representations, our method achieves state-of-the-art performance on the nuScenes benchmark for 1-3 second occupancy forecasting, outperforming existing approaches by a significant margin. Furthermore, it demonstrates robust scene dynamics understanding, consistently delivering high accuracy under arbitrary future trajectory conditioning.
