---
layout: default
title: "[8.6]VERDI: VLM-Embedded Reasoning for Autonomous Driving"
---

# [8.6] VERDI: VLM-Embedded Reasoning for Autonomous Driving

- Authors: Bowen Feng, Zhiting Mei, Baiang Li, Julian Ost, Filippo Ghilotti, Roger Girgis, Anirudha ...
- [arXiv Link](https://arxiv.org/abs/2505.15925)
- [PDF Link](https://arxiv.org/pdf/2505.15925.pdf)

## Subfields
 端到端自动驾驶 / 知识蒸馏 (End-to-End AD / Knowledge Distillation)
## Reason for Interest

论文提出了 VERDI 框架，针对 VLM 车端推理延迟高的问题，创新性地采用训练时蒸馏策略，将 VLM 的 Chain-of-Thought 推理能力映射到端到端模型（基于 VAD）的感知、预测、规划三个子模块的潜在特征空间中。方法既保留了 VLM 的语义推理优势，又维持了实时推理速度（4.5Hz）。实验非常充分，涵盖了 nuScenes 开环、Bench2Drive 开环以及 HugSim 闭环测试，并在关键安全性指标和规划精度上超越了主流基线（UniAD, VAD），具有极高的行业落地潜力和研究价值。
## Abstract: 
While autonomous driving (AD) stacks struggle with decision making under partial observability and real-world complexity, human drivers are capable of commonsense reasoning to make near-optimal decisions with limited information. Recent work has attempted to leverage finetuned Vision-Language Models (VLMs) for trajectory planning at inference time to emulate human behavior. Despite their success in benchmark evaluations, these methods are often impractical to deploy (a 70B parameter VLM inference at merely 8 tokens per second requires more than 160G of memory), and their monolithic network structure prohibits safety decomposition. To bridge this gap, we propose VLM-Embedded Reasoning for autonomous Driving (VERDI), a training-time framework that distills the reasoning process and commonsense knowledge of VLMs into the AD stack. VERDI augments modular differentiable end-to-end (e2e) AD models by aligning intermediate module outputs at the perception, prediction, and planning stages with text features explaining the driving reasoning process produced by VLMs. By encouraging alignment in latent space, VERDI enables the modular AD stack to internalize structured reasoning, without incurring the inference-time costs of large VLMs. We validate VERDI in both open-loop (NuScenes and Bench2Drive benchmarks) and closed-loop (HugSim Simulator) settings. We find that VERDI outperforms existing e2e methods that do not embed reasoning by up to 11% in $\ell_{2}$ distance and 11% in driving performance, while maintaining real-time inference speed.
