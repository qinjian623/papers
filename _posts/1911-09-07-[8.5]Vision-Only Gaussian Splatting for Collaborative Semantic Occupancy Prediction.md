---
layout: default
title: "[8.5]Vision-Only Gaussian Splatting for Collaborative Semantic Occupancy Prediction"
---

# [8.5] Vision-Only Gaussian Splatting for Collaborative Semantic Occupancy Prediction

- Authors: Cheng Chen, Hao Huang, Saurabh Bagchi
- [arXiv Link](https://arxiv.org/abs/2508.10936)
- [PDF Link](https://arxiv.org/pdf/2508.10936.pdf)

## Subfields
 协同感知 (Collaborative Perception) / 3D 语义占据预测 (3D Semantic Occupancy Prediction)
## Reason for Interest

1. 创新性强：论文首次提出将3D Gaussian Splatting (3DGS) 作为V2X协同感知的通信介质。相比于传统的密集特征图或BEV特征，高斯原语作为稀疏、显式的3D表示，能够更高效地编码几何与语义信息，且天然支持刚性变换对齐，显著降低了通信带宽需求。
2. 实验效果显著：在仿真数据集上，不仅精度（mIoU/IoU）超越了现有的SOTA方法（CoHFF），而且验证了在低带宽限制下的鲁棒性，这对实际车联网部署极具价值。
3. 方法论合理：提出的'Gaussian Packaging'和'Cross-Agent Gaussian Fusion'模块设计简洁有效，解决了多智能体间数据融合的噪声和冗余问题。
4. 局限性：目前实验主要基于CARLA仿真环境（OPV2V），缺乏真实世界数据的验证（受限于行业数据现状），且对定位误差的鲁棒性分析可进一步加强。
## Abstract: 
Collaborative perception enables connected vehicles to share information, overcoming occlusions and extending the limited sensing range inherent in single-agent (non-collaborative) systems. Existing vision-only methods for 3D semantic occupancy prediction commonly rely on dense 3D voxels, which incur high communication costs, or 2D planar features, which require accurate depth estimation or additional supervision, limiting their applicability to collaborative scenarios. To address these challenges, we propose the first approach leveraging sparse 3D semantic Gaussian splatting for collaborative 3D semantic occupancy prediction. By sharing and fusing intermediate Gaussian primitives, our method provides three benefits: a neighborhood-based cross-agent fusion that removes duplicates and suppresses noisy or inconsistent Gaussians; a joint encoding of geometry and semantics in each primitive, which reduces reliance on depth supervision and allows simple rigid alignment; and sparse, object-centric messages that preserve structural information while reducing communication volume. Extensive experiments demonstrate that our approach outperforms single-agent perception and baseline collaborative methods by +8.42 and +3.28 points in mIoU, and +5.11 and +22.41 points in IoU, respectively. When further reducing the number of transmitted Gaussians, our method still achieves a +1.9 improvement in mIoU, using only 34.6% communication volume, highlighting robust performance under limited communication budgets.
