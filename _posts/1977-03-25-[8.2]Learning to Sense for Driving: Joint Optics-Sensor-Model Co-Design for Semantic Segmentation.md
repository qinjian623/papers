---
layout: default
title: "[8.2]Learning to Sense for Driving: Joint Optics-Sensor-Model Co-Design for Semantic Segmentation"
---

# [8.2] Learning to Sense for Driving: Joint Optics-Sensor-Model Co-Design for Semantic Segmentation

- Authors: Reeshad Khan amd John Gauch
- [arXiv Link](https://arxiv.org/abs/2512.20815)
- [PDF Link](https://arxiv.org/pdf/2512.20815.pdf)

## Subfields
 感知 / 软硬协同设计 (Sensor-Model Co-Design)
## Reason for Interest

该论文针对自动驾驶感知中的硬件与算法割裂问题，提出了一套完整的光学-传感器-模型联合优化框架。创新性强，将物理光学模型引入感知优化回路，有效提升了在低光、模糊等恶劣条件下的鲁棒性。极轻量化设计（<1M 参数）使其具有极高的工程应用价值，非常适合车载嵌入式平台。虽然在绝对精度指标上未超越大模型 SOTA，但在效率与鲁棒性的平衡上表现优异。扣分点在于主要依赖较旧的 KITTI-360 数据集，缺乏在大规模现代数据集（如 nuScenes）上的验证。
## Abstract: 
Traditional autonomous driving pipelines decouple camera design from downstream perception, relying on fixed optics and handcrafted ISPs that prioritize human viewable imagery rather than machine semantics. This separation discards information during demosaicing, denoising, or quantization, while forcing models to adapt to sensor artifacts. We present a task-driven co-design framework that unifies optics, sensor modeling, and lightweight semantic segmentation networks into a single end-to-end RAW-to-task pipeline. Building on DeepLens[19], our system integrates realistic cellphone-scale lens models, learnable color filter arrays, Poisson-Gaussian noise processes, and quantization, all optimized directly for segmentation objectives. Evaluations on KITTI-360 show consistent mIoU improvements over fixed pipelines, with optics modeling and CFA learning providing the largest gains, especially for thin or low-light-sensitive classes. Importantly, these robustness gains are achieved with a compact ~1M-parameter model running at ~28 FPS, demonstrating edge deployability. Visual and quantitative analyses further highlight how co-designed sensors adapt acquisition to semantic structure, sharpening boundaries and maintaining accuracy under blur, noise, and low bit-depth. Together, these findings establish full-stack co-optimization of optics, sensors, and networks as a principled path toward efficient, reliable, and deployable perception in autonomous systems.
