---
layout: default
title: "[7.5]From Human Intention to Action Prediction: A Comprehensive Benchmark for Intention-driven End-to-End Autonomous Driving"
---

# [7.5] From Human Intention to Action Prediction: A Comprehensive Benchmark for Intention-driven End-to-End Autonomous Driving

- Authors: Huan Zheng, Yucheng Zhou, Tianyi Yan, Jiayi Su, Hongjun Chen, Dubing Chen, Wencheng Han, ...
- [arXiv Link](https://arxiv.org/abs/2512.12302v1)
- [PDF Link](https://arxiv.org/pdf/2512.12302v1.pdf)

## Subfields
 端到端自动驾驶 / 具身智能 (Vision-Language-Action)
## Reason for Interest

1. **创新性 (8/10)**：论文敏锐地指出了当前端到端自动驾驶仅停留在“指令跟随”（如左转、右转）而无法理解复杂抽象意图（如“在右侧大楼旁停车”）的痛点。提出的 Intention-Drive 基准和基于 VLM 的 Intent Success Rate (ISR) 语义评测指标具有较强的前瞻性，推动了从 Navigation 到 Intention-Fulfillment 的范式转变。
2. **实验完整性 (6/10)**：虽然提出了一套完整的数据生成和评测流程，但实验部分仅评估了 InternVL3.0-2B 一个基线模型，缺乏对不同架构（如单纯的 LLM-Planner 或其他 VLA 模型）的广泛对比，使得结论的普适性稍显不足。
3. **数据与可信度 (7/10)**：数据集基于 OpenScene 构建，通过 VLM 分层生成标注并经人工校验，逻辑闭环。但数据集规模（训练集1359，测试集600）相对主流 E2E 数据集偏小。此外，ISR 指标依赖 VLM 进行自动化判定，虽然是解决语义评测的有效尝试，但“用模型评测模型”的方法在鲁棒性上仍需更多验证。
4. **行业价值 (8/10)**：该工作对于推动 L4/L5 级自动驾驶的人机交互和复杂场景理解具有重要参考价值，明确了当前技术的短板。
## Abstract: 

