---
layout: default
title: "[9.2]Text2Loc++: Generalizing 3D Point Cloud Localization from Natural Language"
---

# [9.2] Text2Loc++: Generalizing 3D Point Cloud Localization from Natural Language

- Authors: Yan Xia, Letian Shi, Yilin Di, Joao F. Henriques, Daniel Cremers
- [arXiv Link](https://arxiv.org/abs/2511.15308)
- [PDF Link](https://arxiv.org/pdf/2511.15308.pdf)

## Subfields
 语言引导的3D定位 / 跨模态检索 (Language-guided 3D Localization)
## Reason for Interest

该论文针对自动驾驶和机器人导航中的'最后一公里'问题，提出了一种基于自然语言描述在3D点云地图中进行定位的高精度框架Text2Loc++。其核心创新点极具价值：1）提出了掩码实例训练（MIT）和模态感知分层对比学习（MHCL），有效解决了自然语言描述模糊性带来的跨模态对齐难题；2）设计了无匹配（matching-free）的精细定位网络，摒弃了易错的显式文本-实例匹配步骤，通过原型地图克隆（PMC）和级联交叉注意力Transformer（CCAT）实现了端到端的高效定位，大幅提升了推理速度和精度；3）构建了包含多个城市（真实与合成数据）及不同文本复杂度的新基准数据集，充分验证了模型的跨场景泛化能力。论文逻辑严密，实验极其详尽（涵盖消融研究、鲁棒性分析、跨数据集测试），且由TUM和Oxford等顶尖团队完成，具有很高的学术和应用价值。
## Abstract: 
We tackle the problem of localizing 3D point cloud submaps using complex and diverse natural language descriptions, and present Text2Loc++, a novel neural network designed for effective cross-modal alignment between language and point clouds in a coarse-to-fine localization pipeline. To support benchmarking, we introduce a new city-scale dataset covering both color and non-color point clouds from diverse urban scenes, and organize location descriptions into three levels of linguistic complexity. In the global place recognition stage, Text2Loc++ combines a pretrained language model with a Hierarchical Transformer with Max pooling (HTM) for sentence-level semantics, and employs an attention-based point cloud encoder for spatial understanding. We further propose Masked Instance Training (MIT) to filter out non-aligned objects and improve multimodal robustness. To enhance the embedding space, we introduce Modality-aware Hierarchical Contrastive Learning (MHCL), incorporating cross-modal, submap-, text-, and instance-level losses. In the fine localization stage, we completely remove explicit text-instance matching and design a lightweight yet powerful framework based on Prototype-based Map Cloning (PMC) and a Cascaded Cross-Attention Transformer (CCAT). Extensive experiments on the KITTI360Pose dataset show that Text2Loc++ outperforms existing methods by up to 15%. In addition, the proposed model exhibits robust generalization when evaluated on the new dataset, effectively handling complex linguistic expressions and a wide variety of urban environments. The code and dataset will be made publicly available.
