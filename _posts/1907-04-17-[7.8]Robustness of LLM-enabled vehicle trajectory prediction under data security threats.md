---
layout: default
title: "[7.8]Robustness of LLM-enabled vehicle trajectory prediction under data security threats"
---

# [7.8] Robustness of LLM-enabled vehicle trajectory prediction under data security threats

- Authors: Feilong Wang, Fuqiang Liu
- [arXiv Link](https://arxiv.org/abs/2511.13753)
- [PDF Link](https://arxiv.org/pdf/2511.13753.pdf)

## Subfields
 轨迹预测 / 大模型 (LLM) / 对抗攻击与鲁棒性
## Reason for Interest

该论文针对当前自动驾驶领域热门的‘LLM轨迹预测’方向进行了系统性的安全性评估，具有较高的研究价值。主要亮点包括：1. 提出了针对驾驶场景Prompt中数值特征的差分进化（DE）黑盒攻击方法，揭示了LLM在处理物理运动参数时的脆弱性；2. 实验分析深入，不仅量化了攻击带来的性能下降（RMSE增加29%），还探讨了模型规模、微调深度对鲁棒性的影响；3. 发现思维链（CoT）推理能有效提升模型抵抗扰动的能力，为提升LLM车端应用的安全性提供了有益思路。尽管攻击算法本身属于现有优化方法的应用迁移，但其在特定垂直领域的分析填补了空白，对行业探索端到端大模型上车具有重要的警示和参考意义。
## Abstract: 
The integration of large language models (LLMs) into automated driving systems has opened new possibilities for reasoning and decision-making by transforming complex driving contexts into language-understandable representations. Recent studies demonstrate that fine-tuned LLMs can accurately predict vehicle trajectories and lane-change intentions by gathering and transforming data from surrounding vehicles. However, the robustness of such LLM-based prediction models for safety-critical driving systems remains unexplored, despite the increasing concerns about the trustworthiness of LLMs. This study addresses this gap by conducting a systematic vulnerability analysis of LLM-enabled vehicle trajectory prediction. We propose a one-feature differential evolution attack that perturbs a single kinematic feature of surrounding vehicles within the LLM's input prompts under a black-box setting. Experiments on the highD dataset reveal that even minor, physically plausible perturbations can significantly disrupt model outputs, underscoring the susceptibility of LLM-based predictors to adversarial manipulation. Further analyses reveal a trade-off between accuracy and robustness, examine the failure mechanism, and explore potential mitigation solutions. The findings provide the very first insights into adversarial vulnerabilities of LLM-driven automated vehicle models in the context of vehicular interactions and highlight the need for robustness-oriented design in future LLM-based intelligent transportation systems.
