---
layout: default
title: "[8.2]Universal Camouflage Attack on Vision-Language Models for Autonomous Driving"
---

# [8.2] Universal Camouflage Attack on Vision-Language Models for Autonomous Driving

- Authors: Dehong Kong, Sifan Yu, Siyuan Liang, Jiawei Liang, Jianhou Gan, Aishan Liu, Wenqi Ren
- [arXiv Link](https://arxiv.org/abs/2509.20196v1)
- [PDF Link](https://arxiv.org/pdf/2509.20196v1.pdf)

## Subfields
 自动驾驶安全 / VLM-AD 对抗攻击
## Reason for Interest

1. 创新性（8.5/10）：论文针对新兴的自动驾驶视觉语言模型（VLM-AD）提出了一种通用的物理伪装攻击框架（UCA）。不同于传统针对Logit层的攻击，该方法创新性地通过最小化特征差异损失（Feature Divergence Loss）攻击编码器和投影层特征，直接破坏多模态语义理解，且提出了多尺度训练和自适应视角采样策略，针对性解决了物理攻击在多视角下的鲁棒性问题。
2. 实验完整性（8.0/10）：论文定义了涵盖感知、预测、规划的全栈评估指标（3-P Metrics），并引入LLM Judge进行语义评估，实验设计较为全面。选择CARLA仿真器进行高保真验证是合理的。
3. 可信度与局限（7.5/10）：虽然论文标题强调“物理”攻击，且在仿真中模拟了物理环境（光照、视角），但根据文档内容，主要实验均在CARLA仿真中完成，未见真实车辆贴膜的实车路测数据，这在一定程度上限制了其宣称的“物理现实可行性”的说服力。
4. 行业价值（8.5/10）：随着VLM端到端自动驾驶成为趋势，其安全性至关重要。该研究揭示了VLM-AD在特征层的脆弱性，对设计更鲁棒的端到端大模型系统具有重要的警示和指导意义。
## Abstract: 

