---
layout: default
title: "[4.5]DensePercept-NCSSD: Vision Mamba towards Real-time Dense Visual Perception with Non-Causal State Space Duality"
---

# [4.5] DensePercept-NCSSD: Vision Mamba towards Real-time Dense Visual Perception with Non-Causal State Space Duality

- Authors: Tushar Anand, Advik Sinha, Abhijit Das
- [arXiv Link](https://arxiv.org/abs/2511.12671v1)
- [PDF Link](https://arxiv.org/pdf/2511.12671v1.pdf)

## Subfields
 2D感知 / 光流估计与双目深度预测
## Reason for Interest

该论文提出了结合Non-Causal State Space Duality (NC-SSD) 的Vision Mamba架构用于光流和视差估计，试图在保持精度的同时降低计算复杂度，选题符合自动驾驶对实时性的需求。然而，该论文存在致命的可信度问题：
1. 结果异常：论文声称在仅使用SceneFlow预训练（Zero-shot）的情况下，在KITTI15上达到了0.54的EPE和1.43%的F1-all。参考KITTI官方榜单，当前全监督的SOTA方法F1-all通常仍在4%-5%左右。该论文汇报的Zero-shot结果远超全监督SOTA数倍，这在物理和统计上极不合理，强烈暗示了评估代码存在Bug、测试集与训练集泄露（Testing on Training Data）或使用了非标准的简单子集。
2. 对比基准存疑：论文中复现的RAFT基准结果（EPE 2.45）也优于RAFT原论文汇报的泛化性能，进一步降低了实验数据的可信度。
3. 尽管Mamba架构在视觉任务中的应用具有探索价值，但基于目前呈现的“过于完美”的实验数据，无法判断该方法的真实有效性。建议对代码和评估流程进行彻底审查。
## Abstract: 

