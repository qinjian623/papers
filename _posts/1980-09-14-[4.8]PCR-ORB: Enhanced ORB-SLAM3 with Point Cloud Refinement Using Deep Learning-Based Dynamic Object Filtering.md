---
layout: default
title: "[4.8]PCR-ORB: Enhanced ORB-SLAM3 with Point Cloud Refinement Using Deep Learning-Based Dynamic Object Filtering"
---

# [4.8] PCR-ORB: Enhanced ORB-SLAM3 with Point Cloud Refinement Using Deep Learning-Based Dynamic Object Filtering

- Authors: Sheng-Kai Chen, Jie-Yu Chao, Jr-Yu Chang, Po-Lien Wu, Po-Chiang Lin
- [arXiv Link](https://arxiv.org/abs/2512.23318)
- [PDF Link](https://arxiv.org/pdf/2512.23318.pdf)

## Subfields
 Visual SLAM / 动态环境定位
## Reason for Interest

该论文属于工程应用型工作，创新性较低（YOLOv8 + ORB-SLAM3 是常见组合）。实验结果不稳定：虽然在部分动态场景（如 Seq 04）有提升，但在多个序列（05/06/08）中出现了性能退化（Degradation），且缺乏与其他动态 SLAM 方法的横向对比，难以证明其竞争力。
## Abstract: 
Visual Simultaneous Localization and Mapping (vSLAM) systems encounter substantial challenges in dynamic environments where moving objects compromise tracking accuracy and map consistency. This paper introduces PCR-ORB (Point Cloud Refinement ORB), an enhanced ORB-SLAM3 framework that integrates deep learning-based point cloud refinement to mitigate dynamic object interference. Our approach employs YOLOv8 for semantic segmentation combined with CUDA-accelerated processing to achieve real-time performance. The system implements a multi-stage filtering strategy encompassing ground plane estimation, sky region removal, edge filtering, and temporal consistency validation. Comprehensive evaluation on the KITTI dataset (sequences 00-09) demonstrates performance characteristics across different environmental conditions and scene types. Notable improvements are observed in specific sequences, with sequence 04 achieving 25.9% improvement in ATE RMSE and 30.4% improvement in ATE median. However, results show mixed performance across sequences, indicating scenario-dependent effectiveness. The implementation provides insights into dynamic object filtering challenges and opportunities for robust navigation in complex environments.
