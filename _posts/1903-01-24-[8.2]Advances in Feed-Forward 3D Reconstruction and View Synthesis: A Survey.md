---
layout: default
title: "[8.2]Advances in Feed-Forward 3D Reconstruction and View Synthesis: A Survey"
---

# [8.2] Advances in Feed-Forward 3D Reconstruction and View Synthesis: A Survey

- Authors: Jiahui Zhang, Yuelei Li, Anpei Chen, Muyu Xu, Kunhao Liu, Jianyuan Wang, Xiao-Xiao Long, ...
- [arXiv Link](https://arxiv.org/abs/2507.14501)
- [PDF Link](https://arxiv.org/pdf/2507.14501.pdf)

## Subfields
 3D 重建与新视角合成 (基础技术, 机器人与SLAM应用)
## Reason for Interest

该论文是一篇全面且及时的高质量综述，涵盖了前馈3D重建和新视角合成的最新进展。其创新性体现在提出了清晰的分类学，将现有方法根据底层场景表示（如NeRF、3DGS、点图、网格/SDF、3D-Free模型）进行归类。论文详尽地分析了各类别中的代表性方法、核心架构设计和特征表示，并总结了常用的数据集和评估指标，提供了多项任务的性能对比表格，使得该领域的研究人员能够快速了解当前的技术格局和最新SOTA方法。

尽管论文主要关注计算机视觉和图形学领域，但其在“任务与应用”章节中明确讨论了与自动驾驶直接相关的应用，例如“SLAM与视觉定位”和“机器人操作”。文中强调了前馈（feed-forward）方法在实现实时场景理解和跟踪方面的潜力，这对于自动驾驶系统（包括车端和更广泛的机器人系统）至关重要。论文识别的开放挑战，如数据集模态多样性限制、重建精度提升、自由视角合成的泛化性以及长上下文输入的计算效率，都与自动驾驶领域面临的关键问题高度相关。因此，尽管并非纯粹的车端自动驾驶论文，其内容对于自动驾驶研究具有极高的参考价值和行业潜力。

严格评分下，由于它是一个更广泛的计算机视觉领域综述，而非专注于车端自动驾驶的特定问题，因此未能获得最高分。但其作为综述的质量、内容的全面性、及时性以及与自动驾驶领域的显著交集，使其获得高分。
## Abstract: 
3D reconstruction and view synthesis are foundational problems in computer vision, graphics, and immersive technologies such as augmented reality (AR), virtual reality (VR), and digital twins. Traditional methods rely on computationally intensive iterative optimization in a complex chain, limiting their applicability in real-world scenarios. Recent advances in feed-forward approaches, driven by deep learning, have revolutionized this field by enabling fast and generalizable 3D reconstruction and view synthesis. This survey offers a comprehensive review of feed-forward techniques for 3D reconstruction and view synthesis, with a taxonomy according to the underlying representation architectures including point cloud, 3D Gaussian Splatting (3DGS), Neural Radiance Fields (NeRF), etc. We examine key tasks such as pose-free reconstruction, dynamic 3D reconstruction, and 3D-aware image and video synthesis, highlighting their applications in digital humans, SLAM, robotics, and beyond. In addition, we review commonly used datasets with detailed statistics, along with evaluation protocols for various downstream tasks. We conclude by discussing open research challenges and promising directions for future work, emphasizing the potential of feed-forward approaches to advance the state of the art in 3D vision.
