---
layout: default
title: "[4.5]Video4Spatial: Towards Visuospatial Intelligence with Context-Guided Video Generation"
---

# [4.5] Video4Spatial: Towards Visuospatial Intelligence with Context-Guided Video Generation

- Authors: Zeqi Xiao, Yiwei Zhao, Lingxiao Li, Yushi Lan, Ning Yu, Rahul Garg, Roshni Cooper, Mohamm...
- [arXiv Link](https://arxiv.org/abs/2512.03040v2)
- [PDF Link](https://arxiv.org/pdf/2512.03040v2.pdf)

## Subfields
 生成式世界模型 / 具身智能 (Generative World Models / Embodied AI)
## Reason for Interest

该论文是一篇高质量的计算机视觉与具身智能论文，提出利用视频生成模型作为世界模型来处理空间任务，方法具有创新性（如非连续上下文采样、辅助Bbox推理）。然而，严格依据自动驾驶领域的评审标准：1. 数据集完全局限于室内（ScanNet/ARKit），未涉及车端驾驶场景；2. 任务聚焦于室内导航与物体寻找，缺乏对道路交通、车辆控制或驾驶规划的适配。虽然'世界模型'是AD的热门方向，但本文目前的形态属于通用视觉/机器人研究，不直接通过车端自动驾驶的价值验证，因此依据规则分值受限。
## Abstract: 

