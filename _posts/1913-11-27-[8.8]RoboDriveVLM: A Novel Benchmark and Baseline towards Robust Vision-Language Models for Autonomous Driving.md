---
layout: default
title: "[8.8]RoboDriveVLM: A Novel Benchmark and Baseline towards Robust Vision-Language Models for Autonomous Driving"
---

# [8.8] RoboDriveVLM: A Novel Benchmark and Baseline towards Robust Vision-Language Models for Autonomous Driving

- Authors: Dacheng Liao, Mengshi Qi, Peng Shu, Zhining Zhang, Yuxin Lin, Liang Liu, Huadong Ma
- [arXiv Link](https://arxiv.org/abs/2512.01300)
- [PDF Link](https://arxiv.org/pdf/2512.01300.pdf)

## Subfields
 端到端自动驾驶 / VLM 鲁棒性测评 (End-to-end AD / VLM Robustness)
## Reason for Interest

1. 选题前瞻且关键：针对当前大热的 VLM 端到端驾驶，切中其最大的痛点——鲁棒性与安全性，特别是首次系统化地引入了针对 VLM 特性的“提示词腐蚀”（如恶意攻击、传输丢字）评测维度，创新性强。
2. 方法设计合理：提出的 RoboDriveBench 填补了 VLM 驾驶鲁棒性基准的空白；设计的 MCL2/MCC 指标通过惩罚无效输出，有效解决了 VLM 生成格式不稳定难以量化评估的问题；提出的跨模态蒸馏 TTA 方法在不依赖额外标注的情况下有效提升了抗噪能力。
3. 实验扎实：不仅对比了传统的 SOTA 端到端模型（UniAD, VAD），还高质量复现了闭源或难以复现的 VLM 驾驶模型（DriveVLM, OpenEMMA），实验工作量大且具有说服力。
4. 行业指导意义大：明确揭示了当前 VLM 模型在面对 Prompt 注入攻击时的脆弱性，为大模型上车的安全防御提供了重要参考。
## Abstract: 
Current Vision-Language Model (VLM)-based end-to-end autonomous driving systems often leverage large language models to generate driving decisions directly based on their understanding of the current scene. However, such systems introduce multiple risks in real-world driving scenarios. To evaluate whether VLMs are truly viable for autonomous driving, we introduce RoboDriveBench, the first robustness benchmark focused on end-to-end trajectory prediction tasks. This benchmark systematically evaluates two critical categories of real-world challenges for VLM-based end-to-end autonomous driving systems through 11 simulated scenarios encompassing various corruption types, including 6 scenarios of sensor corruption caused by environmental variations, along with 5 cases of prompt corruption resulting from human intervention and data transmission failures. Each corruption type includes 250 unique driving scenarios and 5,689 frames, resulting in 64,559 total trajectory prediction cases per evaluation. To overcome these real-world challenges, we propose a novel VLM-based autonomous driving framework called RoboDriveVLM, which enhances robustness by mapping more multimodal data-e.g., lidar and radar-into a unified latent space. Furthermore, we introduce a new Test-Time Adaptation (TTA) method based on cross-modal knowledge distillation to improve the robustness of VLM-based autonomous driving systems. Through extensive experiments, our work highlights the limitations of current VLM-based end-to-end autonomous driving systems and provides a more reliable solution for real-world deployment. Source code and datasets will be released.
