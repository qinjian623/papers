---
layout: default
title: "[9.2]From Forecasting to Planning: Policy World Model for Collaborative State-Action Prediction"
---

# [9.2] From Forecasting to Planning: Policy World Model for Collaborative State-Action Prediction

- Authors: Zhida Zhao, Talas Fu, Yifan Wang, Lijun Wang, Huchuan Lu
- [arXiv Link](https://arxiv.org/abs/2510.19654)
- [PDF Link](https://arxiv.org/pdf/2510.19654.pdf)

## Subfields
 端到端自动驾驶 / 生成式世界模型
## Reason for Interest

论文提出了一种名为Policy World Model (PWM) 的创新范式，成功解决了生成式世界模型如何显式辅助自动驾驶规划这一核心难题。其主要贡献包括：1. 协同状态-动作预测机制：不同于传统基于动作条件的视频生成，PWM先进行无动作的未来环境预测，再利用预测的未来特征指导轨迹规划，有效模拟了人类驾驶员的预判行为。2. 高效的并行生成架构：通过上下文引导的Tokenizer和并行的下一帧（而非下一Token）预测机制，大幅提升了推理速度（在不解码像素时可达40FPS），使其具备车端部署潜力。3. 动态焦点损失（Dynamic Focal Loss）：针对视频生成中动态物体模糊的问题，提出了针对性的损失函数，显著提升了动态场景的建模精度。实验数据详实，在主流数据集nuScenes和NAVSIM上均取得了SOTA级别的安全性和综合评分，展示了生成式世界模型在端到端规划中的巨大应用价值。
## Abstract: 
Despite remarkable progress in driving world models, their potential for autonomous systems remains largely untapped: the world models are mostly learned for world simulation and decoupled from trajectory planning. While recent efforts aim to unify world modeling and planning in a single framework, the synergistic facilitation mechanism of world modeling for planning still requires further exploration. In this work, we introduce a new driving paradigm named Policy World Model (PWM), which not only integrates world modeling and trajectory planning within a unified architecture, but is also able to benefit planning using the learned world knowledge through the proposed action-free future state forecasting scheme. Through collaborative state-action prediction, PWM can mimic the human-like anticipatory perception, yielding more reliable planning performance. To facilitate the efficiency of video forecasting, we further introduce a dynamically enhanced parallel token generation mechanism, equipped with a context-guided tokenizer and an adaptive dynamic focal loss. Despite utilizing only front camera input, our method matches or exceeds state-of-the-art approaches that rely on multi-view and multi-modal inputs. Code and model weights will be released at https://github.com/6550Zhao/Policy-World-Model.
