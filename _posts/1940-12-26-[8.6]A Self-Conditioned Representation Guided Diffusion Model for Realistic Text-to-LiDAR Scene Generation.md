---
layout: default
title: "[8.6]A Self-Conditioned Representation Guided Diffusion Model for Realistic Text-to-LiDAR Scene Generation"
---

# [8.6] A Self-Conditioned Representation Guided Diffusion Model for Realistic Text-to-LiDAR Scene Generation

- Authors: Wentao Qu, Guofeng Mei, Yang Wu, Yongshun Gong, Xiaoshui Huang, Liang Xiao
- [arXiv Link](https://arxiv.org/abs/2511.19004v2)
- [PDF Link](https://arxiv.org/pdf/2511.19004v2.pdf)

## Subfields
 自动驾驶仿真 / 3D场景生成 (LiDAR)
## Reason for Interest

1. 创新性强：提出了 SCRG（自条件表示引导）有效解决了 LiDAR 数据稀缺导致的生成细节丢失问题，并设计了 DPE（方向位置编码）解决了 Range Map 投影导致的几何畸变（如街道断裂），技术方案针对性强且逻辑严密。
2. 实验充分：在多个主流数据集上进行了无条件、文本引导及多种条件（如 ControlNet 应用）的生成实验，不仅在 FID 等传统生成指标上达成 SOTA，还通过自建的 T2nuScenes 基准和 TBR 指标验证了更优的可控性。
3. 应用价值：论文展示了从文本、语义图生成高质量 LiDAR 点云的能力，甚至支持 Sparse-to-Dense 的补全任务，这对于自动驾驶解决长尾数据（如恶劣天气、特定交互场景）的合成与扩增具有直接且重要的实用价值。
## Abstract: 

