---
layout: default
title: "[8.8]VIGS-SLAM: Visual Inertial Gaussian Splatting SLAM"
---

# [8.8] VIGS-SLAM: Visual Inertial Gaussian Splatting SLAM

- Authors: Zihan Zhu, Wei Zhang, Norbert Haala, Marc Pollefeys, Daniel Barath
- [arXiv Link](https://arxiv.org/abs/2512.02293)
- [PDF Link](https://arxiv.org/pdf/2512.02293.pdf)

## Subfields
 Visual-Inertial SLAM / 3D Gaussian Splatting
## Reason for Interest

该论文提出了一种紧耦合的视觉惯性3D Gaussian Splatting SLAM系统（VIGS-SLAM），主要贡献和价值如下：
1. **创新性**：将DROID-SLAM风格的密集视觉前端与IMU预积分紧密结合，并引入针对3DGS地图的闭环校正机制（Pose Graph优化后高效更新Gaussian参数），有效解决了纯视觉GS-SLAM在快速运动或纹理缺失下的鲁棒性问题，同时解决了传统VIO无法生成高保真稠密地图的问题。
2. **实验完整性**：在室内（EuRoC, RPNG）和室外/剧烈运动（FAST-LIVO2）数据集上进行了广泛测试，对比了包括ORB-SLAM3、VINS-Mono等经典VIO和Splat-SLAM等最新GS-SLAM方法。特别是通过“Strided Evaluation”（抽帧测试）有力证明了引入IMU对低帧率/数据丢失场景的鲁棒性提升。
3. **行业潜力**：3DGS是目前自动驾驶高精地图构建和仿真重建的热门方向，该工作将VIO的鲁棒性与3DGS的高保真性结合，对自动驾驶中的实时定位与稠密建图具有很高的参考价值。尽管目前计算量较大（依赖高端GPU），但算法框架具有先进性。
## Abstract: 
We present VIGS-SLAM, a visual-inertial 3D Gaussian Splatting SLAM system that achieves robust real-time tracking and high-fidelity reconstruction. Although recent 3DGS-based SLAM methods achieve dense and photorealistic mapping, their purely visual design degrades under motion blur, low texture, and exposure variations. Our method tightly couples visual and inertial cues within a unified optimization framework, jointly refining camera poses, depths, and IMU states. It features robust IMU initialization, time-varying bias modeling, and loop closure with consistent Gaussian updates. Experiments on four challenging datasets demonstrate our superiority over state-of-the-art methods. Project page: https://vigs-slam.github.io
