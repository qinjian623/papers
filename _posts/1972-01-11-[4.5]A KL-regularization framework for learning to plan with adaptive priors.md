---
layout: default
title: "[4.5]A KL-regularization framework for learning to plan with adaptive priors"
---

# [4.5] A KL-regularization framework for learning to plan with adaptive priors

- Authors: Álvaro Serra-Gomez, Daniel Jarne Ornia, Dhruva Tirumala, Thomas Moerland
- [arXiv Link](https://arxiv.org/abs/2510.04280v1)
- [PDF Link](https://arxiv.org/pdf/2510.04280v1.pdf)

## Subfields
 规划控制 / 强化学习 (Planning & Control / MBRL)
## Reason for Interest

论文提出了一种统一MPPI规划与策略优化的KL正则化框架（PO-MPC），在理论上具有较高的创新性，有效解决了策略与规划分布不匹配的问题，并在高维机器人控制任务上验证了其有效性。然而，该研究完全基于通用机器人仿真环境（人形机器人、机器狗），未涉及任何自动驾驶车辆特定的动力学、交通场景或数据集。尽管MPC技术本身适用于自动驾驶控制，但该论文属于通用机器人/强化学习基础研究，不直接针对车端自动驾驶应用，根据严格评分标准（非直接车端相关封顶5分），给予4.5分。
## Abstract: 

