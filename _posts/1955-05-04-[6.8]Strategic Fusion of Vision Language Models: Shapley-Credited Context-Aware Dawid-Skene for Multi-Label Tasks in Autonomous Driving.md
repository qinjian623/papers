---
layout: default
title: "[6.8]Strategic Fusion of Vision Language Models: Shapley-Credited Context-Aware Dawid-Skene for Multi-Label Tasks in Autonomous Driving"
---

# [6.8] Strategic Fusion of Vision Language Models: Shapley-Credited Context-Aware Dawid-Skene for Multi-Label Tasks in Autonomous Driving

- Authors: Yuxiang Feng, Keyang Zhang, Hassane Ouchouid, Ashwil Kaniamparambil, Ioannis Souflas, Pan...
- [arXiv Link](https://arxiv.org/abs/2510.01126v1)
- [PDF Link](https://arxiv.org/pdf/2510.01126v1.pdf)

## Subfields
 Scene Understanding / VLM Decision Making (场景理解 / VLM 决策)
## Reason for Interest

Innovation: The paper introduces a novel game-theoretic fusion framework (Shapley-credited Context-Aware Dawid–Skene) to mitigate VLM hallucinations, which is theoretically grounded and addresses a critical safety issue in AVs.

Credibility & Experiments: The experimental validation is limited. It relies on a small, custom subset (1,000 clips) of the HDD dataset rather than the full standard benchmark, making direct comparison with the broader industry impossible. The ground truth generation relies partially on an automated pipeline (LLaMA-3.2 CoT), introducing potential bias despite manual review.

Practicality: While the method improves reliability, the computational cost of running an ensemble of three heterogeneous VLMs (requiring 2x RTX A6000 for experiments) makes it currently impractical for real-time onboard deployment in production vehicles. It is more suitable as an offline data curation or teacher model tool.
## Abstract: 

