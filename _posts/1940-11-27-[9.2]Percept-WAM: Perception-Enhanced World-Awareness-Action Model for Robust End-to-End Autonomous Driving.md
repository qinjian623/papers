---
layout: default
title: "[9.2]Percept-WAM: Perception-Enhanced World-Awareness-Action Model for Robust End-to-End Autonomous Driving"
---

# [9.2] Percept-WAM: Perception-Enhanced World-Awareness-Action Model for Robust End-to-End Autonomous Driving

- Authors: Jianhua Han, Meng Tian, Jiangtong Zhu, Fan He, Huixin Zhang, Sitong Guo, Dechang Zhu, Hao...
- [arXiv Link](https://arxiv.org/abs/2511.19221v1)
- [PDF Link](https://arxiv.org/pdf/2511.19221v1.pdf)

## Subfields
 端到端自动驾驶 / VLA (Vision-Language-Action) 模型 / 轨迹预测
## Reason for Interest

该论文提出了一种极具创新性的端到端自动驾驶框架Percept-WAM，有效地解决了现有VLM（视觉语言模型）在空间感知和几何推理方面的短板。

1. **创新性强**：提出了World-PV和World-BEV Token机制，将2D和3D感知任务统一编码到VLM中，并设计了IoU感知评分和并行自回归解码，这种将显式几何约束引入VLM的方法在端到端领域具有重要参考价值。
2. **实验结果扎实**：在权威的NAVSIM闭环仿真基准上取得了SOTA成绩（PDMS 90.2），证明了其规划策略的有效性。虽然在nuScenes纯3D检测指标上未完全超越最强专家模型（如BEVFusion），但在统一架构下实现了极具竞争力的感知性能，且显著优于PointPillars等经典方法。
3. **方法论完善**：论文不仅验证了感知性能，还通过两阶段训练和流式推理（Streaming Inference）优化了端到端规划的实时性和准确性。
4. **行业价值高**：展示了VLM大模型在保留通用推理能力的同时，通过特定设计具备高精度自动驾驶感知与决策能力的潜力，是当前大模型上车的重要探索方向。
## Abstract: 

