---
layout: default
title: "[7.8]M2H: Multi-Task Learning with Efficient Window-Based Cross-Task Attention for Monocular Spatial Perception"
---

# [7.8] M2H: Multi-Task Learning with Efficient Window-Based Cross-Task Attention for Monocular Spatial Perception

- Authors: U. V. B. L Udugama, George Vosselman, Francesco Nex
- [arXiv Link](https://arxiv.org/abs/2510.17363v1)
- [PDF Link](https://arxiv.org/pdf/2510.17363v1.pdf)

## Subfields
 单目视觉感知 / 多任务学习 (Monocular Perception / Multi-Task Learning)
## Reason for Interest

1. **创新性与架构设计**：论文提出了M2H框架，核心在于“窗口化跨任务注意力模块（WMCA）”和“全局门控特征融合（GGFM）”。这种设计有效解决了多任务学习中局部细节交互与全局上下文平衡的难题，且基于高效的DINOv2 ViT骨干网，架构逻辑清晰，针对性强。

2. **车端相关性与泛化能力**：虽然论文花费大量篇幅验证室内场景（NYUDv2, Hypersim）并应用于3D场景图构建（通常偏机器人领域），但其在**Cityscapes**数据集上的表现证明了该方法在自动驾驶室外场景的有效性。它在语义分割和深度估计上均优于SwinMTL（2024），表明其不仅适用于室内，也能作为车端低算力感知的有力候选方案。

3. **实验完整性与SOTA验证**：实验对比了包括MTMamba++、SwinMTL、InvPT在内的多种最新方法。在Cityscapes上的对比虽不如室内数据集详尽，但足以支撑其性能优越的结论。提供了详细的消融实验证明各模块价值。

4. **工程价值与效率**：论文强调“实时性”，在RTX 3080 Laptop上达到30 FPS。虽然这并非车规级嵌入式芯片的实测数据，但81M的参数量（相比MTMamba++的315M）显示了其在边缘计算设备上的部署潜力，符合自动驾驶降本增效的趋势。

5. **扣分项**：Cityscapes的对比竞品主要集中在通用的多任务框架，缺少与自动驾驶领域专用SOTA（如针对长尾问题或特定Corner Case优化的模型）的深度对比；且主要应用场景演示偏向于室内建图。
## Abstract: 

