---
layout: default
title: "[5.0]Read or Ignore? A Unified Benchmark for Typographic-Attack Robustness and Text Recognition in Vision-Language Models"
---

# [5.0] Read or Ignore? A Unified Benchmark for Typographic-Attack Robustness and Text Recognition in Vision-Language Models

- Authors: Futa Waseda, Shojiro Yamabe, Daiki Shiono, Kento Sasaki, Tsubasa Takahashi
- [arXiv Link](https://arxiv.org/abs/2512.11899)
- [PDF Link](https://arxiv.org/pdf/2512.11899.pdf)

## Subfields
 大模型 / 模型安全 (Large Models / Model Safety)
## Reason for Interest

1. 创新性与价值：论文敏锐地指出了视觉语言模型（VLM）在'排版攻击'防御与'文本阅读'能力之间的内在矛盾，提出了'Read-or-Ignore'（按需读取）的新任务和RIO-RT训练方法，这对未来基于VLM的端到端自动驾驶系统（如区分路牌指令与车身广告干扰）具有重要的安全理论价值。由自动驾驶公司（Turing Inc.）主导也印证了其行业相关性。
2. 缺陷与评分理由：尽管动机与自动驾驶安全高度相关，但这本质上是一篇通用计算机视觉领域的论文。其实验完全基于通用数据集（TextVQA, Open Images），未在nuScenes、Waymo或任何驾驶专用数据集上进行验证，也未展示该方法在自动驾驶感知或规划闭环中的实际效果。根据评分规则'如果不直接和车端自动驾驶相关（即缺乏车端场景/数据验证），最多5分'，故给出5.0分。
## Abstract: 
Large vision-language models (LVLMs) are vulnerable to typographic attacks, where misleading text within an image overrides visual understanding. Existing evaluation protocols and defenses, largely focused on object recognition, implicitly encourage ignoring text to achieve robustness; however, real-world scenarios often require joint reasoning over both objects and text (e.g., recognizing pedestrians while reading traffic signs). To address this, we introduce a novel task, Read-or-Ignore VQA (RIO-VQA), which formalizes selective text use in visual question answering (VQA): models must decide, from context, when to read text and when to ignore it. For evaluation, we present the Read-or-Ignore Benchmark (RIO-Bench), a standardized dataset and protocol that, for each real image, provides same-scene counterfactuals (read / ignore) by varying only the textual content and question type. Using RIO-Bench, we show that strong LVLMs and existing defenses fail to balance typographic robustness and text-reading capability, highlighting the need for improved approaches. Finally, RIO-Bench enables a novel data-driven defense that learns adaptive selective text use, moving beyond prior non-adaptive, text-ignoring defenses. Overall, this work reveals a fundamental misalignment between the existing evaluation scope and real-world requirements, providing a principled path toward reliable LVLMs. Our Project Page is at https://turingmotors.github.io/rio-vqa/.
