---
layout: default
title: "[8.8]Graph Query Networks for Object Detection with Automotive Radar"
---

# [8.8] Graph Query Networks for Object Detection with Automotive Radar

- Authors: Loveneet Saini, Hasan Tercan, Tobias Meisen
- [arXiv Link](https://arxiv.org/abs/2511.15271)
- [PDF Link](https://arxiv.org/pdf/2511.15271.pdf)

## Subfields
 3D感知 / 毫米波雷达目标检测
## Reason for Interest

该论文提出了一种针对毫米波雷达稀疏性和不规则性设计的图查询网络（GQN），创新性地利用动态图查询（Graph Queries）在BEV空间中进行特征采样和关系推理，有效弥补了传统网格或序列模型在处理稀疏雷达点云时的不足。实验设计严谨，在PointPillars、CenterPoint、AttentiveGRU等多个基线上均实现了显著的性能提升（最高相对提升53%），且保持了实时运行速度（21 FPS）。该方法作为即插即用的模块具有很高的工程应用价值，且在nuScenes这一主流数据集上建立了新的雷达纯视觉感知性能基准。
## Abstract: 
Object detection with 3D radar is essential for 360-degree automotive perception, but radar's long wavelengths produce sparse and irregular reflections that challenge traditional grid and sequence-based convolutional and transformer detectors. This paper introduces Graph Query Networks (GQN), an attention-based framework that models objects sensed by radar as graphs, to extract individualized relational and contextual features. GQN employs a novel concept of graph queries to dynamically attend over the bird's-eye view (BEV) space, constructing object-specific graphs processed by two novel modules: EdgeFocus for relational reasoning and DeepContext Pooling for contextual aggregation. On the NuScenes dataset, GQN improves relative mAP by up to +53%, including a +8.2% gain over the strongest prior radar method, while reducing peak graph construction overhead by 80% with moderate FLOPs cost.
