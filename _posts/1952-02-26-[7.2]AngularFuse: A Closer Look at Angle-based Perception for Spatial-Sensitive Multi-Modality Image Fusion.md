---
layout: default
title: "[7.2]AngularFuse: A Closer Look at Angle-based Perception for Spatial-Sensitive Multi-Modality Image Fusion"
---

# [7.2] AngularFuse: A Closer Look at Angle-based Perception for Spatial-Sensitive Multi-Modality Image Fusion

- Authors: Xiaopeng Liu, Yupei Lin, Sen Zhang, Xiao Wang, Yukai Shi, Liang Lin
- [arXiv Link](https://arxiv.org/abs/2510.12260v1)
- [PDF Link](https://arxiv.org/pdf/2510.12260v1.pdf)

## Subfields
 感知 / 多传感器融合 (可见光与红外图像融合)
## Reason for Interest

论文提出了一种名为 AngularFuse 的无监督图像融合框架，针对现有方法忽略梯度方向和参考图像质量差的问题，设计了角度感知损失和细粒度参考图像合成模块。

优点：
1. 创新性：引入梯度方向约束（Cosine Similarity）来保持边缘纹理方向，配合互补掩码策略（ComMask），在无监督设置下有效提升了融合质量。
2. 实时性：模型参数量仅 1.62M，推理时间 26ms (RTX3090)，具备极高的车端部署潜力，符合自动驾驶对低延迟的要求。
3. 实验效果：在三个主流数据集上对比了 2023-2025 年的 SOTA 方法，且在传统的图像质量指标（如熵、标准差、SSIM）上均取得显著领先。

缺点（扣分点）：
虽然论文声称对自动驾驶有重要意义，但评估主要集中在信号层面的图像质量指标（Image Quality Assessment），缺乏对下游感知任务（如目标检测 mAP、语义分割 IoU）的定量增益验证。在自动驾驶领域，图像融合的最终目的是提升感知准确率，仅凭图像看着更清晰或熵更高，难以完全证明其对系统的实际价值。因此，尽管算法设计精巧且高效，但因缺乏下游任务验证，评分受到一定限制。
## Abstract: 

