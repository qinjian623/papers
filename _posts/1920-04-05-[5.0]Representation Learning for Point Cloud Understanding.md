---
layout: default
title: "[5.0]Representation Learning for Point Cloud Understanding"
---

# [5.0] Representation Learning for Point Cloud Understanding

- Authors: Siming Yan
- [arXiv Link](https://arxiv.org/abs/2512.06058)
- [PDF Link](https://arxiv.org/pdf/2512.06058.pdf)

## Subfields
 3D感知 / 点云表征学习 (3D Perception / Point Cloud Representation Learning)
## Reason for Interest

该博士学位论文集合了多篇发表于ICCV和ICLR的高质量论文，提出了HPNet（图元分割）、IAE（隐式自编码器）、MaskFeat3D（掩码特征预测）和MVNet（2D-3D迁移学习）等创新方法。技术上，引入隐式表示作为解码器输出以及利用2D预训练大模型指导3D特征学习是非常前沿且具有价值的方向。然而，论文的所有实验均基于室内RGB-D数据集（ScanNet, S3DIS, SUN RGB-D）或合成物体数据集（ShapeNet, ModelNet），完全缺乏在室外大规模稀疏LiDAR数据集（如nuScenes, Waymo）上的验证。由于室内密集点云与自动驾驶场景下的稀疏雷达点云存在显著的域差异，且严格评分标准要求未直接涉及车端自动驾驶的研究最高给5分，因此尽管学术价值很高，综合评分受限于应用场景的直接相关性。
## Abstract: 
With the rapid advancement of technology, 3D data acquisition and utilization have become increasingly prevalent across various fields, including computer vision, robotics, and geospatial analysis. 3D data, captured through methods such as 3D scanners, LiDARs, and RGB-D cameras, provides rich geometric, shape, and scale information. When combined with 2D images, 3D data offers machines a comprehensive understanding of their environment, benefiting applications like autonomous driving, robotics, remote sensing, and medical treatment. This dissertation focuses on three main areas: supervised representation learning for point cloud primitive segmentation, self-supervised learning methods, and transfer learning from 2D to 3D. Our approach, which integrates pre-trained 2D models to support 3D network training, significantly improves 3D understanding without merely transforming 2D data. Extensive experiments validate the effectiveness of our methods, showcasing their potential to advance point cloud representation learning by effectively integrating 2D knowledge.
