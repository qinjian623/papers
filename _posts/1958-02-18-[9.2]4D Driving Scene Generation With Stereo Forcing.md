---
layout: default
title: "[9.2]4D Driving Scene Generation With Stereo Forcing"
---

# [9.2] 4D Driving Scene Generation With Stereo Forcing

- Authors: Hao Lu, Zhuang Ma, Guangfeng Jiang, Wenhang Ge, Bohan Li, Yuzhan Cai, Wenzhao Zheng, Yunp...
- [arXiv Link](https://arxiv.org/abs/2509.20251v1)
- [PDF Link](https://arxiv.org/pdf/2509.20251v1.pdf)

## Subfields
 自动驾驶仿真 / 世界模型 (World Models) / 4D场景生成
## Reason for Interest

1. **创新性强**：论文提出了PhiGenesis框架，实现了无需逐场景优化（Per-scene Optimization）的泛化式4D场景生成。核心创新点'Stereo Forcing'（立体强迫）机制，巧妙地利用几何不确定性图（Uncertainty Map）来引导视频扩散模型的去噪过程，有效解决了生成模型中的几何曝光偏差问题。
2. **实验完整**：在Waymo和nuScenes两大主流数据集上进行了详尽的评估，涵盖了4D重建、新视角合成、长视频生成等多个任务。不仅对比了最新的生成式前馈方法（如STORM, Omni-Scene），还对比了逐场景优化方法（如3DGS, EmerNeRF），结果具有说服力。
3. **行业价值高**：论文通过UniAD验证了生成视频在下游感知和规划任务中的有效性（Table 9），证明了该方法生成的数据可直接用于增强自动驾驶系统的鲁棒性，契合当前自动驾驶数据闭环和世界模型的研究热点。
4. **技术深度**：结合了视频VAE、Range-View Adapter和3D Gaussian Splatting，技术路线先进且自洽，解决了传统方法在时空一致性上的痛点。
## Abstract: 

