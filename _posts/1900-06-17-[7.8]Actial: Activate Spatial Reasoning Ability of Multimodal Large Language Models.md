---
layout: default
title: "[7.8]Actial: Activate Spatial Reasoning Ability of Multimodal Large Language Models"
---

# [7.8] Actial: Activate Spatial Reasoning Ability of Multimodal Large Language Models

- Authors: Xiaoyu Zhan, Wenxuan Huang, Hao Sun, Xinyu Fu, Changfeng Ma, Shaosheng Cao, Bohan Jia, Sh...
- [arXiv Link](https://arxiv.org/abs/2511.01618)
- [PDF Link](https://arxiv.org/pdf/2511.01618.pdf)

## Subfields
 多模态大模型在自动驾驶中的应用 / 空间推理
## Reason for Interest

这篇论文聚焦于提升多模态大模型（MLLMs）在3D空间推理方面的能力，这对于未来自动驾驶系统中MLLMs进行高级感知和决策至关重要。论文创新性强，提出了Viewpoint Learning任务和Viewpoint-100K数据集，并设计了两阶段（SFT+RL）微调策略及混合冷启动初始化方法来注入空间基础知识并增强泛化能力，有效解决了MLLMs依赖2D线索、缺乏3D一致性理解的核心痛点。实验在多个主流空间推理基准上进行了全面评估，并与多款先进MLLMs进行了对比，结果证明了方法的有效性，特别是在其提出的Viewpoint任务上取得了近乎完美的表现，并在CV-Bench上超越了现有专有模型。虽然它不是直接的BEV感知或规划控制模块，但其目标是为自动驾驶等自主系统提供更强大、更可靠的MLLM“大脑”基础能力，使其能从多视角图像中进行鲁棒的3D场景理解和推理，这与车端自动驾驶的高级智能需求直接相关，具有重要的行业潜力。因此，其价值远超一般性AI研究，符合自动驾驶大模型方向的深入探讨。
## Abstract: 
Recent advances in Multimodal Large Language Models (MLLMs) have significantly improved 2D visual understanding, prompting interest in their application to complex 3D reasoning tasks. However, it remains unclear whether these models can effectively capture the detailed spatial information required for robust real-world performance, especially cross-view consistency, a key requirement for accurate 3D reasoning. Considering this issue, we introduce Viewpoint Learning, a task designed to evaluate and improve the spatial reasoning capabilities of MLLMs. We present the Viewpoint-100K dataset, consisting of 100K object-centric image pairs with diverse viewpoints and corresponding question-answer pairs. Our approach employs a two-stage fine-tuning strategy: first, foundational knowledge is injected to the baseline MLLM via Supervised Fine-Tuning (SFT) on Viewpoint-100K, resulting in significant improvements across multiple tasks; second, generalization is enhanced through Reinforcement Learning using the Group Relative Policy Optimization (GRPO) algorithm on a broader set of questions. Additionally, we introduce a hybrid cold-start initialization method designed to simultaneously learn viewpoint representations and maintain coherent reasoning thinking. Experimental results show that our approach significantly activates the spatial reasoning ability of MLLM, improving performance on both in-domain and out-of-domain reasoning tasks. Our findings highlight the value of developing foundational spatial skills in MLLMs, supporting future progress in robotics, autonomous systems, and 3D scene understanding.
