---
layout: default
title: "[7.0]Compressing Multi-Task Model for Autonomous Driving via Pruning and Knowledge Distillation"
---

# [7.0] Compressing Multi-Task Model for Autonomous Driving via Pruning and Knowledge Distillation

- Authors: Jiayuan Wang, Q. M. Jonathan Wu, Ning Zhang, Katsuya Suto, Lei Zhong
- [arXiv Link](https://arxiv.org/abs/2511.05557v1)
- [PDF Link](https://arxiv.org/pdf/2511.05557v1.pdf)

## Subfields
 多任务感知 (Multi-task Perception) / 模型压缩 (Model Compression)
## Reason for Interest

论文针对自动驾驶多任务感知模型，提出了一种结合梯度冲突惩罚的‘安全剪枝’策略和非特定头部的特征蒸馏方法，方法论具有一定的创新性和合理性，能够有效应对多任务间的优化冲突。然而，实验结果存在明显短板：1. 尽管实现了32.7%的参数压缩，但在RTX 4090上的推理速度几乎没有提升（仅+0.1 FPS），这使得其在实时性要求极高的车载部署中的实际价值大打折扣；2. 相比轻量级基线（如YOLOP），该模型虽然精度更高，但参数量和计算量仍大得多，并未在‘效率-精度’权衡上取得突破性进展；3. 缺乏在真实嵌入式计算平台（如Orin）上的验证，无法证明其不仅节省存储还能加速推理。
## Abstract: 

