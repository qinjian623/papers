---
layout: default
title: "[9.2]OmniDrive-R1: Reinforcement-driven Interleaved Multi-modal Chain-of-Thought for Trustworthy Vision-Language Autonomous Driving"
---

# [9.2] OmniDrive-R1: Reinforcement-driven Interleaved Multi-modal Chain-of-Thought for Trustworthy Vision-Language Autonomous Driving

- Authors: Zhenguo Zhang, Haohan Zhen, Yishen Wang, Le Xu, Tianchen Deng, Xuefeng Chen, Qu Chen, Bo ...
- [arXiv Link](https://arxiv.org/abs/2512.14044v1)
- [PDF Link](https://arxiv.org/pdf/2512.14044v1.pdf)

## Subfields
 端到端自动驾驶 / VLM 认知推理 / 可解释性驾驶
## Reason for Interest

1. 创新性极高：论文提出了一种基于强化学习（RL）的端到端VLM框架，核心在于Clip-GRPO算法，利用CLIP的跨模态一致性作为奖励，在无需昂贵边界框标注的情况下，训练模型主动使用'Zoom-in'工具进行细粒度视觉定位（Visual Grounding）。这种模仿人类驾驶员'注视'关键区域的机制非常符合自动驾驶感知逻辑。
2. 解决痛点：针对VLM在自动驾驶中常见的幻觉问题，通过强制视觉与推理过程的对齐（Interleaved Multi-modal CoT），显著提高了系统的可信度和安全性。
3. 实验扎实：在主流推理基准DriveLMM-o1上取得了全面SOTA，且相比基座模型（Qwen2.5VL-7B）提升巨大（Reasoning +28.58%），证明了RL微调的有效性。同时进行了充分的消融实验验证了两阶段训练和Reward设计的必要性。
4. 行业价值：该方法探索了利用强化学习（类似DeepSeek-R1的思路）来增强VLM在驾驶场景中的物理感知能力，为构建高认知的自动驾驶Agent提供了极具潜力的技术路径。
## Abstract: 

