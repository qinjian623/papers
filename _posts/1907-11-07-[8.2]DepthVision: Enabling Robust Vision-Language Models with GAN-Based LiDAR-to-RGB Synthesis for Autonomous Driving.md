---
layout: default
title: "[8.2]DepthVision: Enabling Robust Vision-Language Models with GAN-Based LiDAR-to-RGB Synthesis for Autonomous Driving"
---

# [8.2] DepthVision: Enabling Robust Vision-Language Models with GAN-Based LiDAR-to-RGB Synthesis for Autonomous Driving

- Authors: Sven Kirchner, Nils Purschke, Ross Greer, Alois C. Knoll
- [arXiv Link](https://arxiv.org/abs/2509.07463)
- [PDF Link](https://arxiv.org/pdf/2509.07463.pdf)

## Subfields
 Vision-Language Models (VLM) / 多模态融合 (Multimodal Fusion)
## Reason for Interest

论文提出了一种创新的'跨模态转换'思路，通过GAN将稀疏LiDAR点云转换为类RGB图像，从而允许冻结参数的预训练视觉-语言模型（VLM）直接利用LiDAR信息，无需重新训练。这种方法巧妙地解决了VLM在夜间/低光照下失效的问题。亮点在于完整的工程实现，包括Luminance-Aware融合策略以及实车在环（Vehicle-in-the-Loop）的验证，证明了系统的实时性和实用潜力。主要扣分点在于评估主要基于自建的VQA任务子集，缺乏与主流3D检测/融合算法在标准榜单上的直接对比，且依赖GAN生成纹理可能在极端情况下存在幻觉风险。
## Abstract: 
Ensuring reliable autonomous operation when visual input is degraded remains a key challenge in intelligent vehicles and robotics. We present DepthVision, a multimodal framework that enables Vision--Language Models (VLMs) to exploit LiDAR data without any architectural changes or retraining. DepthVision synthesizes dense, RGB-like images from sparse LiDAR point clouds using a conditional GAN with an integrated refiner, and feeds these into off-the-shelf VLMs through their standard visual interface. A Luminance-Aware Modality Adaptation (LAMA) module fuses synthesized and real camera images by dynamically weighting each modality based on ambient lighting, compensating for degradation such as darkness or motion blur. This design turns LiDAR into a drop-in visual surrogate when RGB becomes unreliable, effectively extending the operational envelope of existing VLMs. We evaluate DepthVision on real and simulated datasets across multiple VLMs and safety-critical tasks, including vehicle-in-the-loop experiments. The results show substantial improvements in low-light scene understanding over RGB-only baselines while preserving full compatibility with frozen VLM architectures. These findings demonstrate that LiDAR-guided RGB synthesis is a practical pathway for integrating range sensing into modern vision-language systems for autonomous driving.
