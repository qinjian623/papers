---
layout: default
title: "[4.2]3D Ground Truth Reconstruction from Multi-Camera Annotations Using UKF"
---

# [4.2] 3D Ground Truth Reconstruction from Multi-Camera Annotations Using UKF

- Authors: Linh Van Ma, Unse Fatima, Tepy Sokun Chriv, Haroon Imran, Moongu Jeon
- [arXiv Link](https://arxiv.org/abs/2511.17609)
- [PDF Link](https://arxiv.org/pdf/2511.17609.pdf)

## Subfields
 数据标注与真值生成 / 路侧感知 (Data Annotation / Infrastructure Perception)
## Reason for Interest

1. 论文定位：提出一种利用无迹卡尔曼滤波（UKF）融合多视角2D标注来生成3D真值（位置+形状）的工具，属于自动驾驶基础设施中的离线数据处理环节，而非车端实时感知算法。
2. 适用性限制：该方法高度依赖多相机对同一区域的重叠覆盖（典型的监控或路侧感知视角），不适用于车端单车智能场景（视野重叠小），因此与车端自动驾驶的相关性较弱。
3. 创新性：方法论较为传统，使用几何投影和经典滤波算法，缺乏前沿的深度学习或大模型技术引入。
4. 价值：对于低成本构建路侧感知（V2X）数据集有一定工程价值，能从2D视频中恢复3D信息，但评分受限于严格的‘车端相关性’标准。
## Abstract: 
Accurate 3D ground truth estimation is critical for applications such as autonomous navigation, surveillance, and robotics. This paper introduces a novel method that uses an Unscented Kalman Filter (UKF) to fuse 2D bounding box or pose keypoint ground truth annotations from multiple calibrated cameras into accurate 3D ground truth. By leveraging human-annotated ground-truth 2D, our proposed method, a multi-camera single-object tracking algorithm, transforms 2D image coordinates into robust 3D world coordinates through homography-based projection and UKF-based fusion. Our proposed algorithm processes multi-view data to estimate object positions and shapes while effectively handling challenges such as occlusion. We evaluate our method on the CMC, Wildtrack, and Panoptic datasets, demonstrating high accuracy in 3D localization compared to the available 3D ground truth. Unlike existing approaches that provide only ground-plane information, our method also outputs the full 3D shape of each object. Additionally, the algorithm offers a scalable and fully automatic solution for multi-camera systems using only 2D image annotations.
