---
layout: default
title: "[9.2]E3AD: An Emotion-Aware Vision-Language-Action Model for Human-Centric End-to-End Autonomous Driving"
---

# [9.2] E3AD: An Emotion-Aware Vision-Language-Action Model for Human-Centric End-to-End Autonomous Driving

- Authors: Yihong Tang, Haicheng Liao, Tong Nie, Junlin He, Ao Qu, Kehua Chen, Wei Ma, Zhenning Li, ...
- [arXiv Link](https://arxiv.org/abs/2512.04733)
- [PDF Link](https://arxiv.org/pdf/2512.04733.pdf)

## Subfields
 端到端自动驾驶 / 视觉语言动作模型 (VLA) / 人机交互
## Reason for Interest

该论文具有极高的研究价值和创新性，主要体现在以下几点：
1. **任务定义创新**：首次明确提出了考虑情感维度的开放域端到端自动驾驶任务（Open-Domain E2E AD）。它指出自动驾驶不仅要理解“做什么”（语义），还要理解“怎么做”（语气、紧迫感），切中了当前Robotaxi乘客体验的痛点。
2. **方法论先进**：提出了E3AD框架，核心包含两个亮点：一是引入连续的Valence-Arousal-Dominance (VAD) 情感模型，使车辆能根据指令的语气（如‘立刻停车’ vs ‘慢慢停’）动态调整规划策略；二是设计了Egocentric（自车视角）与Allocentric（鸟瞰图视角）的双通路空间推理机制，有效解决了VLA模型空间感知弱的问题。
3. **对齐技术应用**：创新性地利用DPO（直接偏好优化）来对齐情感意图与物理轨迹，使得生成的驾驶行为在几何上可行且在风格上符合乘客情绪（如紧急情况下轨迹更直、更果断）。
4. **实验扎实**：在多个真实世界数据集上进行了广泛的对比实验和消融研究，在轨迹预测、视觉定位和情感识别三个子任务上均取得了SOTA性能，并包含详细的用户研究（User Study）验证了其在人机共驾场景下的优越性。
## Abstract: 
End-to-end autonomous driving (AD) systems increasingly adopt vision-language-action (VLA) models, yet they typically ignore the passenger's emotional state, which is central to comfort and AD acceptance. We introduce Open-Domain End-to-End (OD-E2E) autonomous driving, where an autonomous vehicle (AV) must interpret free-form natural-language commands, infer the emotion, and plan a physically feasible trajectory. We propose E3AD, an emotion-aware VLA framework that augments semantic understanding with two cognitively inspired components: a continuous Valenc-Arousal-Dominance (VAD) emotion model that captures tone and urgency from language, and a dual-pathway spatial reasoning module that fuses egocentric and allocentric views for human-like spatial cognition. A consistency-oriented training scheme, combining modality pretraining with preference-based alignment, further enforces coherence between emotional intent and driving actions. Across real-world datasets, E3AD improves visual grounding and waypoint planning and achieves state-of-the-art (SOTA) VAD correlation for emotion estimation. These results show that injecting emotion into VLA-style driving yields more human-aligned grounding, planning, and human-centric feedback.
