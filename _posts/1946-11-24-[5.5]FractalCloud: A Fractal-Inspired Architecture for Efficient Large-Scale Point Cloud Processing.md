---
layout: default
title: "[5.5]FractalCloud: A Fractal-Inspired Architecture for Efficient Large-Scale Point Cloud Processing"
---

# [5.5] FractalCloud: A Fractal-Inspired Architecture for Efficient Large-Scale Point Cloud Processing

- Authors: Yuzhe Fu, Changchun Zhou, Hancheng Ye, Bowen Duan, Qiyu Huang, Chiyue Wei, Cong Guo, Hai ...
- [arXiv Link](https://arxiv.org/abs/2511.07665)
- [PDF Link](https://arxiv.org/pdf/2511.07665.pdf)

## Subfields
 自动驾驶芯片 / 3D感知硬件加速 (AD Hardware / 3D Perception Acceleration)
## Reason for Interest

1. **相关性与方向**：论文提出了一种针对大规模点云处理的硬件加速架构，属于自动驾驶边缘计算硬件领域。高效处理点云对车端LiDAR感知至关重要。
2. **创新性**：提出了'Fractal'（分形）形状感知的分区方法和块级并行点操作（BPPO），有效地解决了大规模点云处理中非结构化访存和负载不均衡的痛点，创新性较高。
3. **关键缺陷（严格扣分项）**：作为一篇声称面向'自动驾驶'的论文，其核心实验完全依赖于室内数据集（S3DIS）和物体级数据集（ModelNet40），**严重缺乏在自动驾驶主流室外数据集（如nuScenes, Waymo, KITTI）上的验证**。室外LiDAR点云具有稀疏性、环状分布和远距离特性，与室内RGB-D重建点云的几何分布差异巨大，该架构在真实车端场景下的有效性未得到证明。
4. **综合评价**：这是一篇优秀的计算机体系结构（HPCA）论文，但在自动驾驶领域的应用价值因数据集脱节而大打折扣。虽然解决了'大规模'问题，但未解决'车端域'问题，因此给予基础分以上的及格分数，但无法给予高分。
## Abstract: 
Three-dimensional (3D) point clouds are increasingly used in applications such as autonomous driving, robotics, and virtual reality (VR). Point-based neural networks (PNNs) have demonstrated strong performance in point cloud analysis, originally targeting small-scale inputs. However, as PNNs evolve to process large-scale point clouds with hundreds of thousands of points, all-to-all computation and global memory access in point cloud processing introduce substantial overhead, causing $O(n^2)$ computational complexity and memory traffic where n is the number of points}. Existing accelerators, primarily optimized for small-scale workloads, overlook this challenge and scale poorly due to inefficient partitioning and non-parallel architectures. To address these issues, we propose FractalCloud, a fractal-inspired hardware architecture for efficient large-scale 3D point cloud processing. FractalCloud introduces two key optimizations: (1) a co-designed Fractal method for shape-aware and hardware-friendly partitioning, and (2) block-parallel point operations that decompose and parallelize all point operations. A dedicated hardware design with on-chip fractal and flexible parallelism further enables fully parallel processing within limited memory resources. Implemented in 28 nm technology as a chip layout with a core area of 1.5 $mm^2$, FractalCloud achieves 21.7x speedup and 27x energy reduction over state-of-the-art accelerators while maintaining network accuracy, demonstrating its scalability and efficiency for PNN inference.
