---
layout: default
title: "[8.5]CrashChat: A Multimodal Large Language Model for Multitask Traffic Crash Video Analysis"
---

# [8.5] CrashChat: A Multimodal Large Language Model for Multitask Traffic Crash Video Analysis

- Authors: Kaidi Liang, Ke Li, Xianbiao Hu, Ruwen Qin
- [arXiv Link](https://arxiv.org/abs/2512.18878)
- [PDF Link](https://arxiv.org/pdf/2512.18878.pdf)

## Subfields
 自动驾驶安全 / 视觉风险感知 / 视频理解大模型
## Reason for Interest

论文针对自动驾驶中的长尾关键问题——交通事故视频分析，提出了一种专用的多模态大模型CrashChat。1. 创新性：针对感知任务（时序定位）与语言任务（推理描述）的训练冲突，设计了基于LoRA的任务解耦与分组训练策略，有效解决了多任务干扰问题。2. 实用价值：模型在极具挑战的“撞前预测（Pre-crash Localization）”任务上表现优异（mIoU 0.50 vs VideoLLaMA3 0.24），这意味着其具备早期风险预警能力，对自动驾驶的主动安全与Corner Case挖掘具有重要意义。3. 实验完整性：构建了大规模整合数据集（18k+视频），对比了Qwen3-VL、VideoLLaMA3等强基线，消融实验充分验证了架构设计的有效性。尽管主要定位为离线分析工具，但其核心能力直接服务于车端感知与安全评估，符合高分标准。
## Abstract: 
Automating crash video analysis is essential to leverage the growing availability of driving video data for traffic safety research and accountability attribution in autonomous driving. Crash video analysis is a challenging multitask problem due to the complex spatiotemporal dynamics of crash events in video data and the diverse analytical requirements involved. It requires capabilities spanning crash recognition, temporal grounding, and high-level video understanding. Existing models, however, cannot perform all these tasks within a unified framework, and effective training strategies for such models remain underexplored. To fill these gaps, this paper proposes CrashChat, a multimodal large language model (MLLM) for multitask traffic crash analysis, built upon VideoLLaMA3. CrashChat acquires domain-specific knowledge through instruction fine-tuning and employs a novel multitask learning strategy based on task decoupling and grouping, which maximizes the benefit of joint learning within and across task groups while mitigating negative transfer. Numerical experiments on consolidated public datasets demonstrate that CrashChat consistently outperforms existing MLLMs across model scales and traditional vision-based methods, achieving state-of-the-art performance. It reaches near-perfect accuracy in crash recognition, a 176\% improvement in crash localization, and a 40\% improvement in the more challenging pre-crash localization. Compared to general MLLMs, it substantially enhances textual accuracy and content coverage in crash description and reasoning tasks, with 0.18-0.41 increases in BLEU scores and 0.18-0.42 increases in ROUGE scores. Beyond its strong performance, CrashChat is a convenient, end-to-end analytical tool ready for practical implementation. The dataset and implementation code for CrashChat are available at https://github.com/Liangkd/CrashChat.
