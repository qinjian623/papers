---
layout: default
title: "[8.5]Robust Object Detection with Pseudo Labels from VLMs using Per-Object Co-teaching"
---

# [8.5] Robust Object Detection with Pseudo Labels from VLMs using Per-Object Co-teaching

- Authors: Uday Bhaskar, Rishabh Bhattacharya, Avinash Patel, Sarthak Khoche, Praveen Anil Kulkarni,...
- [arXiv Link](https://arxiv.org/abs/2511.09955)
- [PDF Link](https://arxiv.org/pdf/2511.09955.pdf)

## Subfields
 2D目标检测 / 伪标签学习 / 鲁棒学习 / 大模型应用
## Reason for Interest

1. 创新性：论文提出了一种新颖的Per-Object Co-teaching框架，专门针对目标检测任务中VLM生成伪标签的噪声问题。与传统的图像级Co-teaching不同，该方法通过过滤不可靠的边界框而非整个图像来缓解噪声影响，这对于目标检测而言是更精细且有效的创新，体现了对问题深度理解。同时，在选择损失中排除objectness term也体现了细致的设计。
2. 实验完整性：论文在三个主流自动驾驶数据集（KITTI, ACDC, BDD100k）上进行了全面且充分的实验。对比了OWLv2、基于伪标签的YOLOv5m基线、Soft Distillation、Data Distillation和Standard Coteaching等多种相关基线，验证了方法的优越性。此外，还进行了详细的消融研究，包括选择损失成分分析、无标签数据量扩展性分析和半监督设置下的性能表现，有力支持了设计选择和方法的可扩展性。
3. 结果可信度：实验结果一致表明，在伪标签训练范式下，所提出的方法在多个数据集和指标上均显著优于其他基线，有效缓解了VLM伪标签的噪声问题。论文对SOTA的声称是限定在特定问题背景下（即利用VLM伪标签训练高效检测器），而非普遍意义上的SOTA，这一点表述清晰，提升了结果的可信度。与真值标签训练的模型之间存在的性能差距也得到了诚实的讨论。
4. 行业潜力：该方法直接解决了自动驾驶领域数据标注成本高昂的关键痛点，通过利用VLM生成伪标签，并有效处理其固有的噪声，大大降低了对人工标注的依赖。生成的YOLOv5m模型具有高效的实时推理能力，适用于车载硬件部署。尤其在处理恶劣天气条件（ACDC数据集）方面表现出色，且能从少量真值标签中获益，这使其在实际自动驾驶场景中具有极高的实用价值和部署潜力。
## Abstract: 
Foundation models, especially vision-language models (VLMs), offer compelling zero-shot object detection for applications like autonomous driving, a domain where manual labelling is prohibitively expensive. However, their detection latency and tendency to hallucinate predictions render them unsuitable for direct deployment. This work introduces a novel pipeline that addresses this challenge by leveraging VLMs to automatically generate pseudo-labels for training efficient, real-time object detectors. Our key innovation is a per-object co-teaching-based training strategy that mitigates the inherent noise in VLM-generated labels. The proposed per-object coteaching approach filters noisy bounding boxes from training instead of filtering the entire image. Specifically, two YOLO models learn collaboratively, filtering out unreliable boxes from each mini-batch based on their peers' per-object loss values. Overall, our pipeline provides an efficient, robust, and scalable approach to train high-performance object detectors for autonomous driving, significantly reducing reliance on costly human annotation. Experimental results on the KITTI dataset demonstrate that our method outperforms a baseline YOLOv5m model, achieving a significant mAP@0.5 boost ($31.12\%$ to $46.61\%$) while maintaining real-time detection latency. Furthermore, we show that supplementing our pseudo-labelled data with a small fraction of ground truth labels ($10\%$) leads to further performance gains, reaching $57.97\%$ mAP@0.5 on the KITTI dataset. We observe similar performance improvements for the ACDC and BDD100k datasets.
