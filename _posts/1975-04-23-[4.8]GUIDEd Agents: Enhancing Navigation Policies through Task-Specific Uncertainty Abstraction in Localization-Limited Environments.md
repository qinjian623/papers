---
layout: default
title: "[4.8]GUIDEd Agents: Enhancing Navigation Policies through Task-Specific Uncertainty Abstraction in Localization-Limited Environments"
---

# [4.8] GUIDEd Agents: Enhancing Navigation Policies through Task-Specific Uncertainty Abstraction in Localization-Limited Environments

- Authors: Gokul Puthumanaillam, Paulo Padrao, Jose Fuentes, Leonardo Bobadilla, Melkior Ornik
- [arXiv Link](https://arxiv.org/abs/2410.15178)
- [PDF Link](https://arxiv.org/pdf/2410.15178.pdf)

## Subfields
 规划控制 / 机器人导航 (Planning & Control / Robotic Navigation)
## Reason for Interest

论文提出了一种利用视觉语言模型（CLIP）生成任务特定不确定性地图（TSUM），并将其融入强化学习（SAC）框架以指导导航策略的方法（GUIDE）。该方法允许机器人在定位受限（如高成本或隐身需求）的环境中动态调整对不确定性的容忍度。虽然论文在方法论上具有创新性（结合 VLM 与 RL 处理不确定性），且进行了扎实的实船（无人船 ASV）验证，但其核心应用场景为水面无人艇（Marine Autonomy）及特殊的定位受限场景，与主流车端自动驾驶（城市/高速、高动态环境）的感知规划体系差异较大，属于通用移动机器人领域，不直接对应车端自动驾驶技术栈，因此根据严格评分规则（非车端相关最多 5 分）给出此分数。
## Abstract: 
Autonomous vehicles performing navigation tasks in complex environments face significant challenges due to uncertainty in state estimation. In many scenarios, such as stealth operations or resource-constrained settings, accessing high-precision localization comes at a significant cost, forcing robots to rely primarily on less precise state estimates. Our key observation is that different tasks require varying levels of precision in different regions: a robot navigating a crowded space might need precise localization near obstacles but can operate effectively with less precision elsewhere. In this paper, we present a planning method for integrating task-specific uncertainty requirements directly into navigation policies. We introduce Task-Specific Uncertainty Maps (TSUMs), which abstract the acceptable levels of state estimation uncertainty across different regions. TSUMs align task requirements and environmental features using a shared representation space, generated via a domain-adapted encoder. Using TSUMs, we propose Generalized Uncertainty Integration for Decision-Making and Execution (GUIDE), a policy conditioning framework that incorporates these uncertainty requirements into robot decision-making. We find that TSUMs provide an effective way to abstract task-specific uncertainty requirements, and conditioning policies on TSUMs enables the robot to reason about the context-dependent value of certainty and adapt its behavior accordingly. We show how integrating GUIDE into reinforcement learning frameworks allows the agent to learn navigation policies that effectively balance task completion and uncertainty management without explicit reward engineering. We evaluate GUIDE on various real-world robotic navigation tasks and find that it demonstrates significant improvement in task completion rates compared to baseline methods that do not explicitly consider task-specific uncertainty.
