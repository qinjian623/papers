---
layout: default
title: "[9.2]UniMPR: A Unified Framework for Multimodal Place Recognition with Heterogeneous Sensor Configurations"
---

# [9.2] UniMPR: A Unified Framework for Multimodal Place Recognition with Heterogeneous Sensor Configurations

- Authors: Zhangshuo Qi, Jingyi Xu, Luqi Cheng, Shichen Wen, Yiming Ma, Guangming Xiong
- [arXiv Link](https://arxiv.org/abs/2512.18279)
- [PDF Link](https://arxiv.org/pdf/2512.18279.pdf)

## Subfields
 多模态位置识别 (Multimodal Place Recognition) / SLAM
## Reason for Interest

该论文提出了 UniMPR 框架，解决了多模态位置识别中传感器配置异构和模态缺失的难题。核心创新在于：1) 统一的极坐标 BEV 特征空间（Polar BEV）能够兼容相机、激光雷达和雷达数据；2) 基于 MoE Transformer 和可学习 BEV 填充模块（Learnable BEV Imputation）的融合网络，使其能通过单一模型适应任意传感器组合。实验非常充分，在 7 个数据集上验证了其在全模态、模态缺失及跨域场景下的 SOTA 性能，具有极高的工程落地价值和学术创新性。
## Abstract: 
Place recognition is a critical component of autonomous vehicles and robotics, enabling global localization in GPS-denied environments. Recent advances have spurred significant interest in multimodal place recognition (MPR), which leverages complementary strengths of multiple modalities. Despite its potential, most existing MPR methods still face three key challenges: (1) dynamically adapting to various modality inputs within a unified framework, (2) maintaining robustness with missing or degraded modalities, and (3) generalizing across diverse sensor configurations and setups. In this paper, we propose UniMPR, a unified framework for multimodal place recognition. Using only one trained model, it can seamlessly adapt to any combination of common perceptual modalities (e.g., camera, LiDAR, radar). To tackle the data heterogeneity, we unify all inputs within a polar BEV feature space. Subsequently, the polar BEVs are fed into a multi-branch network to exploit discriminative intra-model and inter-modal features from any modality combinations. To fully exploit the network's generalization capability and robustness, we construct a large-scale training set from multiple datasets and introduce an adaptive label assignment strategy for extensive pre-training. Experiments on seven datasets demonstrate that UniMPR achieves state-of-the-art performance under varying sensor configurations, modality combinations, and environmental conditions. Our code will be released at https://github.com/QiZS-BIT/UniMPR.
