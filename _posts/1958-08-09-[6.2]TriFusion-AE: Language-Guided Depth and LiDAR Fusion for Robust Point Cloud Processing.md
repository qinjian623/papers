---
layout: default
title: "[6.2]TriFusion-AE: Language-Guided Depth and LiDAR Fusion for Robust Point Cloud Processing"
---

# [6.2] TriFusion-AE: Language-Guided Depth and LiDAR Fusion for Robust Point Cloud Processing

- Authors: Susmit Neogi
- [arXiv Link](https://arxiv.org/abs/2509.18743v1)
- [PDF Link](https://arxiv.org/pdf/2509.18743v1.pdf)

## Subfields
 感知 / 多模态融合 / 鲁棒性 (Perception / Multi-modal Fusion / Robustness)
## Reason for Interest

论文提出了结合文本（Text）、深度图（Depth）和激光雷达（LiDAR）的多模态抗噪自编码器（TriFusion-AE）。

优点：
1. 创新性：引入文本语义（CLIP特征）辅助点云重建是一个较新颖的尝试，尤其是在对抗攻击防御方面表现出显著的鲁棒性。
2. 实验分析：针对随机噪声、FGSM和PGD攻击进行了详细的对比分析，证明了多模态融合在强干扰下的稳定性。

缺点（导致扣分的主要原因）：
1. 数据集局限：仅在 nuScenes-mini（小规模子集）上进行评估，缺乏全量数据集的验证，无法证明其在大规模实际场景中的泛化能力。
2. 基线薄弱：仅对比了基础的 CNN Autoencoder，缺乏与现有的 SOTA 鲁棒感知模型或更高级的点云补全/去噪方法的对比。
3. 下游任务缺失：仅评估了重建质量（MSE/PSNR），未验证该重建效果对 3D 检测或分割等核心自动驾驶任务的实际提升。
4. 实时性存疑：引入 CLIP 和多模态分支增加了推理成本，论文未详细评估其实时性，这对车端部署至关重要。
## Abstract: 

