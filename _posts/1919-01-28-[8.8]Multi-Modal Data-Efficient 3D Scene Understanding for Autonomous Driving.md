---
layout: default
title: "[8.8]Multi-Modal Data-Efficient 3D Scene Understanding for Autonomous Driving"
---

# [8.8] Multi-Modal Data-Efficient 3D Scene Understanding for Autonomous Driving

- Authors: Lingdong Kong, Xiang Xu, Jiawei Ren, Wenwei Zhang, Liang Pan, Kai Chen, Wei Tsang Ooi, Zi...
- [arXiv Link](https://arxiv.org/abs/2405.05258)
- [PDF Link](https://arxiv.org/pdf/2405.05258.pdf)

## Subfields
 3D Perception / Semi-supervised Semantic Segmentation
## Reason for Interest

论文提出了一种结合多模态数据（LiDAR+Camera）和语言驱动知识（CLIP）的半监督 3D 场景理解框架 LaserMix++。其核心创新在于利用激光雷达的空间几何先验（LaserMix）结合图像的纹理语义特征，通过跨模态混合和蒸馏显著提升了数据利用率。论文实验极其详尽，在三个主流数据集上验证了五种不同类型的主干网络（Range View, Voxel, BEV, PV），证明了方法的通用性和鲁棒性。该方案能显著降低自动驾驶感知模型的标注成本，具有很高的落地潜力和学术价值。
## Abstract: 
Efficient data utilization is crucial for advancing 3D scene understanding in autonomous driving, where reliance on heavily human-annotated LiDAR point clouds challenges fully supervised methods. Addressing this, our study extends into semi-supervised learning for LiDAR semantic segmentation, leveraging the intrinsic spatial priors of driving scenes and multi-sensor complements to augment the efficacy of unlabeled datasets. We introduce LaserMix++, an evolved framework that integrates laser beam manipulations from disparate LiDAR scans and incorporates LiDAR-camera correspondences to further assist data-efficient learning. Our framework is tailored to enhance 3D scene consistency regularization by incorporating multi-modality, including 1) multi-modal LaserMix operation for fine-grained cross-sensor interactions; 2) camera-to-LiDAR feature distillation that enhances LiDAR feature learning; and 3) language-driven knowledge guidance generating auxiliary supervisions using open-vocabulary models. The versatility of LaserMix++ enables applications across LiDAR representations, establishing it as a universally applicable solution. Our framework is rigorously validated through theoretical analysis and extensive experiments on popular driving perception datasets. Results demonstrate that LaserMix++ markedly outperforms fully supervised alternatives, achieving comparable accuracy with five times fewer annotations and significantly improving the supervised-only baselines. This substantial advancement underscores the potential of semi-supervised approaches in reducing the reliance on extensive labeled data in LiDAR-based 3D scene understanding systems.
