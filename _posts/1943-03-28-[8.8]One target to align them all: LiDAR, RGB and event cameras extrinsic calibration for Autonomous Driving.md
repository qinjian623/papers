---
layout: default
title: "[8.8]One target to align them all: LiDAR, RGB and event cameras extrinsic calibration for Autonomous Driving"
---

# [8.8] One target to align them all: LiDAR, RGB and event cameras extrinsic calibration for Autonomous Driving

- Authors: Andrea Bertogalli, Giacomo Boracchi, Luca Magri
- [arXiv Link](https://arxiv.org/abs/2511.12291v1)
- [PDF Link](https://arxiv.org/pdf/2511.12291v1.pdf)

## Subfields
 多传感器标定 (Multi-sensor Calibration)
## Reason for Interest

该论文针对自动驾驶中日益重要的事件相机（Event Camera）与传统传感器（LiDAR, RGB）的联合标定难题，提出了一种极具创新性的解决方案。1. **创新性强**：设计了一种包含不同频率闪烁LED的定制3D靶标，巧妙利用频率分析在事件流中提取特征，解决了事件相机难以对静态场景标定的痛点，同时通过ChArUco和平面特征兼容RGB和LiDAR，实现了'一次拍摄，全员对齐'（One-shot）。2. **工程价值高**：相比传统的分步标定（容易累积误差），该方法能同时统一三个模态的坐标系，对于多传感器融合系统的量产和维护具有重要意义。3. **实验扎实**：在真实的Maserati自动驾驶测试车上进行了验证，不仅对比了多篇2023年的最新论文，还详细分析了误差来源。尽管依赖自制靶标使得难以在公共通用数据集上测试，但这属于标定领域的常规特性。论文逻辑清晰，结果可信，对引入神经形态视觉传感器的下一代自动驾驶系统极具参考价值。
## Abstract: 

