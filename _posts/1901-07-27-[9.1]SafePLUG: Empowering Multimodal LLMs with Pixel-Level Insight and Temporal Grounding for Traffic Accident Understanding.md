---
layout: default
title: "[9.1]SafePLUG: Empowering Multimodal LLMs with Pixel-Level Insight and Temporal Grounding for Traffic Accident Understanding"
---

# [9.1] SafePLUG: Empowering Multimodal LLMs with Pixel-Level Insight and Temporal Grounding for Traffic Accident Understanding

- Authors: Zihao Sheng, Zilin Huang, Yansong Qu, Jiancong Chen, Yuhao Luo, Yen-Jung Chen, Yue Leng, ...
- [arXiv Link](https://arxiv.org/abs/2508.06763)
- [PDF Link](https://arxiv.org/pdf/2508.06763.pdf)

## Subfields
 自动驾驶安全感知 / 多模态大模型 / 交通场景理解
## Reason for Interest

该论文提出了一种名为SafePLUG的新型框架，旨在增强多模态大语言模型（MLLMs）在交通事故理解中的像素级洞察力和时序定位能力。其创新性在于将任意形状的视觉提示、嵌入视频帧的轻量级数字提示以及基于SAM的像素级解码器巧妙地整合到MLLM中，以实现细粒度的空间推理和时间对齐。此框架直接解决了现有MLLMs在处理复杂交通场景中，对局部视觉细节和事件发生时间缺乏精确理解的局限性，这对自动驾驶的安全感知和决策至关重要。

论文的实验非常完整。它在作者新构建的SafePLUG-Bench数据集上进行了广泛评估，该数据集是首个支持区域级QA和像素级grounding QA的交通事故理解基准，涵盖了事故描述、区域级问答、像素级grounding和时序定位四项关键任务。通过与多种通用及专用MLLMs基线进行对比，SafePLUG在几乎所有任务和指标上均展现出显著的领先性能，部分指标实现了SOTA。详细的消融研究充分验证了双LoRA训练策略和各个核心组件（数字提示、视觉提示、像素解码器）的有效性。

该研究结果可信度高，方法设计合理，消融实验清晰地展示了各模块的贡献。通过半自动化结合人工验证的数据集构建流程，保证了SafePLUG-Bench的数据质量和多样性。论文提出的能力，如精细的事故场景解析、因果关系推理以及精确的时空定位，对于提升自动驾驶系统的态势感知、解释性、安全性评估和事故复盘具有巨大的行业潜力。

鉴于其高度的创新性、扎实的实验验证以及对自动驾驶领域安全性和理解能力提升的直接且深远的影响，该论文的价值极高。
## Abstract: 
Multimodal large language models (MLLMs) have achieved remarkable progress across a range of vision-language tasks and demonstrate strong potential for traffic accident understanding. However, existing MLLMs in this domain primarily focus on coarse-grained image-level or video-level comprehension and often struggle to handle fine-grained visual details or localized scene components, limiting their applicability in complex accident scenarios. To address these limitations, we propose SafePLUG, a novel framework that empowers MLLMs with both Pixel-Level Understanding and temporal Grounding for comprehensive traffic accident analysis. SafePLUG supports both arbitrary-shaped visual prompts for region-aware question answering and pixel-level segmentation based on language instructions, while also enabling the recognition of temporally anchored events in traffic accident scenarios. To advance the development of MLLMs for traffic accident understanding, we curate a new dataset containing multimodal question-answer pairs centered on diverse accident scenarios, with detailed pixel-level annotations and temporal event boundaries. Experimental results show that SafePLUG achieves strong performance on multiple tasks, including region-based question answering, pixel-level segmentation, temporal event localization, and accident event understanding. These capabilities lay a foundation for fine-grained understanding of complex traffic scenes, with the potential to improve driving safety and enhance situational awareness in smart transportation systems. The code, dataset, and model checkpoints will be made publicly available at: https://zihaosheng.github.io/SafePLUG
