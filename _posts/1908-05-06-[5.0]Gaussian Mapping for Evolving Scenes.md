---
layout: default
title: "[5.0]Gaussian Mapping for Evolving Scenes"
---

# [5.0] Gaussian Mapping for Evolving Scenes

- Authors: Vladimir Yugay, Thies Kersten, Luca Carlone, Theo Gevers, Martin R. Oswald, Lukas Schmid
- [arXiv Link](https://arxiv.org/abs/2506.06909)
- [PDF Link](https://arxiv.org/pdf/2506.06909.pdf)

## Subfields
 3D Mapping / SLAM (Dynamic 3DGS)
## Reason for Interest

论文提出了一种针对演变场景（Evolving Scenes）的在线3D高斯映射方法（GaME），通过动态场景适应（DSA）和关键帧管理解决了长期场景变化（如物体移动）导致的建图崩坏问题。虽然该问题（地图更新/维护）在自动驾驶长周期建图中非常重要，但该方法主要针对RGB-D输入的室内场景设计，且仅在室内数据集（Aria, Flat）上进行了验证。由于缺乏针对室外大规模场景、LiDAR或纯视觉方案的适配与验证，其无法直接应用于车载自动驾驶系统，符合'非直接车端相关'的评分限制。
## Abstract: 
Mapping systems with novel view synthesis (NVS) capabilities, most notably 3D Gaussian Splatting (3DGS), are widely used in computer vision and across various applications, including augmented reality, robotics, and autonomous driving. However, many current approaches are limited to static scenes. While recent works have begun addressing short-term dynamics (motion within the camera's view), long-term dynamics (the scene evolving through changes out of view) remain less explored. To overcome this limitation, we introduce a dynamic scene-adaptation mechanism that continuously updates 3DGS to reflect the latest changes. Since maintaining consistency remains challenging due to stale observations that disrupt the reconstruction process, we propose a novel keyframe management mechanism that discards outdated observations while preserving as much information as possible. We thoroughly evaluate Gaussian Mapping for Evolving Scenes (\ours) on both synthetic and real-world datasets, achieving a 29.7\% improvement in PSNR and a 3 times improvement in L1 depth error over the most competitive baseline.
