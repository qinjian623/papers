---
layout: default
title: "[4.2]BLIP-FusePPO: A Vision-Language Deep Reinforcement Learning Framework for Lane Keeping in Autonomous Vehicles"
---

# [4.2] BLIP-FusePPO: A Vision-Language Deep Reinforcement Learning Framework for Lane Keeping in Autonomous Vehicles

- Authors: Seyed Ahmad Hosseini Miangoleh, Amin Jalal Aghdasian, Farzaneh Abdollahi
- [arXiv Link](https://arxiv.org/abs/2510.22370v1)
- [PDF Link](https://arxiv.org/pdf/2510.22370v1.pdf)

## Subfields
 端到端自动驾驶 / 车辆控制 (Lane Keeping)
## Reason for Interest

该论文提出将视觉语言模型（BLIP）的语义嵌入与PID控制信号融合到PPO强化学习框架中，用于车道保持任务。综合评分较低，理由如下：
1. **工程落地价值低**：车道保持（LKA）作为基础L2功能，工业界已有基于CNN/Transformer配合MPC/LQR的成熟低算力方案。引入参数量巨大、推理延迟高的VLM（视觉语言模型）来解决简单的横向控制问题，属于“杀鸡用牛刀”，在车载计算资源受限的实际场景中极难部署，且相比传统方案并无明显性能收益。
2. **实验环境局限**：仅在Webots仿真器中进行测试，场景主要为简单的车道线跟踪，未在NuScenes、Waymo等公认的复杂真实数据集上验证，也无实车测试，结论的可信度和泛化能力存疑。
3. **对比基线薄弱**：实验仅对比了DDPG（较旧的RL算法）和同类的VL-SAFE，未与当前主流的端到端自动驾驶模型（如UniAD等）或经过精细调优的传统控制算法进行对比，无法证明其相对于SOTA方法的优势。
4. **方法论创新不足**：将PID误差作为状态输入属于常见的工程技巧（残差学习），利用VLM提取特征辅助决策虽是热点，但在该特定任务上显得牵强。
## Abstract: 

