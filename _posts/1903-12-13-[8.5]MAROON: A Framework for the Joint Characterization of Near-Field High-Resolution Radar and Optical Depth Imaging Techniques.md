---
layout: default
title: "[8.5]MAROON: A Framework for the Joint Characterization of Near-Field High-Resolution Radar and Optical Depth Imaging Techniques"
---

# [8.5] MAROON: A Framework for the Joint Characterization of Near-Field High-Resolution Radar and Optical Depth Imaging Techniques

- Authors: Vanessa Wirth, Johanna Br\"aunig, Nikolai Hofmann, Martin Vossiek, Tim Weyrich, Marc Stam...
- [arXiv Link](https://arxiv.org/abs/2411.00527)
- [PDF Link](https://arxiv.org/pdf/2411.00527.pdf)

## Subfields
 多传感器融合 / 3D感知 / 传感器特性与数据集
## Reason for Interest

论文提出了一个名为 MAROON 的新型多模态数据集，用于联合表征近场高分辨率射频（毫米波雷达）和光学深度成像技术。其创新性在于：
1. 填补了研究空白：现有自动驾驶领域的数据集和研究大多集中于远场感知，而近场（目标距离传感器分米级）的多模态深度感知研究较少，尤其是将高分辨率成像雷达与光学深度传感器进行联合表征。
2. 数据集丰富且高质量：MAROON 数据集包含了 45 种常见家用和建筑物体，在三种不同距离下采集，并采用三种光学深度传感器（主动和被动立体、近红外 ToF）和一个高分辨率成像雷达进行同步捕获。提供了高质量的多视角立体（MVS）重建作为真值。
3. 详细的传感器特性分析：论文对不同传感器在不同物体材料、几何形状和距离下的深度测量行为进行了系统性分析，揭示了散射效应、多径效应等对不同传感器性能的影响，并发布了原始雷达数据，便于后续研究。

实验完整性方面，论文提供了详尽的传感器设置、数据采集流程、真值生成方法以及多维度评估指标（Chamfer 距离、投影误差）和详细的消融研究（雷达天线配置、频率设置），充分验证了其方法的稳健性和数据集的价值。结果分析深入，解释了不同传感器对材料、几何、距离的响应差异，例如射频信号穿透半透明材料以及镜面反射的效应，这对于理解传感器行为至关重要。

可信度方面，论文的采集和校准过程描述清晰，评估框架合理，并公开数据集以支持进一步研究，具有很高的可信度。

行业潜力方面，尽管论文主要关注近场感知，但这对自动驾驶系统的完整性至关重要。例如，自动泊车、低速避障、车内感知和机器人出租车服务中的近距离交互都需要高精度、高鲁棒性的近场感知。理解不同传感器在复杂近场环境下的特性，有助于开发更可靠的多模态融合算法，提升自动驾驶系统在各种操作设计域（ODD）下的性能。同时，数据集也支持了毫米波雷达材料特性分析和多模态重建算法等基础性研究，这些都将间接或直接地促进自动驾驶技术的发展。因此，该工作对自动驾驶领域具有重要的基础性研究价值和潜在的工程应用价值。
## Abstract: 
Utilizing the complementary strengths of wavelength-specific range or depth sensors is crucial for robust computer-assisted tasks such as autonomous driving. Despite this, there is still little research done at the intersection of optical depth sensors and radars operating close range, where the target is decimeters away from the sensors. Together with a growing interest in high-resolution imaging radars operating in the near field, the question arises how these sensors behave in comparison to their traditional optical counterparts.
  In this work, we take on the unique challenge of jointly characterizing depth imagers from both, the optical and radio-frequency domain using a multimodal spatial calibration. We collect data from four depth imagers, with three optical sensors of varying operation principle and an imaging radar. We provide a comprehensive evaluation of their depth measurements with respect to distinct object materials, geometries, and object-to-sensor distances. Specifically, we reveal scattering effects of partially transmissive materials and investigate the response of radio-frequency signals. All object measurements will be made public in form of a multimodal dataset, called MAROON.
