---
layout: default
title: "[6.0]Gradient Inversion in Federated Reinforcement Learning"
---

# [6.0] Gradient Inversion in Federated Reinforcement Learning

- Authors: Shenghong He
- [arXiv Link](https://arxiv.org/abs/2512.00303v1)
- [PDF Link](https://arxiv.org/pdf/2512.00303v1.pdf)

## Subfields
 联邦学习 / 数据隐私与安全 (Federated Learning / Data Privacy & Security)
## Reason for Interest

1. 选题价值：论文探讨了联邦强化学习（FRL）中的梯度反转攻击问题，这对自动驾驶的车队分布式训练（Fleet Learning）具有潜在的数据隐私警示意义。
2. 创新性：针对RL梯度反转中的'伪解'问题（即梯度匹配但违背物理动力学），提出了基于状态分布、奖励范围和动力学一致性的正则化方法（RGIA），理论和方法设计扎实。
3. 实验表现：在多个RL基准上证明了攻击效果优于现有方法，并分析了差分隐私等防御手段的局限性。
4. 局限性：作为自动驾驶领域的评估，该论文的主要短板在于实验环境过于简易。所谓的'自动驾驶任务'仅为Box2D Car Racing（玩具级2D模拟），缺乏在CARLA、NuPlan或真实数据集（如nuScenes）上的验证，无法证明该攻击在复杂高维的真实自动驾驶场景中的有效性，因此对工业界的直接参考价值受限。
## Abstract: 

