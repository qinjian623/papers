---
layout: default
title: "[9.2]DrivePI: Spatial-aware 4D MLLM for Unified Autonomous Driving Understanding, Perception, Prediction and Planning"
---

# [9.2] DrivePI: Spatial-aware 4D MLLM for Unified Autonomous Driving Understanding, Perception, Prediction and Planning

- Authors: Zhe Liu, Runhui Huang, Rui Yang, Siming Yan, Zining Wang, Lu Hou, Di Lin, Xiang Bai, Heng...
- [arXiv Link](https://arxiv.org/abs/2512.12799v1)
- [PDF Link](https://arxiv.org/pdf/2512.12799v1.pdf)

## Subfields
 端到端自动驾驶 / 具身智能 (VLA) / 3D占据栅格感知
## Reason for Interest

1. **创新性强**：提出了首个结合LiDAR点云与多视角相机的4D空间感知VLA（视觉-语言-动作）框架。针对现有VLA模型缺乏精细几何感知的问题，创新性地在MLLM中引入了专门的3D Occupancy和Flow预测头，实现了从语义理解到精细物理感知的跨越。
2. **效果显著且高效**：仅使用0.5B参数的轻量级模型（Qwen2.5-0.5B），就在感知、预测和规划任务上全面对标甚至超越了专门的Vision-Action模型（如VAD）和更大参数的VLA模型（如7B的OpenDriveVLA），展现了极高的参数效率和落地潜力。
3. **实验完整**：在nuScenes和OpenOcc上进行了详尽的对比实验和消融研究，验证了多模态融合（特别是引入LiDAR）对增强大模型空间理解能力的有效性。
4. **行业价值**：解决了大模型在自动驾驶中“懂语义但不懂几何”的痛点，为端到端大模型上车提供了高可行性的技术路径。
## Abstract: 

