---
layout: default
title: "[6.3]3D Point Cloud Object Detection on Edge Devices for Split Computing"
---

# [6.3] 3D Point Cloud Object Detection on Edge Devices for Split Computing

- Authors: Taisuke Noguchi, Takuya Azumi
- [arXiv Link](https://arxiv.org/abs/2511.02293)
- [PDF Link](https://arxiv.org/pdf/2511.02293.pdf)

## Subfields
 3D感知系统部署优化 / 边缘计算与分布式推理
## Reason for Interest

该论文研究了在资源受限的边缘设备上部署3D点云目标检测模型的效率问题，提出了利用分层计算（Split Computing）的方法。其核心贡献在于通过系统性地分析不同的模型分割点，量化了推理时间、边缘设备负载、数据传输量及时间，并探讨了隐私保护的优势。

**创新性 (6/10)**：分层计算本身并非新概念，但将其系统应用于LiDAR 3D目标检测（特别是OpenPCDet中的Voxel R-CNN模型），并详细分析不同分割点对性能、数据传输和隐私的影响，是具有实际价值的工程贡献。它为在实际自动驾驶边缘系统中部署感知模型提供了量化依据和参考。

**实验完整性 (6/10)**：实验在真实的边缘设备（Jetson Orin Nano）上进行，并使用了一个主流的3D检测模型。论文详细评估了多种分割策略下的推理时间、边缘设备执行时间、数据传输大小和传输时间，数据呈现清晰。然而，作为自动驾驶领域的一篇论文，它完全没有提供3D目标检测的**精度指标**。尽管分层计算通常假定不会影响模型精度，但在实际部署中验证这一关键假设的稳定性是至关重要的。缺失精度数据是其作为自动驾驶感知系统论文的一个显著不足。

**可信度 (6/10)**：实验设置和结果报告较为清晰。所声称的性能提升幅度巨大，在边缘计算场景下是可信的。论文也讨论了数据传输量增加带来的权衡。然而，由于缺乏精度验证，这使得对于自动驾驶应用而言，其结论的整体可信度有所降低，因为效率提升不能以牺牲关键精度为代价。

**行业潜力 (7/10)**：解决边缘设备上高算力3D感知模型的部署难题对于自动驾驶（无论是车端还是路侧基础设施）具有极高的行业潜力。降低延迟和功耗是实现实时、高效感知系统的关键。同时，通过传输中间特征而非原始点云数据，提升数据隐私性，也具有重要的实际意义。这使得现有先进的感知模型能更有效地在实际环境中落地。

**综合评分理由**：论文在边缘计算部署优化方面做得扎实，解决了自动驾驶领域非常实际的问题。然而，考虑到评分的严格性（特别是与核心感知算法创新、SOTA精度提升等相比）以及缺失对目标检测精度的评估，其分数受到了限制。如果能同时验证精度不受影响，或者提出了新的分层计算方法论，则得分会更高。由于其贡献更多在于系统部署层面的优化和经验分析，而非基础的感知、预测或规划算法创新，因此给出中等偏上的分数。
## Abstract: 
The field of autonomous driving technology is rapidly advancing, with deep learning being a key component. Particularly in the field of sensing, 3D point cloud data collected by LiDAR is utilized to run deep neural network models for 3D object detection. However, these state-of-the-art models are complex, leading to longer processing times and increased power consumption on edge devices. The objective of this study is to address these issues by leveraging Split Computing, a distributed machine learning inference method. Split Computing aims to lessen the computational burden on edge devices, thereby reducing processing time and power consumption. Furthermore, it minimizes the risk of data breaches by only transmitting intermediate data from the deep neural network model. Experimental results show that splitting after voxelization reduces the inference time by 70.8% and the edge device execution time by 90.0%. When splitting within the network, the inference time is reduced by up to 57.1%, and the edge device execution time is reduced by up to 69.5%.
