---
layout: default
title: "[4.5]BEDI: A Comprehensive Benchmark for Evaluating Embodied Agents on UAVs"
---

# [4.5] BEDI: A Comprehensive Benchmark for Evaluating Embodied Agents on UAVs

- Authors: Mingning Guo, Mengwei Wu, Jiarun He, Shaoxian Li, Haifeng Li, Chao Tao
- [arXiv Link](https://arxiv.org/abs/2505.18229)
- [PDF Link](https://arxiv.org/pdf/2505.18229.pdf)

## Subfields
 Embodied AI / UAV Perception & Control
## Reason for Interest

该论文提出了一个针对无人机（UAV）具身智能的综合基准测试 BEDI，涵盖了从感知到决策再到动作执行的完整闭环。虽然其基于 VLM/VLA 的端到端决策范式与当前自动驾驶大模型的研究趋势在方法论上有重叠，但其应用场景完全专注于低空飞行器（如货物投递、火灾救援等），而非车端自动驾驶。数据集为无人机视角的航拍图像与视频，控制维度（6-DoF飞行控制）与地面车辆截然不同。根据评分标准“如果不直接和车端自动驾驶相关，最多 5分”，该论文属于非直接相关领域的高质量工作，因此给出 4.5 分。
## Abstract: 
With the rapid advancement of low-altitude remote sensing and Vision-Language Models (VLMs), Embodied Agents based on Unmanned Aerial Vehicles (UAVs) have shown significant potential in autonomous tasks. However, current evaluation methods for UAV-Embodied Agents (UAV-EAs) remain constrained by the lack of standardized benchmarks, diverse testing scenarios and open system interfaces. To address these challenges, we propose BEDI (Benchmark for Embodied Drone Intelligence), a systematic and standardized benchmark designed for evaluating UAV-EAs. Specifically, we introduce a novel Dynamic Chain-of-Embodied-Task paradigm based on the perception-decision-action loop, which decomposes complex UAV tasks into standardized, measurable subtasks. Building on this paradigm, we design a unified evaluation framework encompassing six core sub-skills: semantic perception, spatial perception, motion control, tool utilization, task planning and action generation. Furthermore, we develop a hybrid testing platform that incorporates a wide range of both virtual and real-world scenarios, enabling a comprehensive evaluation of UAV-EAs across diverse contexts. The platform also offers open and standardized interfaces, allowing researchers to customize tasks and extend scenarios, thereby enhancing flexibility and scalability in the evaluation process. Finally, through empirical evaluations of several state-of-the-art (SOTA) VLMs, we reveal their limitations in embodied UAV tasks, underscoring the critical role of the BEDI benchmark in advancing embodied intelligence research and model optimization. By filling the gap in systematic and standardized evaluation within this field, BEDI facilitates objective model comparison and lays a robust foundation for future development in this field. Our benchmark is now publicly available at https://github.com/lostwolves/BEDI.
