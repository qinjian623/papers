---
layout: default
title: "[8.8]VG3T: Visual Geometry Grounded Gaussian Transformer"
---

# [8.8] VG3T: Visual Geometry Grounded Gaussian Transformer

- Authors: Junho Kim, Seongwon Lee
- [arXiv Link](https://arxiv.org/abs/2512.05988v1)
- [PDF Link](https://arxiv.org/pdf/2512.05988v1.pdf)

## Subfields
 3D Perception / Semantic Occupancy Prediction
## Reason for Interest

论文提出了一种基于 3D 高斯（3DGS）的纯视觉 3D 语义占用预测方法 VG3T。其核心创新在于：1. 引入 VGGT 作为骨干网络，实现了早期的多视角特征融合，解决了传统晚期融合导致的几何不一致问题；2. 提出了网格采样（Grid-Based Sampling）和位置细化（Positional Refinement）模块，有效解决了视觉 3DGS 方法中常见的近密远疏的密度偏差问题。实验结果扎实，在 nuScenes 数据集上以更少的计算基元（Primitives）实现了显著的精度提升，证明了该方法在自动驾驶环境建模中的高效性和准确性，具有较高的研究价值和应用潜力。
## Abstract: 

