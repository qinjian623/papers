---
layout: default
title: "[3.2]PEFT-DML: Parameter-Efficient Fine-Tuning Deep Metric Learning for Robust Multi-Modal 3D Object Detection in Autonomous Driving"
---

# [3.2] PEFT-DML: Parameter-Efficient Fine-Tuning Deep Metric Learning for Robust Multi-Modal 3D Object Detection in Autonomous Driving

- Authors: Abdolazim Rezaei, Mehdi Sookhak
- [arXiv Link](https://arxiv.org/abs/2512.00060)
- [PDF Link](https://arxiv.org/pdf/2512.00060.pdf)

## Subfields
 多模态3D目标检测 / 参数高效微调 (PEFT)
## Reason for Interest

论文存在致命的实验数据与结论矛盾。文中明确声称'achieves the highest mAP'并超越所有基线，然而表1（Table 1）数据显示对比方法 '3D-LRF' 的mAP高达74.8，远超本文方法的62.2。这种直接的数据矛盾严重破坏了论文的可信度。此外，方法论中将GNSS和IMU作为与Camera/LiDAR并列的'特征模态'映射到共享潜在空间用于提取物体纹理/形状特征（用于检测头分类回归），在原理上缺乏解释力（通常GNSS/IMU用于位姿校正而非直接的目标特征提取）。尽管引入LoRA进行参数高效微调是一个有价值的方向，但实验报告的严谨性严重不足。
## Abstract: 
This study introduces PEFT-DML, a parameter-efficient deep metric learning framework for robust multi-modal 3D object detection in autonomous driving. Unlike conventional models that assume fixed sensor availability, PEFT-DML maps diverse modalities (LiDAR, radar, camera, IMU, GNSS) into a shared latent space, enabling reliable detection even under sensor dropout or unseen modality class combinations. By integrating Low-Rank Adaptation (LoRA) and adapter layers, PEFT-DML achieves significant training efficiency while enhancing robustness to fast motion, weather variability, and domain shifts. Experiments on benchmarks nuScenes demonstrate superior accuracy.
