---
layout: default
title: "[8.5]dVLM-AD: Enhance Diffusion Vision-Language-Model for Driving via Controllable Reasoning"
---

# [8.5] dVLM-AD: Enhance Diffusion Vision-Language-Model for Driving via Controllable Reasoning

- Authors: Yingzi Ma, Yulong Cao, Wenhao Ding, Shuibai Zhang, Yan Wang, Boris Ivanovic, Ming Jiang, ...
- [arXiv Link](https://arxiv.org/abs/2512.04459)
- [PDF Link](https://arxiv.org/pdf/2512.04459.pdf)

## Subfields
 端到端自动驾驶 / 视觉语言模型 (Vision-Language Models)
## Reason for Interest

该论文创新性地将离散扩散模型（Discrete Diffusion）引入驾驶VLM领域，替代了主流的自回归（AR）范式。其核心价值在于：1. 理论层面：指出了AR模型单向注意力导致的“推理-动作”不一致问题，利用扩散模型的双向注意力机制实现了全局一致性约束；2. 技术层面：提出了‘动态去噪策略’（Dynamic Denoise Strategy）和‘Reduce Token’机制，巧妙解决了扩散模型难以生成变长文本序列的痛点；3. 实验层面：在WOD-E2E和nuScenes上证明了该方法在保证规划精度的同时，显著提升了系统的可解释性一致性和抗干扰能力。虽然在绝对轨迹误差（ADE）上未完全超越最强专用模型，但在长尾场景的人类对齐度指标（RFS）上表现优异，为高可靠性的E2E VLM提供了新思路。
## Abstract: 
The autonomous driving community is increasingly focused on addressing the challenges posed by out-of-distribution (OOD) driving scenarios. A dominant research trend seeks to enhance end-to-end (E2E) driving systems by integrating vision-language models (VLMs), leveraging their rich world knowledge and reasoning abilities to improve generalization across diverse environments. However, most existing VLMs or vision-language agents (VLAs) are built upon autoregressive (AR) models. In this paper, we observe that existing AR-based VLMs -- limited by causal attention and sequential token generation -- often fail to maintain consistency and controllability between high-level reasoning and low-level planning. In contrast, recent discrete diffusion VLMs equipped with bidirectional attention exhibit superior controllability and reliability through iterative denoising. Building on these observations, we introduce dVLM-AD, a diffusion-based vision-language model that unifies perception, structured reasoning, and low-level planning for end-to-end driving. Evaluated on nuScenes and WOD-E2E, dVLM-AD yields more consistent reasoning-action pairs and achieves planning performance comparable to existing driving VLM/VLA systems despite a modest backbone, outperforming AR-based baselines with a 9 percent improvement in behavior-trajectory consistency and a 6 percent increase in RFS on long-tail WOD-E2E scenarios. These results suggest a controllable and reliable pathway for scalable end-to-end driving.
