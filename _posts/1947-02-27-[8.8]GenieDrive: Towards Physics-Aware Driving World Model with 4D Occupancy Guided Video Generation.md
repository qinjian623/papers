---
layout: default
title: "[8.8]GenieDrive: Towards Physics-Aware Driving World Model with 4D Occupancy Guided Video Generation"
---

# [8.8] GenieDrive: Towards Physics-Aware Driving World Model with 4D Occupancy Guided Video Generation

- Authors: Zhenya Yang, Zhe Liu, Yuxiang Lu, Liping Hou, Chenxuan Miao, Siyi Peng, Bailan Feng, Xian...
- [arXiv Link](https://arxiv.org/abs/2512.12751)
- [PDF Link](https://arxiv.org/pdf/2512.12751.pdf)

## Subfields
 自动驾驶世界模型 / 4D 占据栅格预测 / 视频生成
## Reason for Interest

1. 创新性：提出了一种基于 Tri-plane VAE 和 Mutual Control Attention (MCA) 的轻量级两阶段世界模型框架。通过 4D Occupancy 作为中间表征，有效解决了视频生成中的物理一致性问题，且 Tri-plane 设计极大地降低了计算开销（仅 3.47M 参数）。
2. 实验完整性：在 NuScenes 数据集上进行了详尽的对比实验，涵盖了占据栅格预测和视频生成两个任务。消融实验充分验证了端到端训练和 MCA 模块的有效性。
3. 结果可信度：论文在占据栅格预测指标（mIoU）上取得了显著提升（+7.2%），同时保持了极高的推理速度（41 FPS），这对自动驾驶闭环仿真和实车部署具有极高的实用价值。
4. 行业潜力：该方法不仅能生成高质量、多视角的自动驾驶视频，还能支持场景编辑（移除/插入车辆）和长时序预测（20秒），是构建高保真自动驾驶仿真器的重要技术方向。
## Abstract: 
Physics-aware driving world model is essential for drive planning, out-of-distribution data synthesis, and closed-loop evaluation. However, existing methods often rely on a single diffusion model to directly map driving actions to videos, which makes learning difficult and leads to physically inconsistent outputs. To overcome these challenges, we propose GenieDrive, a novel framework designed for physics-aware driving video generation. Our approach starts by generating 4D occupancy, which serves as a physics-informed foundation for subsequent video generation. 4D occupancy contains rich physical information, including high-resolution 3D structures and dynamics. To facilitate effective compression of such high-resolution occupancy, we propose a VAE that encodes occupancy into a latent tri-plane representation, reducing the latent size to only 58% of that used in previous methods. We further introduce Mutual Control Attention (MCA) to accurately model the influence of control on occupancy evolution, and we jointly train the VAE and the subsequent prediction module in an end-to-end manner to maximize forecasting accuracy. Together, these designs yield a 7.2% improvement in forecasting mIoU at an inference speed of 41 FPS, while using only 3.47 M parameters. Additionally, a Normalized Multi-View Attention is introduced in the video generation model to generate multi-view driving videos with guidance from our 4D occupancy, significantly improving video quality with a 20.7% reduction in FVD. Experiments demonstrate that GenieDrive enables highly controllable, multi-view consistent, and physics-aware driving video generation.
