---
layout: default
title: "[9.2]LocateAnything3D: Vision-Language 3D Detection with Chain-of-Sight"
---

# [9.2] LocateAnything3D: Vision-Language 3D Detection with Chain-of-Sight

- Authors: Yunze Man, Shihao Wang, Guowen Zhang, Johan Bjorck, Zhiqi Li, Liang-Yan Gui, Jim Fan, Jan...
- [arXiv Link](https://arxiv.org/abs/2511.20648)
- [PDF Link](https://arxiv.org/pdf/2511.20648.pdf)

## Subfields
 单目3D检测 (Monocular 3D Detection) / 具身智能感知 (VLM-based Perception)
## Reason for Interest

该论文提出了一种基于视觉语言模型（VLM）的创新3D检测范式‘Chain-of-Sight’，通过‘先2D后3D’、‘由近及远’的Token生成策略，巧妙地利用了VLM强大的2D定位能力来辅助3D推断。实验结果令人印象深刻，在Omni3D大规模基准上大幅超越现有SOTA，且展现出极强的零样本（Zero-shot）长尾物体检测能力，这对自动驾驶中的Corner Case挖掘和自动标注极具价值。尽管目前的推理延迟（~683ms）限制了车端实时部署，但作为数据闭环中的自动标注工具或离线感知大模型，其价值巨大且方法论具有启发性。
## Abstract: 
To act in the world, a model must name what it sees and know where it is in 3D. Today's vision-language models (VLMs) excel at open-ended 2D description and grounding, yet multi-object 3D detection remains largely missing from the VLM toolbox. We present LocateAnything3D, a VLM-native recipe that casts 3D detection as a next-token prediction problem. The key is a short, explicit Chain-of-Sight (CoS) sequence that mirrors how human reason from images: find an object in 2D, then infer its distance, size, and pose. The decoder first emits 2D detections as a visual chain-of-thought, then predicts 3D boxes under an easy-to-hard curriculum: across objects, a near-to-far order reduces early ambiguity and matches ego-centric utility; within each object, a center-from-camera, dimensions, and rotation factorization ranks information by stability and learnability. This VLM-native interface preserves open-vocabulary and visual-prompting capability without specialized heads. On the challenging Omni3D benchmark, our model achieves state-of-the-art results, with 49.89 AP_3D, surpassing the previous best by +15.51 absolute improvement even when the baseline is given ground-truth 2D boxes. It also generalizes zero-shot to held-out categories with strong robustness. By turning 3D detection into a disciplined next-token problem, LocateAnything3D offers a practical foundation for models to perceive in 3D.
