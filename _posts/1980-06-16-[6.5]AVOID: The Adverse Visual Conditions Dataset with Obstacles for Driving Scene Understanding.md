---
layout: default
title: "[6.5]AVOID: The Adverse Visual Conditions Dataset with Obstacles for Driving Scene Understanding"
---

# [6.5] AVOID: The Adverse Visual Conditions Dataset with Obstacles for Driving Scene Understanding

- Authors: Jongoh Jeong, Taek-Jin Song, Jong-Hwan Kim, Kuk-Jin Yoon
- [arXiv Link](https://arxiv.org/abs/2512.23215)
- [PDF Link](https://arxiv.org/pdf/2512.23215.pdf)

## Subfields
 仿真与数据集 / 感知 (Simulation & Datasets / Perception)
## Reason for Interest

该论文构建了一个针对恶劣天气和突发障碍物的多模态仿真数据集（AVOID），填补了感知长尾场景的数据空白，标注质量较高，对提升系统的鲁棒性有一定参考价值。然而，论文完全依赖合成数据，缺乏Sim-to-Real的有效性验证，且作为核心贡献的感知网络架构（基于ResNet）创新性一般，未展现出超越现有SOTA架构（如BEVFormer等）的显著优势。严格评分下，由于缺乏真实场景验证，行业应用潜力受限。
## Abstract: 
Understanding road scenes for visual perception remains crucial for intelligent self-driving cars. In particular, it is desirable to detect unexpected small road hazards reliably in real-time, especially under varying adverse conditions (e.g., weather and daylight). However, existing road driving datasets provide large-scale images acquired in either normal or adverse scenarios only, and often do not contain the road obstacles captured in the same visual domain as for the other classes. To address this, we introduce a new dataset called AVOID, the Adverse Visual Conditions Dataset, for real-time obstacle detection collected in a simulated environment. AVOID consists of a large set of unexpected road obstacles located along each path captured under various weather and time conditions. Each image is coupled with the corresponding semantic and depth maps, raw and semantic LiDAR data, and waypoints, thereby supporting most visual perception tasks. We benchmark the results on high-performing real-time networks for the obstacle detection task, and also propose and conduct ablation studies using a comprehensive multi-task network for semantic segmentation, depth and waypoint prediction tasks.
