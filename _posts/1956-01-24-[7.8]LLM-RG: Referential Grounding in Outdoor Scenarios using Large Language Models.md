---
layout: default
title: "[7.8]LLM-RG: Referential Grounding in Outdoor Scenarios using Large Language Models"
---

# [7.8] LLM-RG: Referential Grounding in Outdoor Scenarios using Large Language Models

- Authors: Pranav Saxena, Avigyan Bhattacharya, Ji Zhang, Wenshan Wang
- [arXiv Link](https://arxiv.org/abs/2509.25528v2)
- [PDF Link](https://arxiv.org/pdf/2509.25528v2.pdf)

## Subfields
 视觉语言感知 / 自动驾驶人机交互 (HMI)
## Reason for Interest

1. 创新性与价值：论文提出了一种结合大语言模型（LLM）推理能力和视觉语言模型（VLM）细粒度感知能力的模块化框架，专门解决自动驾驶场景下复杂的自然语言指代定位问题（如“停在右边那辆黑车后面”）。其最大的亮点是“零样本（Training-free）”特性，无需针对特定数据集微调即可部署，展示了强大的泛化潜力，符合自动驾驶大模型化和自然交互的发展趋势。
2. 实验表现：在Talk2Car数据集上取得了优异的零样本性能，并通过消融实验证明了引入3D空间信息（如LiDAR深度）能进一步大幅提升推理准确性，验证了多模态融合的必要性。
3. 不足与局限：虽然方法在零样本设定下领先，但论文主要对比的是自构建的LLM/VLM基线，未与经过充分监督训练的传统SOTA模型进行详尽的横向对比（尽管零样本通常难以超越监督SOTA，但对比能更好定位其绝对性能水平）。此外，串联多个大模型（Detector-VLM-LLM）的推理延迟在车端部署时可能面临实时性挑战，文中对此未做深入评估。
## Abstract: 

