---
layout: default
title: "[8.2]MAFNet:Multi-frequency Adaptive Fusion Network for Real-time Stereo Matching"
---

# [8.2] MAFNet:Multi-frequency Adaptive Fusion Network for Real-time Stereo Matching

- Authors: Ao Xu, Rujin Zhao, Xiong Xu, Boceng Huang, Yujia Jia, Hongfeng Long, Fuxuan Chen, Zilong ...
- [arXiv Link](https://arxiv.org/abs/2512.04358)
- [PDF Link](https://arxiv.org/pdf/2512.04358.pdf)

## Subfields
 3D感知 / 双目立体匹配 (Stereo Matching)
## Reason for Interest

该论文提出了一种面向实时应用的双目立体匹配网络 MAFNet，核心创新在于利用频域注意力机制（AFFA）将特征分离为高频（边缘/细节）和低频（平滑/无纹理）部分，并使用基于 Linformer 的低秩注意力进行融合。这种方法在保持极低计算量（39.4G FLOPs）的同时，有效解决了传统轻量级网络在弱纹理区域匹配困难的问题。实验数据显示其在 KITTI 2015 数据集上取得了实时方法中的最佳性能（1.82% D1-all），对于资源受限的车端嵌入式感知系统具有很高的应用价值。注：文中提及的 RTX 5090 硬件和 2025 年参考文献表明这是一篇面向未来的或非常新的手稿，需关注其实验复现性。
## Abstract: 
Existing stereo matching networks typically rely on either cost-volume construction based on 3D convolutions or deformation methods based on iterative optimization. The former incurs significant computational overhead during cost aggregation, whereas the latter often lacks the ability to model non-local contextual information. These methods exhibit poor compatibility on resource-constrained mobile devices, limiting their deployment in real-time applications. To address this, we propose a Multi-frequency Adaptive Fusion Network (MAFNet), which can produce high-quality disparity maps using only efficient 2D convolutions. Specifically, we design an adaptive frequency-domain filtering attention module that decomposes the full cost volume into high-frequency and low-frequency volumes, performing frequency-aware feature aggregation separately. Subsequently, we introduce a Linformer-based low-rank attention mechanism to adaptively fuse high- and low-frequency information, yielding more robust disparity estimation. Extensive experiments demonstrate that the proposed MAFNet significantly outperforms existing real-time methods on public datasets such as Scene Flow and KITTI 2015, showing a favorable balance between accuracy and real-time performance.
