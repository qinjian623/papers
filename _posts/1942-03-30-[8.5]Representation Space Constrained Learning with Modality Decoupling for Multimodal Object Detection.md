---
layout: default
title: "[8.5]Representation Space Constrained Learning with Modality Decoupling for Multimodal Object Detection"
---

# [8.5] Representation Space Constrained Learning with Modality Decoupling for Multimodal Object Detection

- Authors: YiKang Shao, Tao Shi
- [arXiv Link](https://arxiv.org/abs/2511.15433v1)
- [PDF Link](https://arxiv.org/pdf/2511.15433v1.pdf)

## Subfields
 Perception / Multimodal Object Detection (Visible-Infrared)
## Reason for Interest

1. 理论深度：论文不仅提出了新方法，还从梯度反向传播的角度深入推导了多模态融合中单模态分支'欠优化'和'模态不平衡'的数学本质，指出了现有架构中梯度抑制的根源，具有较强的理论洞察力。
2. 方法创新：提出的RSC（表征空间约束）和MD（模态解耦）模块有效解决了上述优化缺陷。设计巧妙之处在于训练阶段引入辅助监督，推理阶段可移除辅助头，实现了'零推理增量成本'的性能提升。
3. 实验扎实：在四个主流的可见光-红外检测数据集（FLIR, LLVIP, M3FD, MFAD）上均取得了SOTA效果，且对比了最新的基线（如LIF, EI2Det等），提升幅度明显。
4. 行业价值：VIS-IR融合是自动驾驶全天候（如夜间、恶劣天气）感知的关键技术，该方法能显著提升模型在极端环境下的鲁棒性，且易于集成到现有的YOLO等检测器中，工程落地潜力大。
## Abstract: 

