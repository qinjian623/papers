---
layout: default
title: "[8.4]Dynamic Visual SLAM using a General 3D Prior"
---

# [8.4] Dynamic Visual SLAM using a General 3D Prior

- Authors: Xingguang Zhong, Liren Jin, Marija Popovi\'c, Jens Behley, Cyrill Stachniss
- [arXiv Link](https://arxiv.org/abs/2512.06868)
- [PDF Link](https://arxiv.org/pdf/2512.06868.pdf)

## Subfields
 视觉SLAM / 动态环境感知
## Reason for Interest

该论文创新地将基于大模型的3D先验（深度与动态掩码）与传统几何优化紧密结合，显著解决了单目SLAM在动态环境下的鲁棒性问题。实验验证非常充分，在多个基准上取得了SOTA的定位精度和分割效果。虽然目前的推理速度（2 FPS）限制了其在车端的实时应用，但其架构展示了Foundation Model赋能SLAM的巨大潜力，对高精地图构建等离线任务具有极高价值。
## Abstract: 
Reliable incremental estimation of camera poses and 3D reconstruction is key to enable various applications including robotics, interactive visualization, and augmented reality. However, this task is particularly challenging in dynamic natural environments, where scene dynamics can severely deteriorate camera pose estimation accuracy. In this work, we propose a novel monocular visual SLAM system that can robustly estimate camera poses in dynamic scenes. To this end, we leverage the complementary strengths of geometric patch-based online bundle adjustment and recent feed-forward reconstruction models. Specifically, we propose a feed-forward reconstruction model to precisely filter out dynamic regions, while also utilizing its depth prediction to enhance the robustness of the patch-based visual SLAM. By aligning depth prediction with estimated patches from bundle adjustment, we robustly handle the inherent scale ambiguities of the batch-wise application of the feed-forward reconstruction model.
