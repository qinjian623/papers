---
layout: default
title: "[8.8]Neural Eulerian Scene Flow Fields"
---

# [8.8] Neural Eulerian Scene Flow Fields

- Authors: Kyle Vedder, Neehar Peri, Ishan Khatri, Siyi Li, Eric Eaton, Mehmet Kocamaz, Yue Wang, Zh...
- [arXiv Link](https://arxiv.org/abs/2410.02031)
- [PDF Link](https://arxiv.org/pdf/2410.02031.pdf)

## Subfields
 3D感知 / 激光雷达场景流估计 (LiDAR Scene Flow)
## Reason for Interest

1. 创新性高：文章将场景流估计重构为拟合连续时空常微分方程（ODE）的问题，而非传统的离散帧间位移估计。这种‘Eulerian’视角的神经先验方法允许利用多帧观测的一致性进行优化，显著提升了对运动物体的建模能力。
2. 结果惊人：作为一种无监督（自监督）方法，其性能超越了当前的SOTA监督学习方法（如Flow4D），这在深度学习领域较为罕见，极大地提升了无监督方法在自动驾驶数据标注和预处理中的价值。
3. 实验扎实：在Argoverse 2和Waymo两大主流数据集上进行了详尽的对比和消融实验，证明了方法在小物体（如鸟类、网球）和长序列跟踪上的鲁棒性。
4. 局限性：作为一种测试时优化（Test-Time Optimization）方法，其推理速度极慢（单序列需24小时），无法直接用于车端在线感知。但作为离线高精度自动标注（Auto-labeling）工具或教师模型（用于蒸馏Feed-forward网络），具有极高的行业应用潜力。
## Abstract: 
We reframe scene flow as the task of estimating a continuous space-time ODE that describes motion for an entire observation sequence, represented with a neural prior. Our method, EulerFlow, optimizes this neural prior estimate against several multi-observation reconstruction objectives, enabling high quality scene flow estimation via pure self-supervision on real-world data. EulerFlow works out-of-the-box without tuning across multiple domains, including large-scale autonomous driving scenes and dynamic tabletop settings. Remarkably, EulerFlow produces high quality flow estimates on small, fast moving objects like birds and tennis balls, and exhibits emergent 3D point tracking behavior by solving its estimated ODE over long-time horizons. On the Argoverse 2 2024 Scene Flow Challenge, EulerFlow outperforms all prior art, surpassing the next-best unsupervised method by more than 2.5x, and even exceeding the next-best supervised method by over 10%.
