---
layout: default
title: "[8.8]Redefining Radar Segmentation: Simultaneous Static-Moving Segmentation and Ego-Motion Estimation using Radar Point Clouds"
---

# [8.8] Redefining Radar Segmentation: Simultaneous Static-Moving Segmentation and Ego-Motion Estimation using Radar Point Clouds

- Authors: Simin Zhu, Satish Ravindran, Alexander Yarovoy, Francesco Fioranelli
- [arXiv Link](https://arxiv.org/abs/2511.20003)
- [PDF Link](https://arxiv.org/pdf/2511.20003.pdf)

## Subfields
 雷达感知 (Radar Perception) / 动静分割与自车运动估计
## Reason for Interest

1. 创新性与工程价值：论文挑战了使用复杂Transformer处理稀疏雷达点云的趋势，提出利用轻量级MLP+GRU架构，通过挖掘雷达多普勒速度的正弦分布规律，高效实现了动静分割与自车运动估计的双任务耦合，极具车端部署潜力（参数量仅0.15M）。
2. 方法论：采用原始雷达点云序列作为输入，无需点云聚合或外部里程计辅助，解决了传统方法带来的延迟和对外部传感器的依赖问题。
3. 实验效果：在RadarScenes真实数据集上，不仅分割精度超越SOTA，而且在运动估计方面表现出极高的鲁棒性，定性结果展示了清晰的建图与轨迹恢复能力。
4. 行业潜力：该研究由TU Delft与NXP合作，针对雷达传感器的物理特性进行了针对性优化，对低算力嵌入式平台的自动驾驶感知算法落地有重要参考价值。
## Abstract: 
Conventional radar segmentation research has typically focused on learning category labels for different moving objects. Although fundamental differences between radar and optical sensors lead to differences in the reliability of predicting accurate and consistent category labels, a review of common radar perception tasks in automotive reveals that determining whether an object is moving or static is a prerequisite for most tasks. To fill this gap, this study proposes a neural network based solution that can simultaneously segment static and moving objects from radar point clouds. Furthermore, since the measured radial velocity of static objects is correlated with the motion of the radar, this approach can also estimate the instantaneous 2D velocity of the moving platform or vehicle (ego motion). However, despite performing dual tasks, the proposed method employs very simple yet effective building blocks for feature extraction: multi layer perceptrons (MLPs) and recurrent neural networks (RNNs). In addition to being the first of its kind in the literature, the proposed method also demonstrates the feasibility of extracting the information required for the dual task directly from unprocessed point clouds, without the need for cloud aggregation, Doppler compensation, motion compensation, or any other intermediate signal processing steps. To measure its performance, this study introduces a set of novel evaluation metrics and tests the proposed method using a challenging real world radar dataset, RadarScenes. The results show that the proposed method not only performs well on the dual tasks, but also has broad application potential in other radar perception tasks.
