---
layout: default
title: "[7.5]Epistemic Deep Learning: Enabling Machine Learning Models to Know When They Do Not Know"
---

# [7.5] Epistemic Deep Learning: Enabling Machine Learning Models to Know When They Do Not Know

- Authors: Shireen Kudukkil Manchingal
- [arXiv Link](https://arxiv.org/abs/2510.22261v1)
- [PDF Link](https://arxiv.org/pdf/2510.22261v1.pdf)

## Subfields
 感知 / 不确定性量化 (Perception / Uncertainty Quantification)
## Reason for Interest

该博士论文提出了一种基于随机集理论（Random Set Theory）和信念函数（Belief Functions）的深度学习框架（RS-NN），用于显式建模认知不确定性（Epistemic Uncertainty）。

优点：
1. 理论创新：利用随机集对“无知”进行建模，相比传统的贝叶斯网络和Deep Ensembles，在理论上更能区分认知不确定性和偶然不确定性。
2. 算法落地：提出了“Budgeting”机制解决了随机集计算复杂度指数爆炸的问题，使其能应用于ImageNet和ViT等大规模架构。
3. AD相关性：第10章专门针对自动驾驶场景（天气分类、锥桶分类）进行了验证，证明了在域适应（Domain Adaptation）和分布外检测（OoD）方面的鲁棒性，这对提升自动驾驶安全性至关重要。

局限性：
目前主要应用于分类任务。虽然论文在“未来方向”中提到了回归任务（如目标检测框预测）的可能性，但当前未展示其在端到端检测或轨迹预测中的实现，限制了其在自动驾驶感知栈中的直接全面应用。
## Abstract: 
  Central to this work is the development of the Random-Set Neural Network (RS-NN), a novel methodology that leverages random set theory to predict belief functions over sets of classes, capturing the extent of epistemic uncertainty through the width of associated credal sets, applications of RS-NN, including its adaptation to Large Language Models (LLMs) and its deployment in weather classification for autonomous racing. In addition, the thesis proposes a unified evaluation framework for uncertainty-aware classifiers. Extensive experiments validate that integrating epistemic awareness into deep learning not only mitigates the risks associated with overconfident predictions but also lays the foundation for a paradigm shift in artificial intelligence, where the ability to 'know when it does not know' becomes a hallmark of robust and dependable systems. The title encapsulates the core philosophy of this work, emphasizing that true intelligence involves recognizing and managing the limits of one's own knowledge.
